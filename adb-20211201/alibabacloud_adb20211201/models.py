# -*- coding: utf-8 -*-
# This file is auto-generated, don't edit it. Thanks.
from Tea.model import TeaModel
from typing import List, Dict, Any


class Adb4MysqlSparkDiagnosisInfo(TeaModel):
    def __init__(
        self,
        diagnosis_code: str = None,
        diagnosis_code_label: str = None,
        diagnosis_msg: str = None,
        diagnosis_type: str = None,
    ):
        self.diagnosis_code = diagnosis_code
        self.diagnosis_code_label = diagnosis_code_label
        self.diagnosis_msg = diagnosis_msg
        self.diagnosis_type = diagnosis_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.diagnosis_code is not None:
            result['DiagnosisCode'] = self.diagnosis_code
        if self.diagnosis_code_label is not None:
            result['DiagnosisCodeLabel'] = self.diagnosis_code_label
        if self.diagnosis_msg is not None:
            result['DiagnosisMsg'] = self.diagnosis_msg
        if self.diagnosis_type is not None:
            result['DiagnosisType'] = self.diagnosis_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DiagnosisCode') is not None:
            self.diagnosis_code = m.get('DiagnosisCode')
        if m.get('DiagnosisCodeLabel') is not None:
            self.diagnosis_code_label = m.get('DiagnosisCodeLabel')
        if m.get('DiagnosisMsg') is not None:
            self.diagnosis_msg = m.get('DiagnosisMsg')
        if m.get('DiagnosisType') is not None:
            self.diagnosis_type = m.get('DiagnosisType')
        return self


class ColDetailModel(TeaModel):
    def __init__(
        self,
        column_name: str = None,
        create_time: str = None,
        description: str = None,
        distribute_key: bool = None,
        nullable: bool = None,
        partition_key: bool = None,
        primary_key: bool = None,
        schema_name: str = None,
        table_name: str = None,
        type: str = None,
        update_time: str = None,
    ):
        self.column_name = column_name
        self.create_time = create_time
        self.description = description
        self.distribute_key = distribute_key
        self.nullable = nullable
        self.partition_key = partition_key
        self.primary_key = primary_key
        self.schema_name = schema_name
        self.table_name = table_name
        self.type = type
        self.update_time = update_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column_name is not None:
            result['ColumnName'] = self.column_name
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.description is not None:
            result['Description'] = self.description
        if self.distribute_key is not None:
            result['DistributeKey'] = self.distribute_key
        if self.nullable is not None:
            result['Nullable'] = self.nullable
        if self.partition_key is not None:
            result['PartitionKey'] = self.partition_key
        if self.primary_key is not None:
            result['PrimaryKey'] = self.primary_key
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.type is not None:
            result['Type'] = self.type
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColumnName') is not None:
            self.column_name = m.get('ColumnName')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DistributeKey') is not None:
            self.distribute_key = m.get('DistributeKey')
        if m.get('Nullable') is not None:
            self.nullable = m.get('Nullable')
        if m.get('PartitionKey') is not None:
            self.partition_key = m.get('PartitionKey')
        if m.get('PrimaryKey') is not None:
            self.primary_key = m.get('PrimaryKey')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class FieldSchemaModel(TeaModel):
    def __init__(
        self,
        auto_increment: bool = None,
        column_raw_name: str = None,
        comment: str = None,
        compress_float_use_short: bool = None,
        compression: str = None,
        create_time: str = None,
        data_type: str = None,
        database_name: str = None,
        default_value: str = None,
        delimiter: str = None,
        encode: str = None,
        is_partition_key: bool = None,
        mapped_name: str = None,
        name: str = None,
        nullable: bool = None,
        on_update: str = None,
        ordinal_position: int = None,
        physical_column_name: str = None,
        pk_position: int = None,
        precision: int = None,
        primarykey: bool = None,
        scale: int = None,
        table_name: str = None,
        tokenizer: str = None,
        type: str = None,
        update_time: str = None,
        value_type: str = None,
    ):
        self.auto_increment = auto_increment
        self.column_raw_name = column_raw_name
        self.comment = comment
        self.compress_float_use_short = compress_float_use_short
        self.compression = compression
        self.create_time = create_time
        self.data_type = data_type
        self.database_name = database_name
        self.default_value = default_value
        self.delimiter = delimiter
        self.encode = encode
        self.is_partition_key = is_partition_key
        self.mapped_name = mapped_name
        self.name = name
        self.nullable = nullable
        self.on_update = on_update
        self.ordinal_position = ordinal_position
        self.physical_column_name = physical_column_name
        self.pk_position = pk_position
        self.precision = precision
        self.primarykey = primarykey
        self.scale = scale
        self.table_name = table_name
        self.tokenizer = tokenizer
        self.type = type
        self.update_time = update_time
        self.value_type = value_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_increment is not None:
            result['AutoIncrement'] = self.auto_increment
        if self.column_raw_name is not None:
            result['ColumnRawName'] = self.column_raw_name
        if self.comment is not None:
            result['Comment'] = self.comment
        if self.compress_float_use_short is not None:
            result['CompressFloatUseShort'] = self.compress_float_use_short
        if self.compression is not None:
            result['Compression'] = self.compression
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.data_type is not None:
            result['DataType'] = self.data_type
        if self.database_name is not None:
            result['DatabaseName'] = self.database_name
        if self.default_value is not None:
            result['DefaultValue'] = self.default_value
        if self.delimiter is not None:
            result['Delimiter'] = self.delimiter
        if self.encode is not None:
            result['Encode'] = self.encode
        if self.is_partition_key is not None:
            result['IsPartitionKey'] = self.is_partition_key
        if self.mapped_name is not None:
            result['MappedName'] = self.mapped_name
        if self.name is not None:
            result['Name'] = self.name
        if self.nullable is not None:
            result['Nullable'] = self.nullable
        if self.on_update is not None:
            result['OnUpdate'] = self.on_update
        if self.ordinal_position is not None:
            result['OrdinalPosition'] = self.ordinal_position
        if self.physical_column_name is not None:
            result['PhysicalColumnName'] = self.physical_column_name
        if self.pk_position is not None:
            result['PkPosition'] = self.pk_position
        if self.precision is not None:
            result['Precision'] = self.precision
        if self.primarykey is not None:
            result['Primarykey'] = self.primarykey
        if self.scale is not None:
            result['Scale'] = self.scale
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.tokenizer is not None:
            result['Tokenizer'] = self.tokenizer
        if self.type is not None:
            result['Type'] = self.type
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        if self.value_type is not None:
            result['ValueType'] = self.value_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoIncrement') is not None:
            self.auto_increment = m.get('AutoIncrement')
        if m.get('ColumnRawName') is not None:
            self.column_raw_name = m.get('ColumnRawName')
        if m.get('Comment') is not None:
            self.comment = m.get('Comment')
        if m.get('CompressFloatUseShort') is not None:
            self.compress_float_use_short = m.get('CompressFloatUseShort')
        if m.get('Compression') is not None:
            self.compression = m.get('Compression')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DataType') is not None:
            self.data_type = m.get('DataType')
        if m.get('DatabaseName') is not None:
            self.database_name = m.get('DatabaseName')
        if m.get('DefaultValue') is not None:
            self.default_value = m.get('DefaultValue')
        if m.get('Delimiter') is not None:
            self.delimiter = m.get('Delimiter')
        if m.get('Encode') is not None:
            self.encode = m.get('Encode')
        if m.get('IsPartitionKey') is not None:
            self.is_partition_key = m.get('IsPartitionKey')
        if m.get('MappedName') is not None:
            self.mapped_name = m.get('MappedName')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Nullable') is not None:
            self.nullable = m.get('Nullable')
        if m.get('OnUpdate') is not None:
            self.on_update = m.get('OnUpdate')
        if m.get('OrdinalPosition') is not None:
            self.ordinal_position = m.get('OrdinalPosition')
        if m.get('PhysicalColumnName') is not None:
            self.physical_column_name = m.get('PhysicalColumnName')
        if m.get('PkPosition') is not None:
            self.pk_position = m.get('PkPosition')
        if m.get('Precision') is not None:
            self.precision = m.get('Precision')
        if m.get('Primarykey') is not None:
            self.primarykey = m.get('Primarykey')
        if m.get('Scale') is not None:
            self.scale = m.get('Scale')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('Tokenizer') is not None:
            self.tokenizer = m.get('Tokenizer')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        if m.get('ValueType') is not None:
            self.value_type = m.get('ValueType')
        return self


class CstoreIndexModel(TeaModel):
    def __init__(
        self,
        column_ords: List[str] = None,
        create_time: str = None,
        database_name: str = None,
        index_columns: List[FieldSchemaModel] = None,
        index_name: str = None,
        index_type: str = None,
        options: Dict[str, str] = None,
        physical_table_name: str = None,
        update_time: str = None,
    ):
        self.column_ords = column_ords
        self.create_time = create_time
        self.database_name = database_name
        self.index_columns = index_columns
        self.index_name = index_name
        self.index_type = index_type
        self.options = options
        self.physical_table_name = physical_table_name
        self.update_time = update_time

    def validate(self):
        if self.index_columns:
            for k in self.index_columns:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column_ords is not None:
            result['ColumnOrds'] = self.column_ords
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.database_name is not None:
            result['DatabaseName'] = self.database_name
        result['IndexColumns'] = []
        if self.index_columns is not None:
            for k in self.index_columns:
                result['IndexColumns'].append(k.to_map() if k else None)
        if self.index_name is not None:
            result['IndexName'] = self.index_name
        if self.index_type is not None:
            result['IndexType'] = self.index_type
        if self.options is not None:
            result['Options'] = self.options
        if self.physical_table_name is not None:
            result['PhysicalTableName'] = self.physical_table_name
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColumnOrds') is not None:
            self.column_ords = m.get('ColumnOrds')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DatabaseName') is not None:
            self.database_name = m.get('DatabaseName')
        self.index_columns = []
        if m.get('IndexColumns') is not None:
            for k in m.get('IndexColumns'):
                temp_model = FieldSchemaModel()
                self.index_columns.append(temp_model.from_map(k))
        if m.get('IndexName') is not None:
            self.index_name = m.get('IndexName')
        if m.get('IndexType') is not None:
            self.index_type = m.get('IndexType')
        if m.get('Options') is not None:
            self.options = m.get('Options')
        if m.get('PhysicalTableName') is not None:
            self.physical_table_name = m.get('PhysicalTableName')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class DatabaseSummaryModel(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        description: str = None,
        owner: str = None,
        schema_name: str = None,
        update_time: str = None,
    ):
        self.create_time = create_time
        self.description = description
        self.owner = owner
        self.schema_name = schema_name
        self.update_time = update_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.description is not None:
            result['Description'] = self.description
        if self.owner is not None:
            result['Owner'] = self.owner
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Owner') is not None:
            self.owner = m.get('Owner')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class Detail(TeaModel):
    def __init__(
        self,
        app_type: str = None,
        dbcluster_id: str = None,
        data: str = None,
        duration_in_millis: int = None,
        estimate_execution_cpu_time_in_seconds: int = None,
        last_attempt_id: str = None,
        last_updated_time_in_millis: int = None,
        log_root_path: str = None,
        resource_group_name: str = None,
        started_time_in_millis: int = None,
        submitted_time_in_millis: int = None,
        terminated_time_in_millis: int = None,
        web_ui_address: str = None,
    ):
        self.app_type = app_type
        self.dbcluster_id = dbcluster_id
        self.data = data
        self.duration_in_millis = duration_in_millis
        self.estimate_execution_cpu_time_in_seconds = estimate_execution_cpu_time_in_seconds
        self.last_attempt_id = last_attempt_id
        self.last_updated_time_in_millis = last_updated_time_in_millis
        self.log_root_path = log_root_path
        self.resource_group_name = resource_group_name
        self.started_time_in_millis = started_time_in_millis
        self.submitted_time_in_millis = submitted_time_in_millis
        self.terminated_time_in_millis = terminated_time_in_millis
        self.web_ui_address = web_ui_address

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_type is not None:
            result['AppType'] = self.app_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.data is not None:
            result['Data'] = self.data
        if self.duration_in_millis is not None:
            result['DurationInMillis'] = self.duration_in_millis
        if self.estimate_execution_cpu_time_in_seconds is not None:
            result['EstimateExecutionCpuTimeInSeconds'] = self.estimate_execution_cpu_time_in_seconds
        if self.last_attempt_id is not None:
            result['LastAttemptId'] = self.last_attempt_id
        if self.last_updated_time_in_millis is not None:
            result['LastUpdatedTimeInMillis'] = self.last_updated_time_in_millis
        if self.log_root_path is not None:
            result['LogRootPath'] = self.log_root_path
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.started_time_in_millis is not None:
            result['StartedTimeInMillis'] = self.started_time_in_millis
        if self.submitted_time_in_millis is not None:
            result['SubmittedTimeInMillis'] = self.submitted_time_in_millis
        if self.terminated_time_in_millis is not None:
            result['TerminatedTimeInMillis'] = self.terminated_time_in_millis
        if self.web_ui_address is not None:
            result['WebUiAddress'] = self.web_ui_address
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppType') is not None:
            self.app_type = m.get('AppType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('DurationInMillis') is not None:
            self.duration_in_millis = m.get('DurationInMillis')
        if m.get('EstimateExecutionCpuTimeInSeconds') is not None:
            self.estimate_execution_cpu_time_in_seconds = m.get('EstimateExecutionCpuTimeInSeconds')
        if m.get('LastAttemptId') is not None:
            self.last_attempt_id = m.get('LastAttemptId')
        if m.get('LastUpdatedTimeInMillis') is not None:
            self.last_updated_time_in_millis = m.get('LastUpdatedTimeInMillis')
        if m.get('LogRootPath') is not None:
            self.log_root_path = m.get('LogRootPath')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('StartedTimeInMillis') is not None:
            self.started_time_in_millis = m.get('StartedTimeInMillis')
        if m.get('SubmittedTimeInMillis') is not None:
            self.submitted_time_in_millis = m.get('SubmittedTimeInMillis')
        if m.get('TerminatedTimeInMillis') is not None:
            self.terminated_time_in_millis = m.get('TerminatedTimeInMillis')
        if m.get('WebUiAddress') is not None:
            self.web_ui_address = m.get('WebUiAddress')
        return self


class FiltersExecutionTimeRange(TeaModel):
    def __init__(
        self,
        max_time_in_seconds: int = None,
        min_time_in_seconds: int = None,
    ):
        self.max_time_in_seconds = max_time_in_seconds
        self.min_time_in_seconds = min_time_in_seconds

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.max_time_in_seconds is not None:
            result['MaxTimeInSeconds'] = self.max_time_in_seconds
        if self.min_time_in_seconds is not None:
            result['MinTimeInSeconds'] = self.min_time_in_seconds
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MaxTimeInSeconds') is not None:
            self.max_time_in_seconds = m.get('MaxTimeInSeconds')
        if m.get('MinTimeInSeconds') is not None:
            self.min_time_in_seconds = m.get('MinTimeInSeconds')
        return self


class FiltersSubmitTimeRange(TeaModel):
    def __init__(
        self,
        max_time_in_mills: int = None,
        min_time_in_mills: int = None,
    ):
        self.max_time_in_mills = max_time_in_mills
        self.min_time_in_mills = min_time_in_mills

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.max_time_in_mills is not None:
            result['MaxTimeInMills'] = self.max_time_in_mills
        if self.min_time_in_mills is not None:
            result['MinTimeInMills'] = self.min_time_in_mills
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MaxTimeInMills') is not None:
            self.max_time_in_mills = m.get('MaxTimeInMills')
        if m.get('MinTimeInMills') is not None:
            self.min_time_in_mills = m.get('MinTimeInMills')
        return self


class FiltersTermiatedTimeRange(TeaModel):
    def __init__(
        self,
        max_time_in_mills: int = None,
        min_time_in_mills: int = None,
    ):
        self.max_time_in_mills = max_time_in_mills
        self.min_time_in_mills = min_time_in_mills

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.max_time_in_mills is not None:
            result['MaxTimeInMills'] = self.max_time_in_mills
        if self.min_time_in_mills is not None:
            result['MinTimeInMills'] = self.min_time_in_mills
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MaxTimeInMills') is not None:
            self.max_time_in_mills = m.get('MaxTimeInMills')
        if m.get('MinTimeInMills') is not None:
            self.min_time_in_mills = m.get('MinTimeInMills')
        return self


class Filters(TeaModel):
    def __init__(
        self,
        app_id_regex: str = None,
        app_name_regex: str = None,
        app_state: str = None,
        app_type: str = None,
        execution_time_range: FiltersExecutionTimeRange = None,
        submit_time_range: FiltersSubmitTimeRange = None,
        termiated_time_range: FiltersTermiatedTimeRange = None,
    ):
        self.app_id_regex = app_id_regex
        self.app_name_regex = app_name_regex
        self.app_state = app_state
        self.app_type = app_type
        self.execution_time_range = execution_time_range
        self.submit_time_range = submit_time_range
        self.termiated_time_range = termiated_time_range

    def validate(self):
        if self.execution_time_range:
            self.execution_time_range.validate()
        if self.submit_time_range:
            self.submit_time_range.validate()
        if self.termiated_time_range:
            self.termiated_time_range.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id_regex is not None:
            result['AppIdRegex'] = self.app_id_regex
        if self.app_name_regex is not None:
            result['AppNameRegex'] = self.app_name_regex
        if self.app_state is not None:
            result['AppState'] = self.app_state
        if self.app_type is not None:
            result['AppType'] = self.app_type
        if self.execution_time_range is not None:
            result['ExecutionTimeRange'] = self.execution_time_range.to_map()
        if self.submit_time_range is not None:
            result['SubmitTimeRange'] = self.submit_time_range.to_map()
        if self.termiated_time_range is not None:
            result['TermiatedTimeRange'] = self.termiated_time_range.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppIdRegex') is not None:
            self.app_id_regex = m.get('AppIdRegex')
        if m.get('AppNameRegex') is not None:
            self.app_name_regex = m.get('AppNameRegex')
        if m.get('AppState') is not None:
            self.app_state = m.get('AppState')
        if m.get('AppType') is not None:
            self.app_type = m.get('AppType')
        if m.get('ExecutionTimeRange') is not None:
            temp_model = FiltersExecutionTimeRange()
            self.execution_time_range = temp_model.from_map(m['ExecutionTimeRange'])
        if m.get('SubmitTimeRange') is not None:
            temp_model = FiltersSubmitTimeRange()
            self.submit_time_range = temp_model.from_map(m['SubmitTimeRange'])
        if m.get('TermiatedTimeRange') is not None:
            temp_model = FiltersTermiatedTimeRange()
            self.termiated_time_range = temp_model.from_map(m['TermiatedTimeRange'])
        return self


class LogAnalyzeResult(TeaModel):
    def __init__(
        self,
        app_error_advice: str = None,
        app_error_code: str = None,
        app_error_log: str = None,
    ):
        self.app_error_advice = app_error_advice
        self.app_error_code = app_error_code
        self.app_error_log = app_error_log

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_error_advice is not None:
            result['AppErrorAdvice'] = self.app_error_advice
        if self.app_error_code is not None:
            result['AppErrorCode'] = self.app_error_code
        if self.app_error_log is not None:
            result['AppErrorLog'] = self.app_error_log
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppErrorAdvice') is not None:
            self.app_error_advice = m.get('AppErrorAdvice')
        if m.get('AppErrorCode') is not None:
            self.app_error_code = m.get('AppErrorCode')
        if m.get('AppErrorLog') is not None:
            self.app_error_log = m.get('AppErrorLog')
        return self


class OperatorNodeStats(TeaModel):
    def __init__(
        self,
        bytes: int = None,
        output_rows: int = None,
        parameters: str = None,
        peak_memory: int = None,
        time_cost: int = None,
    ):
        self.bytes = bytes
        self.output_rows = output_rows
        self.parameters = parameters
        self.peak_memory = peak_memory
        self.time_cost = time_cost

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.bytes is not None:
            result['bytes'] = self.bytes
        if self.output_rows is not None:
            result['outputRows'] = self.output_rows
        if self.parameters is not None:
            result['parameters'] = self.parameters
        if self.peak_memory is not None:
            result['peakMemory'] = self.peak_memory
        if self.time_cost is not None:
            result['timeCost'] = self.time_cost
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('bytes') is not None:
            self.bytes = m.get('bytes')
        if m.get('outputRows') is not None:
            self.output_rows = m.get('outputRows')
        if m.get('parameters') is not None:
            self.parameters = m.get('parameters')
        if m.get('peakMemory') is not None:
            self.peak_memory = m.get('peakMemory')
        if m.get('timeCost') is not None:
            self.time_cost = m.get('timeCost')
        return self


class OperatorNode(TeaModel):
    def __init__(
        self,
        children: List['OperatorNode'] = None,
        id: int = None,
        level_width: int = None,
        node_depth: int = None,
        node_name: str = None,
        node_width: int = None,
        parent_id: int = None,
        stats: OperatorNodeStats = None,
    ):
        self.children = children
        self.id = id
        self.level_width = level_width
        self.node_depth = node_depth
        self.node_name = node_name
        self.node_width = node_width
        self.parent_id = parent_id
        self.stats = stats

    def validate(self):
        if self.children:
            for k in self.children:
                if k:
                    k.validate()
        if self.stats:
            self.stats.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['children'] = []
        if self.children is not None:
            for k in self.children:
                result['children'].append(k.to_map() if k else None)
        if self.id is not None:
            result['id'] = self.id
        if self.level_width is not None:
            result['levelWidth'] = self.level_width
        if self.node_depth is not None:
            result['nodeDepth'] = self.node_depth
        if self.node_name is not None:
            result['nodeName'] = self.node_name
        if self.node_width is not None:
            result['nodeWidth'] = self.node_width
        if self.parent_id is not None:
            result['parentId'] = self.parent_id
        if self.stats is not None:
            result['stats'] = self.stats.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.children = []
        if m.get('children') is not None:
            for k in m.get('children'):
                temp_model = OperatorNode()
                self.children.append(temp_model.from_map(k))
        if m.get('id') is not None:
            self.id = m.get('id')
        if m.get('levelWidth') is not None:
            self.level_width = m.get('levelWidth')
        if m.get('nodeDepth') is not None:
            self.node_depth = m.get('nodeDepth')
        if m.get('nodeName') is not None:
            self.node_name = m.get('nodeName')
        if m.get('nodeWidth') is not None:
            self.node_width = m.get('nodeWidth')
        if m.get('parentId') is not None:
            self.parent_id = m.get('parentId')
        if m.get('stats') is not None:
            temp_model = OperatorNodeStats()
            self.stats = temp_model.from_map(m['stats'])
        return self


class SerDeInfoModel(TeaModel):
    def __init__(
        self,
        name: str = None,
        parameters: Dict[str, str] = None,
        ser_de_id: int = None,
        serialization_lib: str = None,
    ):
        self.name = name
        self.parameters = parameters
        self.ser_de_id = ser_de_id
        self.serialization_lib = serialization_lib

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.parameters is not None:
            result['Parameters'] = self.parameters
        if self.ser_de_id is not None:
            result['SerDeId'] = self.ser_de_id
        if self.serialization_lib is not None:
            result['SerializationLib'] = self.serialization_lib
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Parameters') is not None:
            self.parameters = m.get('Parameters')
        if m.get('SerDeId') is not None:
            self.ser_de_id = m.get('SerDeId')
        if m.get('SerializationLib') is not None:
            self.serialization_lib = m.get('SerializationLib')
        return self


class SparkAnalyzeLogTask(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        result: LogAnalyzeResult = None,
        rule_matched: bool = None,
        started_time_in_millis: int = None,
        submitted_time_in_millis: int = None,
        task_err_msg: str = None,
        task_id: int = None,
        task_state: str = None,
        terminated_time_in_millis: int = None,
        user_id: int = None,
    ):
        self.dbcluster_id = dbcluster_id
        self.result = result
        self.rule_matched = rule_matched
        self.started_time_in_millis = started_time_in_millis
        self.submitted_time_in_millis = submitted_time_in_millis
        self.task_err_msg = task_err_msg
        self.task_id = task_id
        self.task_state = task_state
        self.terminated_time_in_millis = terminated_time_in_millis
        self.user_id = user_id

    def validate(self):
        if self.result:
            self.result.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.result is not None:
            result['Result'] = self.result.to_map()
        if self.rule_matched is not None:
            result['RuleMatched'] = self.rule_matched
        if self.started_time_in_millis is not None:
            result['StartedTimeInMillis'] = self.started_time_in_millis
        if self.submitted_time_in_millis is not None:
            result['SubmittedTimeInMillis'] = self.submitted_time_in_millis
        if self.task_err_msg is not None:
            result['TaskErrMsg'] = self.task_err_msg
        if self.task_id is not None:
            result['TaskId'] = self.task_id
        if self.task_state is not None:
            result['TaskState'] = self.task_state
        if self.terminated_time_in_millis is not None:
            result['TerminatedTimeInMillis'] = self.terminated_time_in_millis
        if self.user_id is not None:
            result['UserId'] = self.user_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Result') is not None:
            temp_model = LogAnalyzeResult()
            self.result = temp_model.from_map(m['Result'])
        if m.get('RuleMatched') is not None:
            self.rule_matched = m.get('RuleMatched')
        if m.get('StartedTimeInMillis') is not None:
            self.started_time_in_millis = m.get('StartedTimeInMillis')
        if m.get('SubmittedTimeInMillis') is not None:
            self.submitted_time_in_millis = m.get('SubmittedTimeInMillis')
        if m.get('TaskErrMsg') is not None:
            self.task_err_msg = m.get('TaskErrMsg')
        if m.get('TaskId') is not None:
            self.task_id = m.get('TaskId')
        if m.get('TaskState') is not None:
            self.task_state = m.get('TaskState')
        if m.get('TerminatedTimeInMillis') is not None:
            self.terminated_time_in_millis = m.get('TerminatedTimeInMillis')
        if m.get('UserId') is not None:
            self.user_id = m.get('UserId')
        return self


class SparkAppInfo(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        app_name: str = None,
        dbcluster_id: str = None,
        detail: Detail = None,
        message: str = None,
        priority: str = None,
        state: str = None,
    ):
        self.app_id = app_id
        self.app_name = app_name
        self.dbcluster_id = dbcluster_id
        self.detail = detail
        self.message = message
        self.priority = priority
        self.state = state

    def validate(self):
        if self.detail:
            self.detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.app_name is not None:
            result['AppName'] = self.app_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.detail is not None:
            result['Detail'] = self.detail.to_map()
        if self.message is not None:
            result['Message'] = self.message
        if self.priority is not None:
            result['Priority'] = self.priority
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AppName') is not None:
            self.app_name = m.get('AppName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Detail') is not None:
            temp_model = Detail()
            self.detail = temp_model.from_map(m['Detail'])
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Priority') is not None:
            self.priority = m.get('Priority')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class SparkAttemptInfo(TeaModel):
    def __init__(
        self,
        attempt_id: str = None,
        detail: Detail = None,
        message: str = None,
        priority: str = None,
        state: str = None,
    ):
        self.attempt_id = attempt_id
        self.detail = detail
        self.message = message
        self.priority = priority
        self.state = state

    def validate(self):
        if self.detail:
            self.detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.attempt_id is not None:
            result['AttemptId'] = self.attempt_id
        if self.detail is not None:
            result['Detail'] = self.detail.to_map()
        if self.message is not None:
            result['Message'] = self.message
        if self.priority is not None:
            result['Priority'] = self.priority
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AttemptId') is not None:
            self.attempt_id = m.get('AttemptId')
        if m.get('Detail') is not None:
            temp_model = Detail()
            self.detail = temp_model.from_map(m['Detail'])
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Priority') is not None:
            self.priority = m.get('Priority')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class SparkBatchSQLStatement(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        code: str = None,
        end_time: int = None,
        error: str = None,
        result: str = None,
        result_uri: str = None,
        start_time: int = None,
        state: str = None,
        statement_id: str = None,
    ):
        self.app_id = app_id
        self.code = code
        self.end_time = end_time
        self.error = error
        self.result = result
        self.result_uri = result_uri
        self.start_time = start_time
        self.state = state
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.code is not None:
            result['Code'] = self.code
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.error is not None:
            result['Error'] = self.error
        if self.result is not None:
            result['Result'] = self.result
        if self.result_uri is not None:
            result['ResultUri'] = self.result_uri
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.state is not None:
            result['State'] = self.state
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('Result') is not None:
            self.result = m.get('Result')
        if m.get('ResultUri') is not None:
            self.result_uri = m.get('ResultUri')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class SparkBatchSQL(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        err_message: str = None,
        query: str = None,
        query_end_time: int = None,
        query_id: str = None,
        query_start_time: int = None,
        query_state: str = None,
        query_submission_time: int = None,
        resource_group_name: str = None,
        schema: str = None,
        statements: List[SparkBatchSQLStatement] = None,
        uid: int = None,
    ):
        self.dbcluster_id = dbcluster_id
        self.err_message = err_message
        self.query = query
        self.query_end_time = query_end_time
        self.query_id = query_id
        self.query_start_time = query_start_time
        self.query_state = query_state
        self.query_submission_time = query_submission_time
        self.resource_group_name = resource_group_name
        self.schema = schema
        self.statements = statements
        self.uid = uid

    def validate(self):
        if self.statements:
            for k in self.statements:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.err_message is not None:
            result['ErrMessage'] = self.err_message
        if self.query is not None:
            result['Query'] = self.query
        if self.query_end_time is not None:
            result['QueryEndTime'] = self.query_end_time
        if self.query_id is not None:
            result['QueryId'] = self.query_id
        if self.query_start_time is not None:
            result['QueryStartTime'] = self.query_start_time
        if self.query_state is not None:
            result['QueryState'] = self.query_state
        if self.query_submission_time is not None:
            result['QuerySubmissionTime'] = self.query_submission_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.schema is not None:
            result['Schema'] = self.schema
        result['Statements'] = []
        if self.statements is not None:
            for k in self.statements:
                result['Statements'].append(k.to_map() if k else None)
        if self.uid is not None:
            result['Uid'] = self.uid
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ErrMessage') is not None:
            self.err_message = m.get('ErrMessage')
        if m.get('Query') is not None:
            self.query = m.get('Query')
        if m.get('QueryEndTime') is not None:
            self.query_end_time = m.get('QueryEndTime')
        if m.get('QueryId') is not None:
            self.query_id = m.get('QueryId')
        if m.get('QueryStartTime') is not None:
            self.query_start_time = m.get('QueryStartTime')
        if m.get('QueryState') is not None:
            self.query_state = m.get('QueryState')
        if m.get('QuerySubmissionTime') is not None:
            self.query_submission_time = m.get('QuerySubmissionTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        self.statements = []
        if m.get('Statements') is not None:
            for k in m.get('Statements'):
                temp_model = SparkBatchSQLStatement()
                self.statements.append(temp_model.from_map(k))
        if m.get('Uid') is not None:
            self.uid = m.get('Uid')
        return self


class SparkOperatorInfo(TeaModel):
    def __init__(
        self,
        metric_value: int = None,
        operator_name: bytes = None,
    ):
        self.metric_value = metric_value
        self.operator_name = operator_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_value is not None:
            result['MetricValue'] = self.metric_value
        if self.operator_name is not None:
            result['OperatorName'] = self.operator_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MetricValue') is not None:
            self.metric_value = m.get('MetricValue')
        if m.get('OperatorName') is not None:
            self.operator_name = m.get('OperatorName')
        return self


class SparkSession(TeaModel):
    def __init__(
        self,
        active: str = None,
        aliyun_uid: int = None,
        session_id: int = None,
        state: str = None,
    ):
        self.active = active
        self.aliyun_uid = aliyun_uid
        self.session_id = session_id
        self.state = state

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active is not None:
            result['Active'] = self.active
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Active') is not None:
            self.active = m.get('Active')
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class Statement(TeaModel):
    def __init__(
        self,
        aliyun_uid: int = None,
        code: str = None,
        code_state: str = None,
        code_type: str = None,
        end_time: int = None,
        error: str = None,
        have_rows: bool = None,
        output: str = None,
        resource_group: str = None,
        session_id: int = None,
        start_time: int = None,
        statement_id: int = None,
        total_count: int = None,
    ):
        self.aliyun_uid = aliyun_uid
        self.code = code
        self.code_state = code_state
        self.code_type = code_type
        self.end_time = end_time
        self.error = error
        self.have_rows = have_rows
        self.output = output
        self.resource_group = resource_group
        self.session_id = session_id
        self.start_time = start_time
        self.statement_id = statement_id
        self.total_count = total_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.code is not None:
            result['Code'] = self.code
        if self.code_state is not None:
            result['CodeState'] = self.code_state
        if self.code_type is not None:
            result['CodeType'] = self.code_type
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.error is not None:
            result['Error'] = self.error
        if self.have_rows is not None:
            result['HaveRows'] = self.have_rows
        if self.output is not None:
            result['Output'] = self.output
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('CodeState') is not None:
            self.code_state = m.get('CodeState')
        if m.get('CodeType') is not None:
            self.code_type = m.get('CodeType')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('HaveRows') is not None:
            self.have_rows = m.get('HaveRows')
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class StatementInfo(TeaModel):
    def __init__(
        self,
        code: str = None,
        completed_time_in_mills: int = None,
        output: str = None,
        process: float = None,
        started_time_in_mills: int = None,
        state: str = None,
        statement_id: str = None,
    ):
        self.code = code
        self.completed_time_in_mills = completed_time_in_mills
        self.output = output
        self.process = process
        self.started_time_in_mills = started_time_in_mills
        self.state = state
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.completed_time_in_mills is not None:
            result['CompletedTimeInMills'] = self.completed_time_in_mills
        if self.output is not None:
            result['Output'] = self.output
        if self.process is not None:
            result['Process'] = self.process
        if self.started_time_in_mills is not None:
            result['StartedTimeInMills'] = self.started_time_in_mills
        if self.state is not None:
            result['State'] = self.state
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('CompletedTimeInMills') is not None:
            self.completed_time_in_mills = m.get('CompletedTimeInMills')
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('Process') is not None:
            self.process = m.get('Process')
        if m.get('StartedTimeInMills') is not None:
            self.started_time_in_mills = m.get('StartedTimeInMills')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class StorageDescriptorModel(TeaModel):
    def __init__(
        self,
        compressed: bool = None,
        input_format: str = None,
        location: str = None,
        num_buckets: int = None,
        output_format: str = None,
        parameters: Dict[str, str] = None,
        sd_id: int = None,
        ser_de_info: SerDeInfoModel = None,
        stored_as_sub_directories: bool = None,
    ):
        self.compressed = compressed
        self.input_format = input_format
        self.location = location
        self.num_buckets = num_buckets
        self.output_format = output_format
        self.parameters = parameters
        self.sd_id = sd_id
        self.ser_de_info = ser_de_info
        self.stored_as_sub_directories = stored_as_sub_directories

    def validate(self):
        if self.ser_de_info:
            self.ser_de_info.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.compressed is not None:
            result['Compressed'] = self.compressed
        if self.input_format is not None:
            result['InputFormat'] = self.input_format
        if self.location is not None:
            result['Location'] = self.location
        if self.num_buckets is not None:
            result['NumBuckets'] = self.num_buckets
        if self.output_format is not None:
            result['OutputFormat'] = self.output_format
        if self.parameters is not None:
            result['Parameters'] = self.parameters
        if self.sd_id is not None:
            result['SdId'] = self.sd_id
        if self.ser_de_info is not None:
            result['SerDeInfo'] = self.ser_de_info.to_map()
        if self.stored_as_sub_directories is not None:
            result['StoredAsSubDirectories'] = self.stored_as_sub_directories
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Compressed') is not None:
            self.compressed = m.get('Compressed')
        if m.get('InputFormat') is not None:
            self.input_format = m.get('InputFormat')
        if m.get('Location') is not None:
            self.location = m.get('Location')
        if m.get('NumBuckets') is not None:
            self.num_buckets = m.get('NumBuckets')
        if m.get('OutputFormat') is not None:
            self.output_format = m.get('OutputFormat')
        if m.get('Parameters') is not None:
            self.parameters = m.get('Parameters')
        if m.get('SdId') is not None:
            self.sd_id = m.get('SdId')
        if m.get('SerDeInfo') is not None:
            temp_model = SerDeInfoModel()
            self.ser_de_info = temp_model.from_map(m['SerDeInfo'])
        if m.get('StoredAsSubDirectories') is not None:
            self.stored_as_sub_directories = m.get('StoredAsSubDirectories')
        return self


class TableDetailModel(TeaModel):
    def __init__(
        self,
        catalog: str = None,
        columns: List[ColDetailModel] = None,
        create_time: str = None,
        description: str = None,
        owner: str = None,
        schema_name: str = None,
        table_name: str = None,
        table_type: str = None,
        update_time: str = None,
    ):
        self.catalog = catalog
        self.columns = columns
        self.create_time = create_time
        self.description = description
        self.owner = owner
        self.schema_name = schema_name
        self.table_name = table_name
        self.table_type = table_type
        self.update_time = update_time

    def validate(self):
        if self.columns:
            for k in self.columns:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.catalog is not None:
            result['Catalog'] = self.catalog
        result['Columns'] = []
        if self.columns is not None:
            for k in self.columns:
                result['Columns'].append(k.to_map() if k else None)
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.description is not None:
            result['Description'] = self.description
        if self.owner is not None:
            result['Owner'] = self.owner
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.table_type is not None:
            result['TableType'] = self.table_type
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Catalog') is not None:
            self.catalog = m.get('Catalog')
        self.columns = []
        if m.get('Columns') is not None:
            for k in m.get('Columns'):
                temp_model = ColDetailModel()
                self.columns.append(temp_model.from_map(k))
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Owner') is not None:
            self.owner = m.get('Owner')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TableType') is not None:
            self.table_type = m.get('TableType')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class TableModel(TeaModel):
    def __init__(
        self,
        archive_type: str = None,
        block_size: int = None,
        bucket: int = None,
        bucket_count: int = None,
        cols: List[FieldSchemaModel] = None,
        comment: str = None,
        compression: str = None,
        create_time: str = None,
        current_version: int = None,
        db_name: str = None,
        dict_encode: bool = None,
        distribute_columns: List[FieldSchemaModel] = None,
        distribute_type: str = None,
        enable_dfs: bool = None,
        hot_partition_count: int = None,
        indexes: List[CstoreIndexModel] = None,
        is_all_index: bool = None,
        is_fulltext_dict: bool = None,
        max_column_id: int = None,
        parameters: Dict[str, str] = None,
        partition_column: str = None,
        partition_count: int = None,
        partition_keys: List[FieldSchemaModel] = None,
        partition_type: str = None,
        physical_database_name: str = None,
        physical_table_name: str = None,
        previous_version: int = None,
        raw_table_name: str = None,
        route_columns: List[FieldSchemaModel] = None,
        route_effective_column: FieldSchemaModel = None,
        route_type: str = None,
        rt_engine_type: str = None,
        rt_index_all: bool = None,
        rt_mode_type: str = None,
        sd: StorageDescriptorModel = None,
        storage_policy: str = None,
        subpartition_column: str = None,
        subpartition_count: int = None,
        subpartition_type: str = None,
        table_engine_name: str = None,
        table_name: str = None,
        table_type: str = None,
        tbl_id: int = None,
        temporary: bool = None,
        update_time: str = None,
        view_expanded_text: str = None,
        view_original_text: str = None,
        view_security_mode: str = None,
    ):
        self.archive_type = archive_type
        self.block_size = block_size
        self.bucket = bucket
        self.bucket_count = bucket_count
        self.cols = cols
        self.comment = comment
        self.compression = compression
        self.create_time = create_time
        self.current_version = current_version
        self.db_name = db_name
        self.dict_encode = dict_encode
        self.distribute_columns = distribute_columns
        self.distribute_type = distribute_type
        self.enable_dfs = enable_dfs
        self.hot_partition_count = hot_partition_count
        self.indexes = indexes
        self.is_all_index = is_all_index
        self.is_fulltext_dict = is_fulltext_dict
        self.max_column_id = max_column_id
        self.parameters = parameters
        self.partition_column = partition_column
        self.partition_count = partition_count
        self.partition_keys = partition_keys
        self.partition_type = partition_type
        self.physical_database_name = physical_database_name
        self.physical_table_name = physical_table_name
        self.previous_version = previous_version
        self.raw_table_name = raw_table_name
        self.route_columns = route_columns
        self.route_effective_column = route_effective_column
        self.route_type = route_type
        self.rt_engine_type = rt_engine_type
        self.rt_index_all = rt_index_all
        self.rt_mode_type = rt_mode_type
        self.sd = sd
        self.storage_policy = storage_policy
        self.subpartition_column = subpartition_column
        self.subpartition_count = subpartition_count
        self.subpartition_type = subpartition_type
        self.table_engine_name = table_engine_name
        self.table_name = table_name
        self.table_type = table_type
        self.tbl_id = tbl_id
        self.temporary = temporary
        self.update_time = update_time
        self.view_expanded_text = view_expanded_text
        self.view_original_text = view_original_text
        self.view_security_mode = view_security_mode

    def validate(self):
        if self.cols:
            for k in self.cols:
                if k:
                    k.validate()
        if self.distribute_columns:
            for k in self.distribute_columns:
                if k:
                    k.validate()
        if self.indexes:
            for k in self.indexes:
                if k:
                    k.validate()
        if self.partition_keys:
            for k in self.partition_keys:
                if k:
                    k.validate()
        if self.route_columns:
            for k in self.route_columns:
                if k:
                    k.validate()
        if self.route_effective_column:
            self.route_effective_column.validate()
        if self.sd:
            self.sd.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.archive_type is not None:
            result['ArchiveType'] = self.archive_type
        if self.block_size is not None:
            result['BlockSize'] = self.block_size
        if self.bucket is not None:
            result['Bucket'] = self.bucket
        if self.bucket_count is not None:
            result['BucketCount'] = self.bucket_count
        result['Cols'] = []
        if self.cols is not None:
            for k in self.cols:
                result['Cols'].append(k.to_map() if k else None)
        if self.comment is not None:
            result['Comment'] = self.comment
        if self.compression is not None:
            result['Compression'] = self.compression
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.current_version is not None:
            result['CurrentVersion'] = self.current_version
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.dict_encode is not None:
            result['DictEncode'] = self.dict_encode
        result['DistributeColumns'] = []
        if self.distribute_columns is not None:
            for k in self.distribute_columns:
                result['DistributeColumns'].append(k.to_map() if k else None)
        if self.distribute_type is not None:
            result['DistributeType'] = self.distribute_type
        if self.enable_dfs is not None:
            result['EnableDfs'] = self.enable_dfs
        if self.hot_partition_count is not None:
            result['HotPartitionCount'] = self.hot_partition_count
        result['Indexes'] = []
        if self.indexes is not None:
            for k in self.indexes:
                result['Indexes'].append(k.to_map() if k else None)
        if self.is_all_index is not None:
            result['IsAllIndex'] = self.is_all_index
        if self.is_fulltext_dict is not None:
            result['IsFulltextDict'] = self.is_fulltext_dict
        if self.max_column_id is not None:
            result['MaxColumnId'] = self.max_column_id
        if self.parameters is not None:
            result['Parameters'] = self.parameters
        if self.partition_column is not None:
            result['PartitionColumn'] = self.partition_column
        if self.partition_count is not None:
            result['PartitionCount'] = self.partition_count
        result['PartitionKeys'] = []
        if self.partition_keys is not None:
            for k in self.partition_keys:
                result['PartitionKeys'].append(k.to_map() if k else None)
        if self.partition_type is not None:
            result['PartitionType'] = self.partition_type
        if self.physical_database_name is not None:
            result['PhysicalDatabaseName'] = self.physical_database_name
        if self.physical_table_name is not None:
            result['PhysicalTableName'] = self.physical_table_name
        if self.previous_version is not None:
            result['PreviousVersion'] = self.previous_version
        if self.raw_table_name is not None:
            result['RawTableName'] = self.raw_table_name
        result['RouteColumns'] = []
        if self.route_columns is not None:
            for k in self.route_columns:
                result['RouteColumns'].append(k.to_map() if k else None)
        if self.route_effective_column is not None:
            result['RouteEffectiveColumn'] = self.route_effective_column.to_map()
        if self.route_type is not None:
            result['RouteType'] = self.route_type
        if self.rt_engine_type is not None:
            result['RtEngineType'] = self.rt_engine_type
        if self.rt_index_all is not None:
            result['RtIndexAll'] = self.rt_index_all
        if self.rt_mode_type is not None:
            result['RtModeType'] = self.rt_mode_type
        if self.sd is not None:
            result['Sd'] = self.sd.to_map()
        if self.storage_policy is not None:
            result['StoragePolicy'] = self.storage_policy
        if self.subpartition_column is not None:
            result['SubpartitionColumn'] = self.subpartition_column
        if self.subpartition_count is not None:
            result['SubpartitionCount'] = self.subpartition_count
        if self.subpartition_type is not None:
            result['SubpartitionType'] = self.subpartition_type
        if self.table_engine_name is not None:
            result['TableEngineName'] = self.table_engine_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.table_type is not None:
            result['TableType'] = self.table_type
        if self.tbl_id is not None:
            result['TblId'] = self.tbl_id
        if self.temporary is not None:
            result['Temporary'] = self.temporary
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        if self.view_expanded_text is not None:
            result['ViewExpandedText'] = self.view_expanded_text
        if self.view_original_text is not None:
            result['ViewOriginalText'] = self.view_original_text
        if self.view_security_mode is not None:
            result['ViewSecurityMode'] = self.view_security_mode
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ArchiveType') is not None:
            self.archive_type = m.get('ArchiveType')
        if m.get('BlockSize') is not None:
            self.block_size = m.get('BlockSize')
        if m.get('Bucket') is not None:
            self.bucket = m.get('Bucket')
        if m.get('BucketCount') is not None:
            self.bucket_count = m.get('BucketCount')
        self.cols = []
        if m.get('Cols') is not None:
            for k in m.get('Cols'):
                temp_model = FieldSchemaModel()
                self.cols.append(temp_model.from_map(k))
        if m.get('Comment') is not None:
            self.comment = m.get('Comment')
        if m.get('Compression') is not None:
            self.compression = m.get('Compression')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('CurrentVersion') is not None:
            self.current_version = m.get('CurrentVersion')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('DictEncode') is not None:
            self.dict_encode = m.get('DictEncode')
        self.distribute_columns = []
        if m.get('DistributeColumns') is not None:
            for k in m.get('DistributeColumns'):
                temp_model = FieldSchemaModel()
                self.distribute_columns.append(temp_model.from_map(k))
        if m.get('DistributeType') is not None:
            self.distribute_type = m.get('DistributeType')
        if m.get('EnableDfs') is not None:
            self.enable_dfs = m.get('EnableDfs')
        if m.get('HotPartitionCount') is not None:
            self.hot_partition_count = m.get('HotPartitionCount')
        self.indexes = []
        if m.get('Indexes') is not None:
            for k in m.get('Indexes'):
                temp_model = CstoreIndexModel()
                self.indexes.append(temp_model.from_map(k))
        if m.get('IsAllIndex') is not None:
            self.is_all_index = m.get('IsAllIndex')
        if m.get('IsFulltextDict') is not None:
            self.is_fulltext_dict = m.get('IsFulltextDict')
        if m.get('MaxColumnId') is not None:
            self.max_column_id = m.get('MaxColumnId')
        if m.get('Parameters') is not None:
            self.parameters = m.get('Parameters')
        if m.get('PartitionColumn') is not None:
            self.partition_column = m.get('PartitionColumn')
        if m.get('PartitionCount') is not None:
            self.partition_count = m.get('PartitionCount')
        self.partition_keys = []
        if m.get('PartitionKeys') is not None:
            for k in m.get('PartitionKeys'):
                temp_model = FieldSchemaModel()
                self.partition_keys.append(temp_model.from_map(k))
        if m.get('PartitionType') is not None:
            self.partition_type = m.get('PartitionType')
        if m.get('PhysicalDatabaseName') is not None:
            self.physical_database_name = m.get('PhysicalDatabaseName')
        if m.get('PhysicalTableName') is not None:
            self.physical_table_name = m.get('PhysicalTableName')
        if m.get('PreviousVersion') is not None:
            self.previous_version = m.get('PreviousVersion')
        if m.get('RawTableName') is not None:
            self.raw_table_name = m.get('RawTableName')
        self.route_columns = []
        if m.get('RouteColumns') is not None:
            for k in m.get('RouteColumns'):
                temp_model = FieldSchemaModel()
                self.route_columns.append(temp_model.from_map(k))
        if m.get('RouteEffectiveColumn') is not None:
            temp_model = FieldSchemaModel()
            self.route_effective_column = temp_model.from_map(m['RouteEffectiveColumn'])
        if m.get('RouteType') is not None:
            self.route_type = m.get('RouteType')
        if m.get('RtEngineType') is not None:
            self.rt_engine_type = m.get('RtEngineType')
        if m.get('RtIndexAll') is not None:
            self.rt_index_all = m.get('RtIndexAll')
        if m.get('RtModeType') is not None:
            self.rt_mode_type = m.get('RtModeType')
        if m.get('Sd') is not None:
            temp_model = StorageDescriptorModel()
            self.sd = temp_model.from_map(m['Sd'])
        if m.get('StoragePolicy') is not None:
            self.storage_policy = m.get('StoragePolicy')
        if m.get('SubpartitionColumn') is not None:
            self.subpartition_column = m.get('SubpartitionColumn')
        if m.get('SubpartitionCount') is not None:
            self.subpartition_count = m.get('SubpartitionCount')
        if m.get('SubpartitionType') is not None:
            self.subpartition_type = m.get('SubpartitionType')
        if m.get('TableEngineName') is not None:
            self.table_engine_name = m.get('TableEngineName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TableType') is not None:
            self.table_type = m.get('TableType')
        if m.get('TblId') is not None:
            self.tbl_id = m.get('TblId')
        if m.get('Temporary') is not None:
            self.temporary = m.get('Temporary')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        if m.get('ViewExpandedText') is not None:
            self.view_expanded_text = m.get('ViewExpandedText')
        if m.get('ViewOriginalText') is not None:
            self.view_original_text = m.get('ViewOriginalText')
        if m.get('ViewSecurityMode') is not None:
            self.view_security_mode = m.get('ViewSecurityMode')
        return self


class OpenStructMvDetailModelBaseTableInfos(TeaModel):
    def __init__(
        self,
        base_table_is_mv: bool = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        self.base_table_is_mv = base_table_is_mv
        self.schema_name = schema_name
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.base_table_is_mv is not None:
            result['BaseTableIsMv'] = self.base_table_is_mv
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BaseTableIsMv') is not None:
            self.base_table_is_mv = m.get('BaseTableIsMv')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class OpenStructMvDetailModel(TeaModel):
    def __init__(
        self,
        base_table_infos: List[OpenStructMvDetailModelBaseTableInfos] = None,
        base_table_names: List[List[str]] = None,
        explicit_hit: int = None,
        first_refresh_time: str = None,
        implicit_hit: int = None,
        is_inactive: bool = None,
        local_size: int = None,
        query_rewrite_enabled: bool = None,
        refresh_interval: str = None,
        refresh_state: str = None,
        remote_size: int = None,
        resource_group: str = None,
        updated_at: str = None,
    ):
        self.base_table_infos = base_table_infos
        self.base_table_names = base_table_names
        self.explicit_hit = explicit_hit
        self.first_refresh_time = first_refresh_time
        self.implicit_hit = implicit_hit
        self.is_inactive = is_inactive
        self.local_size = local_size
        self.query_rewrite_enabled = query_rewrite_enabled
        self.refresh_interval = refresh_interval
        self.refresh_state = refresh_state
        self.remote_size = remote_size
        self.resource_group = resource_group
        self.updated_at = updated_at

    def validate(self):
        if self.base_table_infos:
            for k in self.base_table_infos:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['BaseTableInfos'] = []
        if self.base_table_infos is not None:
            for k in self.base_table_infos:
                result['BaseTableInfos'].append(k.to_map() if k else None)
        if self.base_table_names is not None:
            result['BaseTableNames'] = self.base_table_names
        if self.explicit_hit is not None:
            result['ExplicitHit'] = self.explicit_hit
        if self.first_refresh_time is not None:
            result['FirstRefreshTime'] = self.first_refresh_time
        if self.implicit_hit is not None:
            result['ImplicitHit'] = self.implicit_hit
        if self.is_inactive is not None:
            result['IsInactive'] = self.is_inactive
        if self.local_size is not None:
            result['LocalSize'] = self.local_size
        if self.query_rewrite_enabled is not None:
            result['QueryRewriteEnabled'] = self.query_rewrite_enabled
        if self.refresh_interval is not None:
            result['RefreshInterval'] = self.refresh_interval
        if self.refresh_state is not None:
            result['RefreshState'] = self.refresh_state
        if self.remote_size is not None:
            result['RemoteSize'] = self.remote_size
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.updated_at is not None:
            result['UpdatedAt'] = self.updated_at
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.base_table_infos = []
        if m.get('BaseTableInfos') is not None:
            for k in m.get('BaseTableInfos'):
                temp_model = OpenStructMvDetailModelBaseTableInfos()
                self.base_table_infos.append(temp_model.from_map(k))
        if m.get('BaseTableNames') is not None:
            self.base_table_names = m.get('BaseTableNames')
        if m.get('ExplicitHit') is not None:
            self.explicit_hit = m.get('ExplicitHit')
        if m.get('FirstRefreshTime') is not None:
            self.first_refresh_time = m.get('FirstRefreshTime')
        if m.get('ImplicitHit') is not None:
            self.implicit_hit = m.get('ImplicitHit')
        if m.get('IsInactive') is not None:
            self.is_inactive = m.get('IsInactive')
        if m.get('LocalSize') is not None:
            self.local_size = m.get('LocalSize')
        if m.get('QueryRewriteEnabled') is not None:
            self.query_rewrite_enabled = m.get('QueryRewriteEnabled')
        if m.get('RefreshInterval') is not None:
            self.refresh_interval = m.get('RefreshInterval')
        if m.get('RefreshState') is not None:
            self.refresh_state = m.get('RefreshState')
        if m.get('RemoteSize') is not None:
            self.remote_size = m.get('RemoteSize')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('UpdatedAt') is not None:
            self.updated_at = m.get('UpdatedAt')
        return self


class TableSummaryModel(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        description: str = None,
        mv_detail_model: OpenStructMvDetailModel = None,
        owner: str = None,
        sql: str = None,
        schema_name: str = None,
        table_name: str = None,
        table_size: int = None,
        table_type: str = None,
        update_time: str = None,
    ):
        self.create_time = create_time
        self.description = description
        self.mv_detail_model = mv_detail_model
        self.owner = owner
        self.sql = sql
        self.schema_name = schema_name
        self.table_name = table_name
        self.table_size = table_size
        self.table_type = table_type
        self.update_time = update_time

    def validate(self):
        if self.mv_detail_model:
            self.mv_detail_model.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.description is not None:
            result['Description'] = self.description
        if self.mv_detail_model is not None:
            result['MvDetailModel'] = self.mv_detail_model.to_map()
        if self.owner is not None:
            result['Owner'] = self.owner
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.table_size is not None:
            result['TableSize'] = self.table_size
        if self.table_type is not None:
            result['TableType'] = self.table_type
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('MvDetailModel') is not None:
            temp_model = OpenStructMvDetailModel()
            self.mv_detail_model = temp_model.from_map(m['MvDetailModel'])
        if m.get('Owner') is not None:
            self.owner = m.get('Owner')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TableSize') is not None:
            self.table_size = m.get('TableSize')
        if m.get('TableType') is not None:
            self.table_type = m.get('TableType')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class OpenStructMvBaseTableDetailModel(TeaModel):
    def __init__(
        self,
        data_volumn: str = None,
        enable_binlog: bool = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        self.data_volumn = data_volumn
        self.enable_binlog = enable_binlog
        self.schema_name = schema_name
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data_volumn is not None:
            result['DataVolumn'] = self.data_volumn
        if self.enable_binlog is not None:
            result['EnableBinlog'] = self.enable_binlog
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DataVolumn') is not None:
            self.data_volumn = m.get('DataVolumn')
        if m.get('EnableBinlog') is not None:
            self.enable_binlog = m.get('EnableBinlog')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class OpenStructMVRecommendResultModel(TeaModel):
    def __init__(
        self,
        accelerated_queries_count: int = None,
        base_tables: List[OpenStructMvBaseTableDetailModel] = None,
        saved_scanbytes: int = None,
        subquery: str = None,
        subquery_id: int = None,
        support_incremental_refresh: bool = None,
    ):
        self.accelerated_queries_count = accelerated_queries_count
        self.base_tables = base_tables
        self.saved_scanbytes = saved_scanbytes
        self.subquery = subquery
        self.subquery_id = subquery_id
        self.support_incremental_refresh = support_incremental_refresh

    def validate(self):
        if self.base_tables:
            for k in self.base_tables:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.accelerated_queries_count is not None:
            result['AcceleratedQueriesCount'] = self.accelerated_queries_count
        result['BaseTables'] = []
        if self.base_tables is not None:
            for k in self.base_tables:
                result['BaseTables'].append(k.to_map() if k else None)
        if self.saved_scanbytes is not None:
            result['SavedScanbytes'] = self.saved_scanbytes
        if self.subquery is not None:
            result['Subquery'] = self.subquery
        if self.subquery_id is not None:
            result['SubqueryId'] = self.subquery_id
        if self.support_incremental_refresh is not None:
            result['SupportIncrementalRefresh'] = self.support_incremental_refresh
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AcceleratedQueriesCount') is not None:
            self.accelerated_queries_count = m.get('AcceleratedQueriesCount')
        self.base_tables = []
        if m.get('BaseTables') is not None:
            for k in m.get('BaseTables'):
                temp_model = OpenStructMvBaseTableDetailModel()
                self.base_tables.append(temp_model.from_map(k))
        if m.get('SavedScanbytes') is not None:
            self.saved_scanbytes = m.get('SavedScanbytes')
        if m.get('Subquery') is not None:
            self.subquery = m.get('Subquery')
        if m.get('SubqueryId') is not None:
            self.subquery_id = m.get('SubqueryId')
        if m.get('SupportIncrementalRefresh') is not None:
            self.support_incremental_refresh = m.get('SupportIncrementalRefresh')
        return self


class OpenStructMvRecommendSubTaskModel(TeaModel):
    def __init__(
        self,
        end_time: str = None,
        scan_queries_count: int = None,
        start_time: str = None,
        status: str = None,
        sub_queries_count: int = None,
        subtask_id: int = None,
    ):
        self.end_time = end_time
        self.scan_queries_count = scan_queries_count
        self.start_time = start_time
        self.status = status
        self.sub_queries_count = sub_queries_count
        self.subtask_id = subtask_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.scan_queries_count is not None:
            result['ScanQueriesCount'] = self.scan_queries_count
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status is not None:
            result['Status'] = self.status
        if self.sub_queries_count is not None:
            result['SubQueriesCount'] = self.sub_queries_count
        if self.subtask_id is not None:
            result['SubtaskId'] = self.subtask_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('ScanQueriesCount') is not None:
            self.scan_queries_count = m.get('ScanQueriesCount')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('SubQueriesCount') is not None:
            self.sub_queries_count = m.get('SubQueriesCount')
        if m.get('SubtaskId') is not None:
            self.subtask_id = m.get('SubtaskId')
        return self


class OpenStructMvRecommendTaskModel(TeaModel):
    def __init__(
        self,
        created_time: str = None,
        description: str = None,
        last_run_at: str = None,
        scan_queries_range: int = None,
        scheduling_settings: str = None,
        task_name: str = None,
    ):
        self.created_time = created_time
        self.description = description
        self.last_run_at = last_run_at
        self.scan_queries_range = scan_queries_range
        self.scheduling_settings = scheduling_settings
        self.task_name = task_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.created_time is not None:
            result['CreatedTime'] = self.created_time
        if self.description is not None:
            result['Description'] = self.description
        if self.last_run_at is not None:
            result['LastRunAt'] = self.last_run_at
        if self.scan_queries_range is not None:
            result['ScanQueriesRange'] = self.scan_queries_range
        if self.scheduling_settings is not None:
            result['SchedulingSettings'] = self.scheduling_settings
        if self.task_name is not None:
            result['TaskName'] = self.task_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreatedTime') is not None:
            self.created_time = m.get('CreatedTime')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('LastRunAt') is not None:
            self.last_run_at = m.get('LastRunAt')
        if m.get('ScanQueriesRange') is not None:
            self.scan_queries_range = m.get('ScanQueriesRange')
        if m.get('SchedulingSettings') is not None:
            self.scheduling_settings = m.get('SchedulingSettings')
        if m.get('TaskName') is not None:
            self.task_name = m.get('TaskName')
        return self


class OpenStructRefreshJobModel(TeaModel):
    def __init__(
        self,
        end_time: str = None,
        name: str = None,
        processid: str = None,
        refresh_interval: str = None,
        refresh_model: str = None,
        resource_group: str = None,
        scheduled_start_time: str = None,
        schema_name: str = None,
        start_time: str = None,
        status: str = None,
    ):
        self.end_time = end_time
        self.name = name
        self.processid = processid
        self.refresh_interval = refresh_interval
        self.refresh_model = refresh_model
        self.resource_group = resource_group
        self.scheduled_start_time = scheduled_start_time
        self.schema_name = schema_name
        self.start_time = start_time
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.name is not None:
            result['Name'] = self.name
        if self.processid is not None:
            result['Processid'] = self.processid
        if self.refresh_interval is not None:
            result['RefreshInterval'] = self.refresh_interval
        if self.refresh_model is not None:
            result['RefreshModel'] = self.refresh_model
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.scheduled_start_time is not None:
            result['ScheduledStartTime'] = self.scheduled_start_time
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Processid') is not None:
            self.processid = m.get('Processid')
        if m.get('RefreshInterval') is not None:
            self.refresh_interval = m.get('RefreshInterval')
        if m.get('RefreshModel') is not None:
            self.refresh_model = m.get('RefreshModel')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('ScheduledStartTime') is not None:
            self.scheduled_start_time = m.get('ScheduledStartTime')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class AllocateClusterPublicConnectionRequest(TeaModel):
    def __init__(
        self,
        connection_string_prefix: str = None,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The prefix of the public endpoint.
        # 
        # *   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
        # *   The prefix can be up to 30 characters in length.
        self.connection_string_prefix = connection_string_prefix
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connection_string_prefix is not None:
            result['ConnectionStringPrefix'] = self.connection_string_prefix
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectionStringPrefix') is not None:
            self.connection_string_prefix = m.get('ConnectionStringPrefix')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class AllocateClusterPublicConnectionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class AllocateClusterPublicConnectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: AllocateClusterPublicConnectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AllocateClusterPublicConnectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ApplyAdviceByIdRequest(TeaModel):
    def __init__(
        self,
        advice_date: int = None,
        advice_id: str = None,
        apply_type: str = None,
        build_immediately: bool = None,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The date on which you want to apply the suggestion. Format: yyyyMMdd.
        self.advice_date = advice_date
        # The suggestion ID.
        self.advice_id = advice_id
        self.apply_type = apply_type
        self.build_immediately = build_immediately
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advice_date is not None:
            result['AdviceDate'] = self.advice_date
        if self.advice_id is not None:
            result['AdviceId'] = self.advice_id
        if self.apply_type is not None:
            result['ApplyType'] = self.apply_type
        if self.build_immediately is not None:
            result['BuildImmediately'] = self.build_immediately
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdviceDate') is not None:
            self.advice_date = m.get('AdviceDate')
        if m.get('AdviceId') is not None:
            self.advice_id = m.get('AdviceId')
        if m.get('ApplyType') is not None:
            self.apply_type = m.get('ApplyType')
        if m.get('BuildImmediately') is not None:
            self.build_immediately = m.get('BuildImmediately')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ApplyAdviceByIdResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ApplyAdviceByIdResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ApplyAdviceByIdResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ApplyAdviceByIdResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachUserENIRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class AttachUserENIResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class AttachUserENIResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: AttachUserENIResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachUserENIResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class BatchApplyAdviceByIdListRequest(TeaModel):
    def __init__(
        self,
        advice_date: int = None,
        advice_id_list: str = None,
        apply_type: str = None,
        build_immediately: bool = None,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The date on which you want to apply the suggestion. Format: yyyyMMdd.
        self.advice_date = advice_date
        # The IDs of the suggestions that you want to apply. Separate multiple IDs with commas (,).
        self.advice_id_list = advice_id_list
        self.apply_type = apply_type
        self.build_immediately = build_immediately
        # The cluster ID.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advice_date is not None:
            result['AdviceDate'] = self.advice_date
        if self.advice_id_list is not None:
            result['AdviceIdList'] = self.advice_id_list
        if self.apply_type is not None:
            result['ApplyType'] = self.apply_type
        if self.build_immediately is not None:
            result['BuildImmediately'] = self.build_immediately
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdviceDate') is not None:
            self.advice_date = m.get('AdviceDate')
        if m.get('AdviceIdList') is not None:
            self.advice_id_list = m.get('AdviceIdList')
        if m.get('ApplyType') is not None:
            self.apply_type = m.get('ApplyType')
        if m.get('BuildImmediately') is not None:
            self.build_immediately = m.get('BuildImmediately')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class BatchApplyAdviceByIdListResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class BatchApplyAdviceByIdListResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: BatchApplyAdviceByIdListResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = BatchApplyAdviceByIdListResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class BindAccountRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        dbcluster_id: str = None,
        ram_user: str = None,
    ):
        # The standard account of the cluster.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the RAM user.
        # 
        # This parameter is required.
        self.ram_user = ram_user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.ram_user is not None:
            result['RamUser'] = self.ram_user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RamUser') is not None:
            self.ram_user = m.get('RamUser')
        return self


class BindAccountResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class BindAccountResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: BindAccountResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = BindAccountResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class BindDBResourceGroupWithUserRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        group_name: str = None,
        group_user: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        # 
        # This parameter is required.
        self.group_name = group_name
        # The name of the database account. It can be a standard account or a privileged account.
        # 
        # This parameter is required.
        self.group_user = group_user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_user is not None:
            result['GroupUser'] = self.group_user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupUser') is not None:
            self.group_user = m.get('GroupUser')
        return self


class BindDBResourceGroupWithUserResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class BindDBResourceGroupWithUserResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: BindDBResourceGroupWithUserResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = BindDBResourceGroupWithUserResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CancelSparkReplStatementRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        session_id: int = None,
        statement_id: int = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query Spark application IDs.
        self.app_id = app_id
        # The session ID.
        self.session_id = session_id
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class CancelSparkReplStatementResponseBodyData(TeaModel):
    def __init__(
        self,
        aliyun_uid: int = None,
        code: str = None,
        code_state: str = None,
        code_type: str = None,
        columns: List[str] = None,
        end_time: int = None,
        error: str = None,
        output: str = None,
        output_type: str = None,
        start_time: int = None,
        statement_id: int = None,
    ):
        # The ID of the Alibaba Cloud account that owns the cluster.
        self.aliyun_uid = aliyun_uid
        # The code that is executed.
        self.code = code
        # The code execution status. Valid values:
        # 
        # *   CANCELLED
        # *   RUNNING
        # *   SUCCEEDED
        # *   ERROR
        self.code_state = code_state
        # The code type. Valid values:
        # 
        # *   SCALA
        # *   PYTHON
        self.code_type = code_type
        # The column names.
        self.columns = columns
        # The end time of the execution. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.end_time = end_time
        # The error message.
        self.error = error
        # The code execution result, which is a JSON string that conforms to Apache Livy.
        self.output = output
        # The execution result type, which is in the JSON format. Valid values:
        # 
        # *   TEXT: the text content that conforms to Apache Livy.
        # *   TABLE: the table content that conforms to Apache Livy.
        self.output_type = output_type
        # The start time of the execution. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.start_time = start_time
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.code is not None:
            result['Code'] = self.code
        if self.code_state is not None:
            result['CodeState'] = self.code_state
        if self.code_type is not None:
            result['CodeType'] = self.code_type
        if self.columns is not None:
            result['Columns'] = self.columns
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.error is not None:
            result['Error'] = self.error
        if self.output is not None:
            result['Output'] = self.output
        if self.output_type is not None:
            result['OutputType'] = self.output_type
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('CodeState') is not None:
            self.code_state = m.get('CodeState')
        if m.get('CodeType') is not None:
            self.code_type = m.get('CodeType')
        if m.get('Columns') is not None:
            self.columns = m.get('Columns')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('OutputType') is not None:
            self.output_type = m.get('OutputType')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class CancelSparkReplStatementResponseBody(TeaModel):
    def __init__(
        self,
        data: CancelSparkReplStatementResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = CancelSparkReplStatementResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CancelSparkReplStatementResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CancelSparkReplStatementResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CancelSparkReplStatementResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CancelSparkWarehouseBatchSQLRequest(TeaModel):
    def __init__(
        self,
        agency: str = None,
        dbcluster_id: str = None,
        query_id: str = None,
    ):
        # The name of the client, which can be up to 16 characters in length. Specify a descriptive name that makes it easy to identify.
        self.agency = agency
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The query ID of the Spark SQL statement.
        # 
        # This parameter is required.
        self.query_id = query_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.agency is not None:
            result['Agency'] = self.agency
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.query_id is not None:
            result['QueryId'] = self.query_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Agency') is not None:
            self.agency = m.get('Agency')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('QueryId') is not None:
            self.query_id = m.get('QueryId')
        return self


class CancelSparkWarehouseBatchSQLResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkBatchSQL = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkBatchSQL()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CancelSparkWarehouseBatchSQLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CancelSparkWarehouseBatchSQLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CancelSparkWarehouseBatchSQLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CheckBindRamUserRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id
        # The region ID of the cluster.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class CheckBindRamUserResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        result: bool = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The returned result of the request. Valid values:
        # 
        # *   **true**: the database account is associated with a RAM user.
        # *   **false**: the database account is not associated with a RAM user.
        self.result = result

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.result is not None:
            result['Result'] = self.result
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Result') is not None:
            self.result = m.get('Result')
        return self


class CheckBindRamUserResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CheckBindRamUserResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CheckBindRamUserResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CheckSampleDataSetRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class CheckSampleDataSetResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        status: str = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The state of the built-in dataset. Valid values:
        # 
        # *   **SUCCEED**: The dataset is loaded.
        # *   **INIT**: The dataset is being loaded.
        # *   **FAILED**: The dataset failed to be loaded.
        # *   **UNINITIALIZED**: The dataset is not loaded.
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class CheckSampleDataSetResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CheckSampleDataSetResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CheckSampleDataSetResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateAPSJobRequest(TeaModel):
    def __init__(
        self,
        aps_job_name: str = None,
        db_list: str = None,
        destination_endpoint_instance_id: str = None,
        destination_endpoint_password: str = None,
        destination_endpoint_user_name: str = None,
        partition_list: str = None,
        region_id: str = None,
        source_endpoint_instance_id: str = None,
        source_endpoint_password: str = None,
        source_endpoint_region: str = None,
        source_endpoint_user_name: str = None,
        target_table_mode: str = None,
    ):
        # The name of the synchronization job.
        # 
        # This parameter is required.
        self.aps_job_name = aps_job_name
        # The objects to be synchronized.
        # 
        # This parameter is required.
        self.db_list = db_list
        # The name of the database account of the destination cluster.
        # 
        # This parameter is required.
        self.destination_endpoint_instance_id = destination_endpoint_instance_id
        # The password of the database account of the destination cluster.
        self.destination_endpoint_password = destination_endpoint_password
        # The name of the database account of the destination cluster.
        self.destination_endpoint_user_name = destination_endpoint_user_name
        # The partitions.
        self.partition_list = partition_list
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The ID of the source instance or cluster.
        # 
        # This parameter is required.
        self.source_endpoint_instance_id = source_endpoint_instance_id
        # The password of the database account of the source instance.
        self.source_endpoint_password = source_endpoint_password
        # The region ID of the source instance.
        self.source_endpoint_region = source_endpoint_region
        # The name of the database account of the source instance.
        self.source_endpoint_user_name = source_endpoint_user_name
        # The mode of the destination table.
        self.target_table_mode = target_table_mode

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_name is not None:
            result['ApsJobName'] = self.aps_job_name
        if self.db_list is not None:
            result['DbList'] = self.db_list
        if self.destination_endpoint_instance_id is not None:
            result['DestinationEndpointInstanceID'] = self.destination_endpoint_instance_id
        if self.destination_endpoint_password is not None:
            result['DestinationEndpointPassword'] = self.destination_endpoint_password
        if self.destination_endpoint_user_name is not None:
            result['DestinationEndpointUserName'] = self.destination_endpoint_user_name
        if self.partition_list is not None:
            result['PartitionList'] = self.partition_list
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.source_endpoint_instance_id is not None:
            result['SourceEndpointInstanceID'] = self.source_endpoint_instance_id
        if self.source_endpoint_password is not None:
            result['SourceEndpointPassword'] = self.source_endpoint_password
        if self.source_endpoint_region is not None:
            result['SourceEndpointRegion'] = self.source_endpoint_region
        if self.source_endpoint_user_name is not None:
            result['SourceEndpointUserName'] = self.source_endpoint_user_name
        if self.target_table_mode is not None:
            result['TargetTableMode'] = self.target_table_mode
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobName') is not None:
            self.aps_job_name = m.get('ApsJobName')
        if m.get('DbList') is not None:
            self.db_list = m.get('DbList')
        if m.get('DestinationEndpointInstanceID') is not None:
            self.destination_endpoint_instance_id = m.get('DestinationEndpointInstanceID')
        if m.get('DestinationEndpointPassword') is not None:
            self.destination_endpoint_password = m.get('DestinationEndpointPassword')
        if m.get('DestinationEndpointUserName') is not None:
            self.destination_endpoint_user_name = m.get('DestinationEndpointUserName')
        if m.get('PartitionList') is not None:
            self.partition_list = m.get('PartitionList')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SourceEndpointInstanceID') is not None:
            self.source_endpoint_instance_id = m.get('SourceEndpointInstanceID')
        if m.get('SourceEndpointPassword') is not None:
            self.source_endpoint_password = m.get('SourceEndpointPassword')
        if m.get('SourceEndpointRegion') is not None:
            self.source_endpoint_region = m.get('SourceEndpointRegion')
        if m.get('SourceEndpointUserName') is not None:
            self.source_endpoint_user_name = m.get('SourceEndpointUserName')
        if m.get('TargetTableMode') is not None:
            self.target_table_mode = m.get('TargetTableMode')
        return self


class CreateAPSJobResponseBody(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        code: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The HTTP status code or the error code.
        self.code = code
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateAPSJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateAPSJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateAPSJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateAccountRequest(TeaModel):
    def __init__(
        self,
        account_description: str = None,
        account_name: str = None,
        account_password: str = None,
        account_type: str = None,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The description of the account.
        # 
        # *   The description cannot start with `http://` or `https://`.
        # *   The description can be up to 256 characters in length.
        self.account_description = account_description
        # The name of the database account.
        # 
        # *   The name must start with a lowercase letter and end with a lowercase letter or a digit.
        # *   The name can contain lowercase letters, digits, and underscores (_).
        # *   The name must be 2 to 16 characters in length.
        # *   Reserved account names such as root, admin, and opsadmin cannot be used.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The password of the database account.
        # 
        # *   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
        # *   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
        # *   The password must be 8 to 32 characters in length.
        # 
        # This parameter is required.
        self.account_password = account_password
        # The type of the database account. Valid values:
        # 
        # *   **Normal**: standard account.
        # *   **Super**: privileged account.
        # 
        # This parameter is required.
        self.account_type = account_type
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_description is not None:
            result['AccountDescription'] = self.account_description
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.account_password is not None:
            result['AccountPassword'] = self.account_password
        if self.account_type is not None:
            result['AccountType'] = self.account_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountDescription') is not None:
            self.account_description = m.get('AccountDescription')
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('AccountPassword') is not None:
            self.account_password = m.get('AccountPassword')
        if m.get('AccountType') is not None:
            self.account_type = m.get('AccountType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class CreateAccountResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateAccountResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateAccountResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateAccountResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateApsCopyWorkloadRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        datasource_id: int = None,
        db_name: str = None,
        region_id: str = None,
        table_name: str = None,
        workload_id: str = None,
        workload_type: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        self.datasource_id = datasource_id
        # The name of the database.
        self.db_name = db_name
        # The region ID.
        self.region_id = region_id
        # The name of the table.
        self.table_name = table_name
        # The job ID.
        # 
        # This parameter is required.
        self.workload_id = workload_id
        # The type of the job.
        # 
        # This parameter is required.
        self.workload_type = workload_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        if self.workload_type is not None:
            result['WorkloadType'] = self.workload_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        if m.get('WorkloadType') is not None:
            self.workload_type = m.get('WorkloadType')
        return self


class CreateApsCopyWorkloadResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: Dict[str, Any] = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The returned data.
        self.data = data
        # The HTTP status code.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateApsCopyWorkloadResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateApsCopyWorkloadResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateApsCopyWorkloadResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateApsDatasoureRequestDatabricksInfo(TeaModel):
    def __init__(
        self,
        access_token: str = None,
        workspace_url: str = None,
    ):
        # The token that is used to access Databricks.
        self.access_token = access_token
        # The URL of the workspace.
        self.workspace_url = workspace_url

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_token is not None:
            result['AccessToken'] = self.access_token
        if self.workspace_url is not None:
            result['WorkspaceURL'] = self.workspace_url
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessToken') is not None:
            self.access_token = m.get('AccessToken')
        if m.get('WorkspaceURL') is not None:
            self.workspace_url = m.get('WorkspaceURL')
        return self


class CreateApsDatasoureRequestHiveInfo(TeaModel):
    def __init__(
        self,
        cluster_id: str = None,
        host_config: str = None,
        meta_store_uri: str = None,
        security_group: str = None,
        vswitch: str = None,
    ):
        # The cluster ID.
        self.cluster_id = cluster_id
        # The configuration of the host.
        self.host_config = host_config
        # The URL of the Hive Metastore.
        self.meta_store_uri = meta_store_uri
        # The security group ID.
        self.security_group = security_group
        # The vSwitch ID.
        self.vswitch = vswitch

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cluster_id is not None:
            result['ClusterId'] = self.cluster_id
        if self.host_config is not None:
            result['HostConfig'] = self.host_config
        if self.meta_store_uri is not None:
            result['MetaStoreUri'] = self.meta_store_uri
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.vswitch is not None:
            result['Vswitch'] = self.vswitch
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClusterId') is not None:
            self.cluster_id = m.get('ClusterId')
        if m.get('HostConfig') is not None:
            self.host_config = m.get('HostConfig')
        if m.get('MetaStoreUri') is not None:
            self.meta_store_uri = m.get('MetaStoreUri')
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('Vswitch') is not None:
            self.vswitch = m.get('Vswitch')
        return self


class CreateApsDatasoureRequestKafkaInfo(TeaModel):
    def __init__(
        self,
        kafka_cluster_id: str = None,
        kafka_topic: str = None,
    ):
        # The ID of the Apache Kafka instance.
        self.kafka_cluster_id = kafka_cluster_id
        # The topic of the Apache Kafka instance.
        self.kafka_topic = kafka_topic

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.kafka_cluster_id is not None:
            result['KafkaClusterId'] = self.kafka_cluster_id
        if self.kafka_topic is not None:
            result['KafkaTopic'] = self.kafka_topic
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('KafkaClusterId') is not None:
            self.kafka_cluster_id = m.get('KafkaClusterId')
        if m.get('KafkaTopic') is not None:
            self.kafka_topic = m.get('KafkaTopic')
        return self


class CreateApsDatasoureRequestPolarDBMysqlInfo(TeaModel):
    def __init__(
        self,
        across: bool = None,
        across_role: str = None,
        across_uid: str = None,
        connect_url: str = None,
        instance_id: str = None,
        password: str = None,
        region_id: str = None,
        security_group: str = None,
        user_name: str = None,
    ):
        # Specifies whether the data source is a cross-account resource. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.across = across
        # The name of the cross-account role.
        self.across_role = across_role
        # The cross-account UID.
        self.across_uid = across_uid
        # The URL used to connect to the custom ApsaraDB RDS for MySQL instance.
        self.connect_url = connect_url
        # The instance ID.
        self.instance_id = instance_id
        # The password.
        self.password = password
        # The region ID.
        self.region_id = region_id
        # The security group ID.
        self.security_group = security_group
        # The username used to access the instance.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across is not None:
            result['Across'] = self.across
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.connect_url is not None:
            result['ConnectUrl'] = self.connect_url
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.password is not None:
            result['Password'] = self.password
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Across') is not None:
            self.across = m.get('Across')
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('ConnectUrl') is not None:
            self.connect_url = m.get('ConnectUrl')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class CreateApsDatasoureRequestPolarDBXInfo(TeaModel):
    def __init__(
        self,
        instance_id: str = None,
    ):
        # The instance ID.
        self.instance_id = instance_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        return self


class CreateApsDatasoureRequestRdsMysqlInfo(TeaModel):
    def __init__(
        self,
        connect_url: str = None,
        instance_id: str = None,
        password: str = None,
        region_id: str = None,
        security_group: str = None,
        user_name: str = None,
    ):
        # The URL used to connect to the read-only instance.
        self.connect_url = connect_url
        # The instance ID.
        self.instance_id = instance_id
        # The password of the database account of the instance.
        self.password = password
        # The region ID.
        self.region_id = region_id
        # The security group ID.
        self.security_group = security_group
        # The name of the database account of the instance.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connect_url is not None:
            result['ConnectUrl'] = self.connect_url
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.password is not None:
            result['Password'] = self.password
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectUrl') is not None:
            self.connect_url = m.get('ConnectUrl')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class CreateApsDatasoureRequestSlsInfo(TeaModel):
    def __init__(
        self,
        across: bool = None,
        across_role: str = None,
        across_uid: str = None,
        project: str = None,
        source_region_id: str = None,
        store: str = None,
    ):
        # Specifies whether the data source is a cross-account resource.
        self.across = across
        # The name of the cross-account role.
        self.across_role = across_role
        # The cross-account UID.
        self.across_uid = across_uid
        # The SLS project.
        self.project = project
        # The region ID.
        self.source_region_id = source_region_id
        # The name of the SLS Logstore.
        self.store = store

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across is not None:
            result['Across'] = self.across
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.project is not None:
            result['Project'] = self.project
        if self.source_region_id is not None:
            result['SourceRegionId'] = self.source_region_id
        if self.store is not None:
            result['Store'] = self.store
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Across') is not None:
            self.across = m.get('Across')
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('Project') is not None:
            self.project = m.get('Project')
        if m.get('SourceRegionId') is not None:
            self.source_region_id = m.get('SourceRegionId')
        if m.get('Store') is not None:
            self.store = m.get('Store')
        return self


class CreateApsDatasoureRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        databricks_info: CreateApsDatasoureRequestDatabricksInfo = None,
        datasource_description: str = None,
        datasource_name: str = None,
        datasource_type: str = None,
        hive_info: CreateApsDatasoureRequestHiveInfo = None,
        kafka_info: CreateApsDatasoureRequestKafkaInfo = None,
        mode: str = None,
        polar_dbmysql_info: CreateApsDatasoureRequestPolarDBMysqlInfo = None,
        polar_dbxinfo: CreateApsDatasoureRequestPolarDBXInfo = None,
        rds_mysql_info: CreateApsDatasoureRequestRdsMysqlInfo = None,
        region_id: str = None,
        sls_info: CreateApsDatasoureRequestSlsInfo = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The information about the Databricks data source.
        self.databricks_info = databricks_info
        # The description of the data source.
        self.datasource_description = datasource_description
        # The name of the data source.
        # 
        # This parameter is required.
        self.datasource_name = datasource_name
        # The type of the data source.
        # 
        # This parameter is required.
        self.datasource_type = datasource_type
        # The information about the Hive data source.
        self.hive_info = hive_info
        # The information about the source Apache Kafka instance.
        self.kafka_info = kafka_info
        # The mode.
        self.mode = mode
        # The information about the source PolarDB for MySQL cluster.
        self.polar_dbmysql_info = polar_dbmysql_info
        # The information about the source PolarDB-X instance.
        self.polar_dbxinfo = polar_dbxinfo
        # The information about the source ApsaraDB RDS for MySQL instance.
        self.rds_mysql_info = rds_mysql_info
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The information about the source Simple Log Service (SLS) instance or cluster.
        self.sls_info = sls_info

    def validate(self):
        if self.databricks_info:
            self.databricks_info.validate()
        if self.hive_info:
            self.hive_info.validate()
        if self.kafka_info:
            self.kafka_info.validate()
        if self.polar_dbmysql_info:
            self.polar_dbmysql_info.validate()
        if self.polar_dbxinfo:
            self.polar_dbxinfo.validate()
        if self.rds_mysql_info:
            self.rds_mysql_info.validate()
        if self.sls_info:
            self.sls_info.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.databricks_info is not None:
            result['DatabricksInfo'] = self.databricks_info.to_map()
        if self.datasource_description is not None:
            result['DatasourceDescription'] = self.datasource_description
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.datasource_type is not None:
            result['DatasourceType'] = self.datasource_type
        if self.hive_info is not None:
            result['HiveInfo'] = self.hive_info.to_map()
        if self.kafka_info is not None:
            result['KafkaInfo'] = self.kafka_info.to_map()
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.polar_dbmysql_info is not None:
            result['PolarDBMysqlInfo'] = self.polar_dbmysql_info.to_map()
        if self.polar_dbxinfo is not None:
            result['PolarDBXInfo'] = self.polar_dbxinfo.to_map()
        if self.rds_mysql_info is not None:
            result['RdsMysqlInfo'] = self.rds_mysql_info.to_map()
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.sls_info is not None:
            result['SlsInfo'] = self.sls_info.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabricksInfo') is not None:
            temp_model = CreateApsDatasoureRequestDatabricksInfo()
            self.databricks_info = temp_model.from_map(m['DatabricksInfo'])
        if m.get('DatasourceDescription') is not None:
            self.datasource_description = m.get('DatasourceDescription')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('DatasourceType') is not None:
            self.datasource_type = m.get('DatasourceType')
        if m.get('HiveInfo') is not None:
            temp_model = CreateApsDatasoureRequestHiveInfo()
            self.hive_info = temp_model.from_map(m['HiveInfo'])
        if m.get('KafkaInfo') is not None:
            temp_model = CreateApsDatasoureRequestKafkaInfo()
            self.kafka_info = temp_model.from_map(m['KafkaInfo'])
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('PolarDBMysqlInfo') is not None:
            temp_model = CreateApsDatasoureRequestPolarDBMysqlInfo()
            self.polar_dbmysql_info = temp_model.from_map(m['PolarDBMysqlInfo'])
        if m.get('PolarDBXInfo') is not None:
            temp_model = CreateApsDatasoureRequestPolarDBXInfo()
            self.polar_dbxinfo = temp_model.from_map(m['PolarDBXInfo'])
        if m.get('RdsMysqlInfo') is not None:
            temp_model = CreateApsDatasoureRequestRdsMysqlInfo()
            self.rds_mysql_info = temp_model.from_map(m['RdsMysqlInfo'])
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SlsInfo') is not None:
            temp_model = CreateApsDatasoureRequestSlsInfo()
            self.sls_info = temp_model.from_map(m['SlsInfo'])
        return self


class CreateApsDatasoureShrinkRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        databricks_info_shrink: str = None,
        datasource_description: str = None,
        datasource_name: str = None,
        datasource_type: str = None,
        hive_info_shrink: str = None,
        kafka_info_shrink: str = None,
        mode: str = None,
        polar_dbmysql_info_shrink: str = None,
        polar_dbxinfo_shrink: str = None,
        rds_mysql_info_shrink: str = None,
        region_id: str = None,
        sls_info_shrink: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The information about the Databricks data source.
        self.databricks_info_shrink = databricks_info_shrink
        # The description of the data source.
        self.datasource_description = datasource_description
        # The name of the data source.
        # 
        # This parameter is required.
        self.datasource_name = datasource_name
        # The type of the data source.
        # 
        # This parameter is required.
        self.datasource_type = datasource_type
        # The information about the Hive data source.
        self.hive_info_shrink = hive_info_shrink
        # The information about the source Apache Kafka instance.
        self.kafka_info_shrink = kafka_info_shrink
        # The mode.
        self.mode = mode
        # The information about the source PolarDB for MySQL cluster.
        self.polar_dbmysql_info_shrink = polar_dbmysql_info_shrink
        # The information about the source PolarDB-X instance.
        self.polar_dbxinfo_shrink = polar_dbxinfo_shrink
        # The information about the source ApsaraDB RDS for MySQL instance.
        self.rds_mysql_info_shrink = rds_mysql_info_shrink
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The information about the source Simple Log Service (SLS) instance or cluster.
        self.sls_info_shrink = sls_info_shrink

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.databricks_info_shrink is not None:
            result['DatabricksInfo'] = self.databricks_info_shrink
        if self.datasource_description is not None:
            result['DatasourceDescription'] = self.datasource_description
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.datasource_type is not None:
            result['DatasourceType'] = self.datasource_type
        if self.hive_info_shrink is not None:
            result['HiveInfo'] = self.hive_info_shrink
        if self.kafka_info_shrink is not None:
            result['KafkaInfo'] = self.kafka_info_shrink
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.polar_dbmysql_info_shrink is not None:
            result['PolarDBMysqlInfo'] = self.polar_dbmysql_info_shrink
        if self.polar_dbxinfo_shrink is not None:
            result['PolarDBXInfo'] = self.polar_dbxinfo_shrink
        if self.rds_mysql_info_shrink is not None:
            result['RdsMysqlInfo'] = self.rds_mysql_info_shrink
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.sls_info_shrink is not None:
            result['SlsInfo'] = self.sls_info_shrink
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabricksInfo') is not None:
            self.databricks_info_shrink = m.get('DatabricksInfo')
        if m.get('DatasourceDescription') is not None:
            self.datasource_description = m.get('DatasourceDescription')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('DatasourceType') is not None:
            self.datasource_type = m.get('DatasourceType')
        if m.get('HiveInfo') is not None:
            self.hive_info_shrink = m.get('HiveInfo')
        if m.get('KafkaInfo') is not None:
            self.kafka_info_shrink = m.get('KafkaInfo')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('PolarDBMysqlInfo') is not None:
            self.polar_dbmysql_info_shrink = m.get('PolarDBMysqlInfo')
        if m.get('PolarDBXInfo') is not None:
            self.polar_dbxinfo_shrink = m.get('PolarDBXInfo')
        if m.get('RdsMysqlInfo') is not None:
            self.rds_mysql_info_shrink = m.get('RdsMysqlInfo')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SlsInfo') is not None:
            self.sls_info_shrink = m.get('SlsInfo')
        return self


class CreateApsDatasoureResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        dbcluster_id: str = None,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The information about the cluster resource usage.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the dry run succeeds. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateApsDatasoureResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateApsDatasoureResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateApsDatasoureResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateApsHiveJobRequest(TeaModel):
    def __init__(
        self,
        advanced_config: str = None,
        conflict_strategy: str = None,
        dbcluster_id: str = None,
        datasource_id: int = None,
        full_compute_unit: str = None,
        oss_location: str = None,
        parallelism: int = None,
        region_id: str = None,
        resource_group: str = None,
        sync_allow_expression: str = None,
        sync_deny_expression: str = None,
        target_type: str = None,
        workload_name: str = None,
    ):
        # The advanced configurations.
        self.advanced_config = advanced_config
        # The policy to handle tables with the same name in the destination cluster.
        self.conflict_strategy = conflict_strategy
        # The ID of the AnalyticDB for MySQL cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        self.datasource_id = datasource_id
        # The number of AnalyticDB compute units (ACUs) required for data migration.
        # 
        # This parameter is required.
        self.full_compute_unit = full_compute_unit
        # The path of the destination data lakehouse in an Object Storage Service (OSS) bucket.
        # 
        # This parameter is required.
        self.oss_location = oss_location
        # The number of tasks that are allowed in parallel.
        self.parallelism = parallelism
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the resource group.
        # 
        # This parameter is required.
        self.resource_group = resource_group
        # The expression that allows objects to be synchronized.
        self.sync_allow_expression = sync_allow_expression
        # The expression that denies objects to be synchronized.
        self.sync_deny_expression = sync_deny_expression
        # The destination type.
        self.target_type = target_type
        # The name of the workload.
        # 
        # This parameter is required.
        self.workload_name = workload_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advanced_config is not None:
            result['AdvancedConfig'] = self.advanced_config
        if self.conflict_strategy is not None:
            result['ConflictStrategy'] = self.conflict_strategy
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.full_compute_unit is not None:
            result['FullComputeUnit'] = self.full_compute_unit
        if self.oss_location is not None:
            result['OssLocation'] = self.oss_location
        if self.parallelism is not None:
            result['Parallelism'] = self.parallelism
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.sync_allow_expression is not None:
            result['SyncAllowExpression'] = self.sync_allow_expression
        if self.sync_deny_expression is not None:
            result['SyncDenyExpression'] = self.sync_deny_expression
        if self.target_type is not None:
            result['TargetType'] = self.target_type
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdvancedConfig') is not None:
            self.advanced_config = m.get('AdvancedConfig')
        if m.get('ConflictStrategy') is not None:
            self.conflict_strategy = m.get('ConflictStrategy')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('FullComputeUnit') is not None:
            self.full_compute_unit = m.get('FullComputeUnit')
        if m.get('OssLocation') is not None:
            self.oss_location = m.get('OssLocation')
        if m.get('Parallelism') is not None:
            self.parallelism = m.get('Parallelism')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('SyncAllowExpression') is not None:
            self.sync_allow_expression = m.get('SyncAllowExpression')
        if m.get('SyncDenyExpression') is not None:
            self.sync_deny_expression = m.get('SyncDenyExpression')
        if m.get('TargetType') is not None:
            self.target_type = m.get('TargetType')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class CreateApsHiveJobResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: str = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The response code.
        self.code = code
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateApsHiveJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateApsHiveJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateApsHiveJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateApsSlsADBJobRequestColumns(TeaModel):
    def __init__(
        self,
        map_name: str = None,
        map_type: str = None,
        name: str = None,
        type: str = None,
    ):
        # The name of the mapping.
        self.map_name = map_name
        # The type of the mapping.
        self.map_type = map_type
        # The name of the column.
        self.name = name
        # The data type of the column.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.map_name is not None:
            result['MapName'] = self.map_name
        if self.map_type is not None:
            result['MapType'] = self.map_type
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MapName') is not None:
            self.map_name = m.get('MapName')
        if m.get('MapType') is not None:
            self.map_type = m.get('MapType')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class CreateApsSlsADBJobRequestUnixTimestampConvert(TeaModel):
    def __init__(
        self,
        convert: str = None,
        format: str = None,
        transform: bool = None,
    ):
        # Specifies whether to enable the conversion of timestamps.
        self.convert = convert
        # The format of the timestamp.
        self.format = format
        # Specifies whether to enable the timestamp conversion.
        self.transform = transform

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.convert is not None:
            result['Convert'] = self.convert
        if self.format is not None:
            result['Format'] = self.format
        if self.transform is not None:
            result['Transform'] = self.transform
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Convert') is not None:
            self.convert = m.get('Convert')
        if m.get('Format') is not None:
            self.format = m.get('Format')
        if m.get('Transform') is not None:
            self.transform = m.get('Transform')
        return self


class CreateApsSlsADBJobRequest(TeaModel):
    def __init__(
        self,
        across_role: str = None,
        across_uid: str = None,
        advanced_config: str = None,
        columns: List[CreateApsSlsADBJobRequestColumns] = None,
        dbcluster_id: str = None,
        datasource_id: int = None,
        db_name: str = None,
        dirty_data_handle_mode: str = None,
        dirty_data_process_pattern: str = None,
        exactly_once: str = None,
        full_compute_unit: str = None,
        hudi_advanced_config: str = None,
        incremental_compute_unit: str = None,
        lakehouse_id: int = None,
        max_offsets_per_trigger: int = None,
        oss_location: str = None,
        output_format: str = None,
        partition_specs: List[Dict[str, Any]] = None,
        password: str = None,
        primary_key_definition: str = None,
        project: str = None,
        region_id: str = None,
        resource_group: str = None,
        source_region_id: str = None,
        starting_offsets: str = None,
        store: str = None,
        table_name: str = None,
        target_generate_rule: str = None,
        target_type: str = None,
        unix_timestamp_convert: CreateApsSlsADBJobRequestUnixTimestampConvert = None,
        user_name: str = None,
        workload_name: str = None,
    ):
        # The name of the cross-account role.
        self.across_role = across_role
        # The cross-account UID.
        self.across_uid = across_uid
        # The advanced configurations.
        self.advanced_config = advanced_config
        # The information about columns.
        # 
        # This parameter is required.
        self.columns = columns
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        self.datasource_id = datasource_id
        # The name of the database.
        # 
        # This parameter is required.
        self.db_name = db_name
        # The dirty data processing mode.
        # 
        # This parameter is required.
        self.dirty_data_handle_mode = dirty_data_handle_mode
        # The dirty data processing mode.
        self.dirty_data_process_pattern = dirty_data_process_pattern
        # Specifies whether to enable the consistency check.
        self.exactly_once = exactly_once
        # The number of full AnalyticDB compute units (ACUs).
        self.full_compute_unit = full_compute_unit
        # The advanced configurations of Hudi.
        self.hudi_advanced_config = hudi_advanced_config
        # The number of increment ACUs.
        self.incremental_compute_unit = incremental_compute_unit
        # The lakehouse ID.
        self.lakehouse_id = lakehouse_id
        # The latest offset.
        self.max_offsets_per_trigger = max_offsets_per_trigger
        # The Object Storage Service (OSS) URL.
        self.oss_location = oss_location
        # The format of the output file.
        self.output_format = output_format
        # The information about partition.
        self.partition_specs = partition_specs
        # The password of the database account.
        # 
        # This parameter is required.
        self.password = password
        # The definition of the primary key.
        self.primary_key_definition = primary_key_definition
        # The name of the SLS project.
        self.project = project
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the resource group.
        self.resource_group = resource_group
        # The region ID of the source cluster.
        self.source_region_id = source_region_id
        # The start offset.
        # 
        # This parameter is required.
        self.starting_offsets = starting_offsets
        # The SLS Logstore.
        self.store = store
        # The name of the table.
        # 
        # This parameter is required.
        self.table_name = table_name
        # The rules for generating the destination database.
        self.target_generate_rule = target_generate_rule
        # The destination type.
        self.target_type = target_type
        # The timestamp conversion.
        self.unix_timestamp_convert = unix_timestamp_convert
        # The name of the database account.
        # 
        # This parameter is required.
        self.user_name = user_name
        # The name of the workload.
        # 
        # This parameter is required.
        self.workload_name = workload_name

    def validate(self):
        if self.columns:
            for k in self.columns:
                if k:
                    k.validate()
        if self.unix_timestamp_convert:
            self.unix_timestamp_convert.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.advanced_config is not None:
            result['AdvancedConfig'] = self.advanced_config
        result['Columns'] = []
        if self.columns is not None:
            for k in self.columns:
                result['Columns'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.dirty_data_handle_mode is not None:
            result['DirtyDataHandleMode'] = self.dirty_data_handle_mode
        if self.dirty_data_process_pattern is not None:
            result['DirtyDataProcessPattern'] = self.dirty_data_process_pattern
        if self.exactly_once is not None:
            result['ExactlyOnce'] = self.exactly_once
        if self.full_compute_unit is not None:
            result['FullComputeUnit'] = self.full_compute_unit
        if self.hudi_advanced_config is not None:
            result['HudiAdvancedConfig'] = self.hudi_advanced_config
        if self.incremental_compute_unit is not None:
            result['IncrementalComputeUnit'] = self.incremental_compute_unit
        if self.lakehouse_id is not None:
            result['LakehouseId'] = self.lakehouse_id
        if self.max_offsets_per_trigger is not None:
            result['MaxOffsetsPerTrigger'] = self.max_offsets_per_trigger
        if self.oss_location is not None:
            result['OssLocation'] = self.oss_location
        if self.output_format is not None:
            result['OutputFormat'] = self.output_format
        if self.partition_specs is not None:
            result['PartitionSpecs'] = self.partition_specs
        if self.password is not None:
            result['Password'] = self.password
        if self.primary_key_definition is not None:
            result['PrimaryKeyDefinition'] = self.primary_key_definition
        if self.project is not None:
            result['Project'] = self.project
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.source_region_id is not None:
            result['SourceRegionId'] = self.source_region_id
        if self.starting_offsets is not None:
            result['StartingOffsets'] = self.starting_offsets
        if self.store is not None:
            result['Store'] = self.store
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.target_generate_rule is not None:
            result['TargetGenerateRule'] = self.target_generate_rule
        if self.target_type is not None:
            result['TargetType'] = self.target_type
        if self.unix_timestamp_convert is not None:
            result['UnixTimestampConvert'] = self.unix_timestamp_convert.to_map()
        if self.user_name is not None:
            result['UserName'] = self.user_name
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('AdvancedConfig') is not None:
            self.advanced_config = m.get('AdvancedConfig')
        self.columns = []
        if m.get('Columns') is not None:
            for k in m.get('Columns'):
                temp_model = CreateApsSlsADBJobRequestColumns()
                self.columns.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('DirtyDataHandleMode') is not None:
            self.dirty_data_handle_mode = m.get('DirtyDataHandleMode')
        if m.get('DirtyDataProcessPattern') is not None:
            self.dirty_data_process_pattern = m.get('DirtyDataProcessPattern')
        if m.get('ExactlyOnce') is not None:
            self.exactly_once = m.get('ExactlyOnce')
        if m.get('FullComputeUnit') is not None:
            self.full_compute_unit = m.get('FullComputeUnit')
        if m.get('HudiAdvancedConfig') is not None:
            self.hudi_advanced_config = m.get('HudiAdvancedConfig')
        if m.get('IncrementalComputeUnit') is not None:
            self.incremental_compute_unit = m.get('IncrementalComputeUnit')
        if m.get('LakehouseId') is not None:
            self.lakehouse_id = m.get('LakehouseId')
        if m.get('MaxOffsetsPerTrigger') is not None:
            self.max_offsets_per_trigger = m.get('MaxOffsetsPerTrigger')
        if m.get('OssLocation') is not None:
            self.oss_location = m.get('OssLocation')
        if m.get('OutputFormat') is not None:
            self.output_format = m.get('OutputFormat')
        if m.get('PartitionSpecs') is not None:
            self.partition_specs = m.get('PartitionSpecs')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('PrimaryKeyDefinition') is not None:
            self.primary_key_definition = m.get('PrimaryKeyDefinition')
        if m.get('Project') is not None:
            self.project = m.get('Project')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('SourceRegionId') is not None:
            self.source_region_id = m.get('SourceRegionId')
        if m.get('StartingOffsets') is not None:
            self.starting_offsets = m.get('StartingOffsets')
        if m.get('Store') is not None:
            self.store = m.get('Store')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TargetGenerateRule') is not None:
            self.target_generate_rule = m.get('TargetGenerateRule')
        if m.get('TargetType') is not None:
            self.target_type = m.get('TargetType')
        if m.get('UnixTimestampConvert') is not None:
            temp_model = CreateApsSlsADBJobRequestUnixTimestampConvert()
            self.unix_timestamp_convert = temp_model.from_map(m['UnixTimestampConvert'])
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class CreateApsSlsADBJobShrinkRequest(TeaModel):
    def __init__(
        self,
        across_role: str = None,
        across_uid: str = None,
        advanced_config: str = None,
        columns_shrink: str = None,
        dbcluster_id: str = None,
        datasource_id: int = None,
        db_name: str = None,
        dirty_data_handle_mode: str = None,
        dirty_data_process_pattern: str = None,
        exactly_once: str = None,
        full_compute_unit: str = None,
        hudi_advanced_config: str = None,
        incremental_compute_unit: str = None,
        lakehouse_id: int = None,
        max_offsets_per_trigger: int = None,
        oss_location: str = None,
        output_format: str = None,
        partition_specs_shrink: str = None,
        password: str = None,
        primary_key_definition: str = None,
        project: str = None,
        region_id: str = None,
        resource_group: str = None,
        source_region_id: str = None,
        starting_offsets: str = None,
        store: str = None,
        table_name: str = None,
        target_generate_rule: str = None,
        target_type: str = None,
        unix_timestamp_convert_shrink: str = None,
        user_name: str = None,
        workload_name: str = None,
    ):
        # The name of the cross-account role.
        self.across_role = across_role
        # The cross-account UID.
        self.across_uid = across_uid
        # The advanced configurations.
        self.advanced_config = advanced_config
        # The information about columns.
        # 
        # This parameter is required.
        self.columns_shrink = columns_shrink
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        self.datasource_id = datasource_id
        # The name of the database.
        # 
        # This parameter is required.
        self.db_name = db_name
        # The dirty data processing mode.
        # 
        # This parameter is required.
        self.dirty_data_handle_mode = dirty_data_handle_mode
        # The dirty data processing mode.
        self.dirty_data_process_pattern = dirty_data_process_pattern
        # Specifies whether to enable the consistency check.
        self.exactly_once = exactly_once
        # The number of full AnalyticDB compute units (ACUs).
        self.full_compute_unit = full_compute_unit
        # The advanced configurations of Hudi.
        self.hudi_advanced_config = hudi_advanced_config
        # The number of increment ACUs.
        self.incremental_compute_unit = incremental_compute_unit
        # The lakehouse ID.
        self.lakehouse_id = lakehouse_id
        # The latest offset.
        self.max_offsets_per_trigger = max_offsets_per_trigger
        # The Object Storage Service (OSS) URL.
        self.oss_location = oss_location
        # The format of the output file.
        self.output_format = output_format
        # The information about partition.
        self.partition_specs_shrink = partition_specs_shrink
        # The password of the database account.
        # 
        # This parameter is required.
        self.password = password
        # The definition of the primary key.
        self.primary_key_definition = primary_key_definition
        # The name of the SLS project.
        self.project = project
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the resource group.
        self.resource_group = resource_group
        # The region ID of the source cluster.
        self.source_region_id = source_region_id
        # The start offset.
        # 
        # This parameter is required.
        self.starting_offsets = starting_offsets
        # The SLS Logstore.
        self.store = store
        # The name of the table.
        # 
        # This parameter is required.
        self.table_name = table_name
        # The rules for generating the destination database.
        self.target_generate_rule = target_generate_rule
        # The destination type.
        self.target_type = target_type
        # The timestamp conversion.
        self.unix_timestamp_convert_shrink = unix_timestamp_convert_shrink
        # The name of the database account.
        # 
        # This parameter is required.
        self.user_name = user_name
        # The name of the workload.
        # 
        # This parameter is required.
        self.workload_name = workload_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.advanced_config is not None:
            result['AdvancedConfig'] = self.advanced_config
        if self.columns_shrink is not None:
            result['Columns'] = self.columns_shrink
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.dirty_data_handle_mode is not None:
            result['DirtyDataHandleMode'] = self.dirty_data_handle_mode
        if self.dirty_data_process_pattern is not None:
            result['DirtyDataProcessPattern'] = self.dirty_data_process_pattern
        if self.exactly_once is not None:
            result['ExactlyOnce'] = self.exactly_once
        if self.full_compute_unit is not None:
            result['FullComputeUnit'] = self.full_compute_unit
        if self.hudi_advanced_config is not None:
            result['HudiAdvancedConfig'] = self.hudi_advanced_config
        if self.incremental_compute_unit is not None:
            result['IncrementalComputeUnit'] = self.incremental_compute_unit
        if self.lakehouse_id is not None:
            result['LakehouseId'] = self.lakehouse_id
        if self.max_offsets_per_trigger is not None:
            result['MaxOffsetsPerTrigger'] = self.max_offsets_per_trigger
        if self.oss_location is not None:
            result['OssLocation'] = self.oss_location
        if self.output_format is not None:
            result['OutputFormat'] = self.output_format
        if self.partition_specs_shrink is not None:
            result['PartitionSpecs'] = self.partition_specs_shrink
        if self.password is not None:
            result['Password'] = self.password
        if self.primary_key_definition is not None:
            result['PrimaryKeyDefinition'] = self.primary_key_definition
        if self.project is not None:
            result['Project'] = self.project
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.source_region_id is not None:
            result['SourceRegionId'] = self.source_region_id
        if self.starting_offsets is not None:
            result['StartingOffsets'] = self.starting_offsets
        if self.store is not None:
            result['Store'] = self.store
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.target_generate_rule is not None:
            result['TargetGenerateRule'] = self.target_generate_rule
        if self.target_type is not None:
            result['TargetType'] = self.target_type
        if self.unix_timestamp_convert_shrink is not None:
            result['UnixTimestampConvert'] = self.unix_timestamp_convert_shrink
        if self.user_name is not None:
            result['UserName'] = self.user_name
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('AdvancedConfig') is not None:
            self.advanced_config = m.get('AdvancedConfig')
        if m.get('Columns') is not None:
            self.columns_shrink = m.get('Columns')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('DirtyDataHandleMode') is not None:
            self.dirty_data_handle_mode = m.get('DirtyDataHandleMode')
        if m.get('DirtyDataProcessPattern') is not None:
            self.dirty_data_process_pattern = m.get('DirtyDataProcessPattern')
        if m.get('ExactlyOnce') is not None:
            self.exactly_once = m.get('ExactlyOnce')
        if m.get('FullComputeUnit') is not None:
            self.full_compute_unit = m.get('FullComputeUnit')
        if m.get('HudiAdvancedConfig') is not None:
            self.hudi_advanced_config = m.get('HudiAdvancedConfig')
        if m.get('IncrementalComputeUnit') is not None:
            self.incremental_compute_unit = m.get('IncrementalComputeUnit')
        if m.get('LakehouseId') is not None:
            self.lakehouse_id = m.get('LakehouseId')
        if m.get('MaxOffsetsPerTrigger') is not None:
            self.max_offsets_per_trigger = m.get('MaxOffsetsPerTrigger')
        if m.get('OssLocation') is not None:
            self.oss_location = m.get('OssLocation')
        if m.get('OutputFormat') is not None:
            self.output_format = m.get('OutputFormat')
        if m.get('PartitionSpecs') is not None:
            self.partition_specs_shrink = m.get('PartitionSpecs')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('PrimaryKeyDefinition') is not None:
            self.primary_key_definition = m.get('PrimaryKeyDefinition')
        if m.get('Project') is not None:
            self.project = m.get('Project')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('SourceRegionId') is not None:
            self.source_region_id = m.get('SourceRegionId')
        if m.get('StartingOffsets') is not None:
            self.starting_offsets = m.get('StartingOffsets')
        if m.get('Store') is not None:
            self.store = m.get('Store')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TargetGenerateRule') is not None:
            self.target_generate_rule = m.get('TargetGenerateRule')
        if m.get('TargetType') is not None:
            self.target_type = m.get('TargetType')
        if m.get('UnixTimestampConvert') is not None:
            self.unix_timestamp_convert_shrink = m.get('UnixTimestampConvert')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class CreateApsSlsADBJobResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the dry run succeeds. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateApsSlsADBJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateApsSlsADBJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateApsSlsADBJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateDBClusterRequestTag(TeaModel):
    def __init__(
        self,
        key: str = None,
        value: str = None,
    ):
        # The key of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.
        # 
        # >  The tag key can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.
        self.key = key
        # The value of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.
        # 
        # >  The tag value can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateDBClusterRequest(TeaModel):
    def __init__(
        self,
        backup_set_id: str = None,
        clone_source_region_id: str = None,
        compute_resource: str = None,
        dbcluster_description: str = None,
        dbcluster_network_type: str = None,
        dbcluster_version: str = None,
        disk_encryption: bool = None,
        enable_default_resource_pool: bool = None,
        kms_id: str = None,
        pay_type: str = None,
        period: str = None,
        product_form: str = None,
        product_version: str = None,
        region_id: str = None,
        reserved_node_count: int = None,
        reserved_node_size: str = None,
        resource_group_id: str = None,
        restore_to_time: str = None,
        restore_type: str = None,
        secondary_vswitch_id: str = None,
        secondary_zone_id: str = None,
        source_db_cluster_id: str = None,
        storage_resource: str = None,
        tag: List[CreateDBClusterRequestTag] = None,
        used_time: str = None,
        vpcid: str = None,
        v_switch_id: str = None,
        zone_id: str = None,
    ):
        # The ID of the backup set that you want to use to restore data.
        # 
        # >  You can call the [DescribeBackups](https://help.aliyun.com/document_detail/612318.html) operation to query the backup sets of the cluster.
        self.backup_set_id = backup_set_id
        # The region ID of the source cluster.
        # 
        # >  This parameter must be specified for cloning clusters across regions.
        self.clone_source_region_id = clone_source_region_id
        # The amount of reserved computing resources. Valid values: 0ACU to 4096ACU. The value must be in increments of 16ACU. Each ACU is approximately equal to 1 core and 4 GB memory.
        # 
        # >  This parameter must be specified with a unit.
        self.compute_resource = compute_resource
        # The description of the cluster.
        # 
        # *   The description cannot start with `http://` or `https://`.
        # *   The description must be 2 to 256 characters in length
        self.dbcluster_description = dbcluster_description
        # The network type of the cluster. Set the value to **VPC**.
        self.dbcluster_network_type = dbcluster_network_type
        # The version of the cluster. Set the value to **5.0**.
        # 
        # This parameter is required.
        self.dbcluster_version = dbcluster_version
        # Specifies whether to enable disk encryption.
        self.disk_encryption = disk_encryption
        # Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:
        # 
        # *   **true** (default)
        # *   **false**\
        self.enable_default_resource_pool = enable_default_resource_pool
        # The ID of the key that is used to encrypt disk data.
        # 
        # >  This parameter must be specified only when disk encryption is enabled.
        self.kms_id = kms_id
        # The billing method of the cluster. Valid values:
        # 
        # *   **Postpaid**: pay-as-you-go.
        # *   **Prepaid**: subscription.
        # 
        # This parameter is required.
        self.pay_type = pay_type
        # The subscription type of the subscription cluster. Valid values:
        # 
        # *   **Year**: subscription on a yearly basis.
        # *   **Month**: subscription on a monthly basis.
        # 
        # >  This parameter must be specified when PayType is set to Prepaid.
        self.period = period
        # The product form of the cluster. Valid values:
        # 
        # *   **IntegrationForm**: integrated.
        # *   **LegacyForm**: Data Lakehouse Edition.
        self.product_form = product_form
        # The edition of the cluster. Valid values:
        # 
        # *   **BasicVersion**: Basic Edition.
        # *   **EnterpriseVersion**: Enterprise Edition.
        # 
        # >  This parameter must be specified only when ProductForm is set to IntegrationForm.
        self.product_version = product_version
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The number of reserved resource nodes.
        # 
        # *   For Enterprise Edition, the default value is 3 and the step size is 3.
        # *   For Basic Edition, the default value is 1.
        # 
        # >  This parameter must be specified only when ProductForm is set to IntegrationForm.
        self.reserved_node_count = reserved_node_count
        # The specifications of reserved resource nodes. Unit: ACUs.
        self.reserved_node_size = reserved_node_size
        # The resource group ID.
        self.resource_group_id = resource_group_id
        # The point in time to which you want to restore data from the backup set.
        self.restore_to_time = restore_to_time
        # The method that you want to use to restore data. Valid values:
        # 
        # *   **backup**: restores data from a backup set. You must also specify the **BackupSetId** and **SourceDBClusterId** parameters.
        # *   **timepoint**: restores data to a point in time. You must also specify the **RestoreToTime** and **SourceDBClusterId** parameters.
        self.restore_type = restore_type
        # The ID of the secondary vSwitch.
        # 
        # >  You cannot set this parameter to a value that is the same as that of the VSwitchId parameter.
        self.secondary_vswitch_id = secondary_vswitch_id
        # The ID of the secondary zone.
        # 
        # >  You cannot set this parameter to a value that is the same as that of the ZoneId parameter.
        self.secondary_zone_id = secondary_zone_id
        # The ID of the source AnalyticDB for MySQL Data Warehouse Edition cluster.
        self.source_db_cluster_id = source_db_cluster_id
        # The amount of reserved storage resources. Valid values: 0ACU to 2064ACU. The value must be in increments of 24ACU. Each ACU is approximately equal to 1 core and 4 GB memory.
        # 
        # >  This parameter must be specified with a unit.
        self.storage_resource = storage_resource
        # The tags to add to the cluster.
        self.tag = tag
        # The subscription period of the subscription cluster.
        # 
        # *   Valid values when Period is set to Year: 1, 2, and 3 (integer)
        # *   Valid values when Period is set to Month: 1 to 9 (integer)
        # 
        # > * This parameter is required if the PayType parameter is set to Prepaid.
        # > * Longer subscription periods offer more savings. Purchasing a cluster for one year is more cost-effective than purchasing the cluster for 10 or 11 months.
        self.used_time = used_time
        # The virtual private cloud (VPC) ID of the cluster.
        # 
        # This parameter is required.
        self.vpcid = vpcid
        # The vSwitch ID of the cluster.
        # 
        # This parameter is required.
        self.v_switch_id = v_switch_id
        # The zone ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent zone list.
        # 
        # This parameter is required.
        self.zone_id = zone_id

    def validate(self):
        if self.tag:
            for k in self.tag:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.backup_set_id is not None:
            result['BackupSetId'] = self.backup_set_id
        if self.clone_source_region_id is not None:
            result['CloneSourceRegionId'] = self.clone_source_region_id
        if self.compute_resource is not None:
            result['ComputeResource'] = self.compute_resource
        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description
        if self.dbcluster_network_type is not None:
            result['DBClusterNetworkType'] = self.dbcluster_network_type
        if self.dbcluster_version is not None:
            result['DBClusterVersion'] = self.dbcluster_version
        if self.disk_encryption is not None:
            result['DiskEncryption'] = self.disk_encryption
        if self.enable_default_resource_pool is not None:
            result['EnableDefaultResourcePool'] = self.enable_default_resource_pool
        if self.kms_id is not None:
            result['KmsId'] = self.kms_id
        if self.pay_type is not None:
            result['PayType'] = self.pay_type
        if self.period is not None:
            result['Period'] = self.period
        if self.product_form is not None:
            result['ProductForm'] = self.product_form
        if self.product_version is not None:
            result['ProductVersion'] = self.product_version
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.reserved_node_count is not None:
            result['ReservedNodeCount'] = self.reserved_node_count
        if self.reserved_node_size is not None:
            result['ReservedNodeSize'] = self.reserved_node_size
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.restore_to_time is not None:
            result['RestoreToTime'] = self.restore_to_time
        if self.restore_type is not None:
            result['RestoreType'] = self.restore_type
        if self.secondary_vswitch_id is not None:
            result['SecondaryVSwitchId'] = self.secondary_vswitch_id
        if self.secondary_zone_id is not None:
            result['SecondaryZoneId'] = self.secondary_zone_id
        if self.source_db_cluster_id is not None:
            result['SourceDbClusterId'] = self.source_db_cluster_id
        if self.storage_resource is not None:
            result['StorageResource'] = self.storage_resource
        result['Tag'] = []
        if self.tag is not None:
            for k in self.tag:
                result['Tag'].append(k.to_map() if k else None)
        if self.used_time is not None:
            result['UsedTime'] = self.used_time
        if self.vpcid is not None:
            result['VPCId'] = self.vpcid
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BackupSetId') is not None:
            self.backup_set_id = m.get('BackupSetId')
        if m.get('CloneSourceRegionId') is not None:
            self.clone_source_region_id = m.get('CloneSourceRegionId')
        if m.get('ComputeResource') is not None:
            self.compute_resource = m.get('ComputeResource')
        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')
        if m.get('DBClusterNetworkType') is not None:
            self.dbcluster_network_type = m.get('DBClusterNetworkType')
        if m.get('DBClusterVersion') is not None:
            self.dbcluster_version = m.get('DBClusterVersion')
        if m.get('DiskEncryption') is not None:
            self.disk_encryption = m.get('DiskEncryption')
        if m.get('EnableDefaultResourcePool') is not None:
            self.enable_default_resource_pool = m.get('EnableDefaultResourcePool')
        if m.get('KmsId') is not None:
            self.kms_id = m.get('KmsId')
        if m.get('PayType') is not None:
            self.pay_type = m.get('PayType')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('ProductForm') is not None:
            self.product_form = m.get('ProductForm')
        if m.get('ProductVersion') is not None:
            self.product_version = m.get('ProductVersion')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ReservedNodeCount') is not None:
            self.reserved_node_count = m.get('ReservedNodeCount')
        if m.get('ReservedNodeSize') is not None:
            self.reserved_node_size = m.get('ReservedNodeSize')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('RestoreToTime') is not None:
            self.restore_to_time = m.get('RestoreToTime')
        if m.get('RestoreType') is not None:
            self.restore_type = m.get('RestoreType')
        if m.get('SecondaryVSwitchId') is not None:
            self.secondary_vswitch_id = m.get('SecondaryVSwitchId')
        if m.get('SecondaryZoneId') is not None:
            self.secondary_zone_id = m.get('SecondaryZoneId')
        if m.get('SourceDbClusterId') is not None:
            self.source_db_cluster_id = m.get('SourceDbClusterId')
        if m.get('StorageResource') is not None:
            self.storage_resource = m.get('StorageResource')
        self.tag = []
        if m.get('Tag') is not None:
            for k in m.get('Tag'):
                temp_model = CreateDBClusterRequestTag()
                self.tag.append(temp_model.from_map(k))
        if m.get('UsedTime') is not None:
            self.used_time = m.get('UsedTime')
        if m.get('VPCId') is not None:
            self.vpcid = m.get('VPCId')
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class CreateDBClusterResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        order_id: str = None,
        request_id: str = None,
        resource_group_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The order ID.
        self.order_id = order_id
        # The request ID.
        self.request_id = request_id
        # The default resource group ID.
        self.resource_group_id = resource_group_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.order_id is not None:
            result['OrderId'] = self.order_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OrderId') is not None:
            self.order_id = m.get('OrderId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        return self


class CreateDBClusterResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateDBClusterResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateDBClusterResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateDBResourceGroupRequestRayConfigWorkerGroups(TeaModel):
    def __init__(
        self,
        allocate_unit: str = None,
        group_name: str = None,
        max_worker_quantity: int = None,
        min_worker_quantity: int = None,
        worker_disk_capacity: str = None,
        worker_spec_name: str = None,
        worker_spec_type: str = None,
    ):
        self.allocate_unit = allocate_unit
        self.group_name = group_name
        self.max_worker_quantity = max_worker_quantity
        self.min_worker_quantity = min_worker_quantity
        self.worker_disk_capacity = worker_disk_capacity
        self.worker_spec_name = worker_spec_name
        self.worker_spec_type = worker_spec_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.allocate_unit is not None:
            result['AllocateUnit'] = self.allocate_unit
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.max_worker_quantity is not None:
            result['MaxWorkerQuantity'] = self.max_worker_quantity
        if self.min_worker_quantity is not None:
            result['MinWorkerQuantity'] = self.min_worker_quantity
        if self.worker_disk_capacity is not None:
            result['WorkerDiskCapacity'] = self.worker_disk_capacity
        if self.worker_spec_name is not None:
            result['WorkerSpecName'] = self.worker_spec_name
        if self.worker_spec_type is not None:
            result['WorkerSpecType'] = self.worker_spec_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AllocateUnit') is not None:
            self.allocate_unit = m.get('AllocateUnit')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('MaxWorkerQuantity') is not None:
            self.max_worker_quantity = m.get('MaxWorkerQuantity')
        if m.get('MinWorkerQuantity') is not None:
            self.min_worker_quantity = m.get('MinWorkerQuantity')
        if m.get('WorkerDiskCapacity') is not None:
            self.worker_disk_capacity = m.get('WorkerDiskCapacity')
        if m.get('WorkerSpecName') is not None:
            self.worker_spec_name = m.get('WorkerSpecName')
        if m.get('WorkerSpecType') is not None:
            self.worker_spec_type = m.get('WorkerSpecType')
        return self


class CreateDBResourceGroupRequestRayConfig(TeaModel):
    def __init__(
        self,
        category: str = None,
        head_spec: str = None,
        worker_groups: List[CreateDBResourceGroupRequestRayConfigWorkerGroups] = None,
    ):
        self.category = category
        self.head_spec = head_spec
        self.worker_groups = worker_groups

    def validate(self):
        if self.worker_groups:
            for k in self.worker_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        if self.head_spec is not None:
            result['HeadSpec'] = self.head_spec
        result['WorkerGroups'] = []
        if self.worker_groups is not None:
            for k in self.worker_groups:
                result['WorkerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('HeadSpec') is not None:
            self.head_spec = m.get('HeadSpec')
        self.worker_groups = []
        if m.get('WorkerGroups') is not None:
            for k in m.get('WorkerGroups'):
                temp_model = CreateDBResourceGroupRequestRayConfigWorkerGroups()
                self.worker_groups.append(temp_model.from_map(k))
        return self


class CreateDBResourceGroupRequestRules(TeaModel):
    def __init__(
        self,
        group_name: str = None,
        query_time: str = None,
        target_group_name: str = None,
    ):
        # The name of the resource group.
        # 
        # *   The name can be up to 255 characters in length.
        # *   The name must start with a letter or digit.
        # *   The name can contain letters, digits, hyphens (-), and underscores (_).
        self.group_name = group_name
        # The execution duration of the query. Unit: milliseconds.
        self.query_time = query_time
        # The name of the resource group to which you want to resubmit the query job.
        self.target_group_name = target_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.query_time is not None:
            result['QueryTime'] = self.query_time
        if self.target_group_name is not None:
            result['TargetGroupName'] = self.target_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('QueryTime') is not None:
            self.query_time = m.get('QueryTime')
        if m.get('TargetGroupName') is not None:
            self.target_group_name = m.get('TargetGroupName')
        return self


class CreateDBResourceGroupRequest(TeaModel):
    def __init__(
        self,
        auto_stop_interval: str = None,
        cluster_mode: str = None,
        cluster_size_resource: str = None,
        dbcluster_id: str = None,
        enable_spot: bool = None,
        engine: str = None,
        engine_params: Dict[str, Any] = None,
        group_name: str = None,
        group_type: str = None,
        max_cluster_count: int = None,
        max_compute_resource: str = None,
        max_gpu_quantity: int = None,
        min_cluster_count: int = None,
        min_compute_resource: str = None,
        min_gpu_quantity: int = None,
        ray_config: CreateDBResourceGroupRequestRayConfig = None,
        region_id: str = None,
        rules: List[CreateDBResourceGroupRequestRules] = None,
        spec_name: str = None,
        target_resource_group_name: str = None,
    ):
        self.auto_stop_interval = auto_stop_interval
        # A reserved parameter.
        self.cluster_mode = cluster_mode
        # A reserved parameter.
        self.cluster_size_resource = cluster_size_resource
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the spot instance feature for the resource group. After you enable the spot instance feature, you are charged for resources at a lower unit price but the resources are probably released. You can enable the spot instance feature only for job resource groups. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.enable_spot = enable_spot
        self.engine = engine
        self.engine_params = engine_params
        # The name of the resource group.
        # 
        # *   The name can be up to 255 characters in length.
        # *   The name must start with a letter or a digit.
        # *   The name can contain letters, digits, hyphens (_), and underscores (_).
        # 
        # This parameter is required.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # >  For more information about resource groups, see [Resource group overview](https://help.aliyun.com/document_detail/428610.html).
        # 
        # This parameter is required.
        self.group_type = group_type
        # A reserved parameter.
        self.max_cluster_count = max_cluster_count
        # The maximum reserved computing resources.
        # 
        # *   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16ACU.
        # *   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8ACU.
        self.max_compute_resource = max_compute_resource
        # A reserved parameter.
        self.max_gpu_quantity = max_gpu_quantity
        # A reserved parameter.
        self.min_cluster_count = min_cluster_count
        # The minimum reserved computing resources.
        # 
        # *   When GroupType is set to Interactive, set this parameter to 16ACU.
        # *   When GroupType is set to Job, set this parameter to 0ACU.
        self.min_compute_resource = min_compute_resource
        # A reserved parameter.
        self.min_gpu_quantity = min_gpu_quantity
        self.ray_config = ray_config
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        self.region_id = region_id
        # The job resubmission rules.
        self.rules = rules
        # A reserved parameter.
        self.spec_name = spec_name
        # A reserved parameter.
        self.target_resource_group_name = target_resource_group_name

    def validate(self):
        if self.ray_config:
            self.ray_config.validate()
        if self.rules:
            for k in self.rules:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_stop_interval is not None:
            result['AutoStopInterval'] = self.auto_stop_interval
        if self.cluster_mode is not None:
            result['ClusterMode'] = self.cluster_mode
        if self.cluster_size_resource is not None:
            result['ClusterSizeResource'] = self.cluster_size_resource
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_spot is not None:
            result['EnableSpot'] = self.enable_spot
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.engine_params is not None:
            result['EngineParams'] = self.engine_params
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.max_cluster_count is not None:
            result['MaxClusterCount'] = self.max_cluster_count
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.max_gpu_quantity is not None:
            result['MaxGpuQuantity'] = self.max_gpu_quantity
        if self.min_cluster_count is not None:
            result['MinClusterCount'] = self.min_cluster_count
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        if self.min_gpu_quantity is not None:
            result['MinGpuQuantity'] = self.min_gpu_quantity
        if self.ray_config is not None:
            result['RayConfig'] = self.ray_config.to_map()
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        result['Rules'] = []
        if self.rules is not None:
            for k in self.rules:
                result['Rules'].append(k.to_map() if k else None)
        if self.spec_name is not None:
            result['SpecName'] = self.spec_name
        if self.target_resource_group_name is not None:
            result['TargetResourceGroupName'] = self.target_resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoStopInterval') is not None:
            self.auto_stop_interval = m.get('AutoStopInterval')
        if m.get('ClusterMode') is not None:
            self.cluster_mode = m.get('ClusterMode')
        if m.get('ClusterSizeResource') is not None:
            self.cluster_size_resource = m.get('ClusterSizeResource')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableSpot') is not None:
            self.enable_spot = m.get('EnableSpot')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('EngineParams') is not None:
            self.engine_params = m.get('EngineParams')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('MaxClusterCount') is not None:
            self.max_cluster_count = m.get('MaxClusterCount')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MaxGpuQuantity') is not None:
            self.max_gpu_quantity = m.get('MaxGpuQuantity')
        if m.get('MinClusterCount') is not None:
            self.min_cluster_count = m.get('MinClusterCount')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        if m.get('MinGpuQuantity') is not None:
            self.min_gpu_quantity = m.get('MinGpuQuantity')
        if m.get('RayConfig') is not None:
            temp_model = CreateDBResourceGroupRequestRayConfig()
            self.ray_config = temp_model.from_map(m['RayConfig'])
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        self.rules = []
        if m.get('Rules') is not None:
            for k in m.get('Rules'):
                temp_model = CreateDBResourceGroupRequestRules()
                self.rules.append(temp_model.from_map(k))
        if m.get('SpecName') is not None:
            self.spec_name = m.get('SpecName')
        if m.get('TargetResourceGroupName') is not None:
            self.target_resource_group_name = m.get('TargetResourceGroupName')
        return self


class CreateDBResourceGroupShrinkRequest(TeaModel):
    def __init__(
        self,
        auto_stop_interval: str = None,
        cluster_mode: str = None,
        cluster_size_resource: str = None,
        dbcluster_id: str = None,
        enable_spot: bool = None,
        engine: str = None,
        engine_params_shrink: str = None,
        group_name: str = None,
        group_type: str = None,
        max_cluster_count: int = None,
        max_compute_resource: str = None,
        max_gpu_quantity: int = None,
        min_cluster_count: int = None,
        min_compute_resource: str = None,
        min_gpu_quantity: int = None,
        ray_config_shrink: str = None,
        region_id: str = None,
        rules_shrink: str = None,
        spec_name: str = None,
        target_resource_group_name: str = None,
    ):
        self.auto_stop_interval = auto_stop_interval
        # A reserved parameter.
        self.cluster_mode = cluster_mode
        # A reserved parameter.
        self.cluster_size_resource = cluster_size_resource
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the spot instance feature for the resource group. After you enable the spot instance feature, you are charged for resources at a lower unit price but the resources are probably released. You can enable the spot instance feature only for job resource groups. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.enable_spot = enable_spot
        self.engine = engine
        self.engine_params_shrink = engine_params_shrink
        # The name of the resource group.
        # 
        # *   The name can be up to 255 characters in length.
        # *   The name must start with a letter or a digit.
        # *   The name can contain letters, digits, hyphens (_), and underscores (_).
        # 
        # This parameter is required.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # >  For more information about resource groups, see [Resource group overview](https://help.aliyun.com/document_detail/428610.html).
        # 
        # This parameter is required.
        self.group_type = group_type
        # A reserved parameter.
        self.max_cluster_count = max_cluster_count
        # The maximum reserved computing resources.
        # 
        # *   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16ACU.
        # *   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8ACU.
        self.max_compute_resource = max_compute_resource
        # A reserved parameter.
        self.max_gpu_quantity = max_gpu_quantity
        # A reserved parameter.
        self.min_cluster_count = min_cluster_count
        # The minimum reserved computing resources.
        # 
        # *   When GroupType is set to Interactive, set this parameter to 16ACU.
        # *   When GroupType is set to Job, set this parameter to 0ACU.
        self.min_compute_resource = min_compute_resource
        # A reserved parameter.
        self.min_gpu_quantity = min_gpu_quantity
        self.ray_config_shrink = ray_config_shrink
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        self.region_id = region_id
        # The job resubmission rules.
        self.rules_shrink = rules_shrink
        # A reserved parameter.
        self.spec_name = spec_name
        # A reserved parameter.
        self.target_resource_group_name = target_resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_stop_interval is not None:
            result['AutoStopInterval'] = self.auto_stop_interval
        if self.cluster_mode is not None:
            result['ClusterMode'] = self.cluster_mode
        if self.cluster_size_resource is not None:
            result['ClusterSizeResource'] = self.cluster_size_resource
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_spot is not None:
            result['EnableSpot'] = self.enable_spot
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.engine_params_shrink is not None:
            result['EngineParams'] = self.engine_params_shrink
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.max_cluster_count is not None:
            result['MaxClusterCount'] = self.max_cluster_count
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.max_gpu_quantity is not None:
            result['MaxGpuQuantity'] = self.max_gpu_quantity
        if self.min_cluster_count is not None:
            result['MinClusterCount'] = self.min_cluster_count
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        if self.min_gpu_quantity is not None:
            result['MinGpuQuantity'] = self.min_gpu_quantity
        if self.ray_config_shrink is not None:
            result['RayConfig'] = self.ray_config_shrink
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.rules_shrink is not None:
            result['Rules'] = self.rules_shrink
        if self.spec_name is not None:
            result['SpecName'] = self.spec_name
        if self.target_resource_group_name is not None:
            result['TargetResourceGroupName'] = self.target_resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoStopInterval') is not None:
            self.auto_stop_interval = m.get('AutoStopInterval')
        if m.get('ClusterMode') is not None:
            self.cluster_mode = m.get('ClusterMode')
        if m.get('ClusterSizeResource') is not None:
            self.cluster_size_resource = m.get('ClusterSizeResource')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableSpot') is not None:
            self.enable_spot = m.get('EnableSpot')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('EngineParams') is not None:
            self.engine_params_shrink = m.get('EngineParams')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('MaxClusterCount') is not None:
            self.max_cluster_count = m.get('MaxClusterCount')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MaxGpuQuantity') is not None:
            self.max_gpu_quantity = m.get('MaxGpuQuantity')
        if m.get('MinClusterCount') is not None:
            self.min_cluster_count = m.get('MinClusterCount')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        if m.get('MinGpuQuantity') is not None:
            self.min_gpu_quantity = m.get('MinGpuQuantity')
        if m.get('RayConfig') is not None:
            self.ray_config_shrink = m.get('RayConfig')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Rules') is not None:
            self.rules_shrink = m.get('Rules')
        if m.get('SpecName') is not None:
            self.spec_name = m.get('SpecName')
        if m.get('TargetResourceGroupName') is not None:
            self.target_resource_group_name = m.get('TargetResourceGroupName')
        return self


class CreateDBResourceGroupResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateDBResourceGroupResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateDBResourceGroupResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateDBResourceGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateElasticPlanRequest(TeaModel):
    def __init__(
        self,
        auto_scale: bool = None,
        cron_expression: str = None,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
        enabled: bool = None,
        end_time: str = None,
        resource_group_name: str = None,
        start_time: str = None,
        target_size: str = None,
        type: str = None,
    ):
        # Specifies whether to enable **Default Proportional Scaling for EIUs**. Valid values:
        # 
        # *   true. In this case, storage resources are scaled along with computing resources, and the TargetSize and CronExpression parameters are not supported.
        # *   false
        # 
        # > 
        # 
        # *   This parameter must be specified when Type is set to WORKER. This parameter is not required when Type is set to EXECUTOR.
        # 
        # *   You can enable Default Proportional Scaling for EIUs for only a single scaling plan of a cluster.
        self.auto_scale = auto_scale
        # A CORN expression that specifies the scaling cycle and time for the scaling plan.
        self.cron_expression = cron_expression
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # >  The name must be 2 to 30 characters in length and can contain letters, digits, and underscores (_). The name must start with a letter.
        # 
        # This parameter is required.
        self.elastic_plan_name = elastic_plan_name
        # Specifies whether to immediately enable the scaling plan after the plan is created. Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is required.
        self.enabled = enabled
        # The end time of the scaling plan.
        # 
        # >  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        self.end_time = end_time
        # The name of the resource group.
        # 
        # > 
        # 
        # *   If you want to create a scaling plan that uses interactive resource groups, you must specify this parameter. If you want to create a scaling plan that uses elastic I/O units (EIUs), you do not need to specify this parameter.
        # 
        # *   You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the resource group name for a cluster.
        self.resource_group_name = resource_group_name
        # The start time of the scaling plan.
        # 
        # >  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        self.start_time = start_time
        # The desired specifications of elastic resources after scaling.
        # 
        # > 
        # 
        # *   If the scaling plan uses **EIUs** and **Default Proportional Scaling for EIUs** is enabled, you do not need to specify this parameter. In other cases, you must specify this parameter.
        # 
        # *   You can call the [DescribeElasticPlanSpecifications](https://help.aliyun.com/document_detail/601278.html) operation to query the specifications that are supported for scaling plans.
        self.target_size = target_size
        # The type of the scaling plan. Valid values:
        # 
        # *   EXECUTOR: the interactive resource group type, which indicates the computing resource type.
        # *   WORKER: the EIU type.
        # 
        # This parameter is required.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_scale is not None:
            result['AutoScale'] = self.auto_scale
        if self.cron_expression is not None:
            result['CronExpression'] = self.cron_expression
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.enabled is not None:
            result['Enabled'] = self.enabled
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.target_size is not None:
            result['TargetSize'] = self.target_size
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoScale') is not None:
            self.auto_scale = m.get('AutoScale')
        if m.get('CronExpression') is not None:
            self.cron_expression = m.get('CronExpression')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('Enabled') is not None:
            self.enabled = m.get('Enabled')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('TargetSize') is not None:
            self.target_size = m.get('TargetSize')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class CreateElasticPlanResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateElasticPlanResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateElasticPlanResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateElasticPlanResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateLakeStorageRequestPermissions(TeaModel):
    def __init__(
        self,
        account: str = None,
        read: bool = None,
        type: str = None,
        write: bool = None,
    ):
        # The account ID.
        self.account = account
        # The read permissions.
        self.read = read
        # The account type.
        self.type = type
        # The write permissions.
        self.write = write

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account is not None:
            result['Account'] = self.account
        if self.read is not None:
            result['Read'] = self.read
        if self.type is not None:
            result['Type'] = self.type
        if self.write is not None:
            result['Write'] = self.write
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Account') is not None:
            self.account = m.get('Account')
        if m.get('Read') is not None:
            self.read = m.get('Read')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Write') is not None:
            self.write = m.get('Write')
        return self


class CreateLakeStorageRequest(TeaModel):
    def __init__(
        self,
        client_token: str = None,
        dbcluster_id: str = None,
        description: str = None,
        permissions: List[CreateLakeStorageRequestPermissions] = None,
        region_id: str = None,
    ):
        # The client token that is used to ensure the idempotence of the request.
        # You can use the client to generate the token, but you must make sure that the token is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length.
        self.client_token = client_token
        # The ID of the AnalyticDB for MySQL cluster with which you want to associate the lake storage.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The permissions that you want to grant on the lake storage to the Alibaba Cloud account besides the permissions that are automatically granted to the Resource Access Management (RAM) user or the Alibaba Cloud account.
        self.permissions = permissions
        # The region ID.
        self.region_id = region_id

    def validate(self):
        if self.permissions:
            for k in self.permissions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        result['Permissions'] = []
        if self.permissions is not None:
            for k in self.permissions:
                result['Permissions'].append(k.to_map() if k else None)
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        self.permissions = []
        if m.get('Permissions') is not None:
            for k in m.get('Permissions'):
                temp_model = CreateLakeStorageRequestPermissions()
                self.permissions.append(temp_model.from_map(k))
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class CreateLakeStorageShrinkRequest(TeaModel):
    def __init__(
        self,
        client_token: str = None,
        dbcluster_id: str = None,
        description: str = None,
        permissions_shrink: str = None,
        region_id: str = None,
    ):
        # The client token that is used to ensure the idempotence of the request.
        # You can use the client to generate the token, but you must make sure that the token is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length.
        self.client_token = client_token
        # The ID of the AnalyticDB for MySQL cluster with which you want to associate the lake storage.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The permissions that you want to grant on the lake storage to the Alibaba Cloud account besides the permissions that are automatically granted to the Resource Access Management (RAM) user or the Alibaba Cloud account.
        self.permissions_shrink = permissions_shrink
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        if self.permissions_shrink is not None:
            result['Permissions'] = self.permissions_shrink
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Permissions') is not None:
            self.permissions_shrink = m.get('Permissions')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class CreateLakeStorageResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The usage details of cluster resources.
        self.data = data
        # The HTTP status code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. If the operation is asynchronously implemented, the job ID is returned.
        self.message = message
        # The request ID
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateLakeStorageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateLakeStorageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateLakeStorageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateOssSubDirectoryRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        path: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The OSS path where you want to create a subdirectory.
        # 
        # This parameter is required.
        self.path = path

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.path is not None:
            result['Path'] = self.path
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Path') is not None:
            self.path = m.get('Path')
        return self


class CreateOssSubDirectoryResponseBodyData(TeaModel):
    def __init__(
        self,
        client_crc: int = None,
        etag: str = None,
        request_id: str = None,
        server_crc: int = None,
    ):
        # The cyclic redundancy check (CRC) value on the client.
        self.client_crc = client_crc
        # The tag of the OSS path.
        self.etag = etag
        # The request ID.
        self.request_id = request_id
        # The CRC-64 value on the OSS bucket.
        self.server_crc = server_crc

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_crc is not None:
            result['ClientCRC'] = self.client_crc
        if self.etag is not None:
            result['ETag'] = self.etag
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.server_crc is not None:
            result['ServerCRC'] = self.server_crc
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientCRC') is not None:
            self.client_crc = m.get('ClientCRC')
        if m.get('ETag') is not None:
            self.etag = m.get('ETag')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ServerCRC') is not None:
            self.server_crc = m.get('ServerCRC')
        return self


class CreateOssSubDirectoryResponseBody(TeaModel):
    def __init__(
        self,
        data: CreateOssSubDirectoryResponseBodyData = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message.
        # 
        # *   If the request was successful, a **success** message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = CreateOssSubDirectoryResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class CreateOssSubDirectoryResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateOssSubDirectoryResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateOssSubDirectoryResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreatePerformanceViewRequestViewDetailCategoriesKeys(TeaModel):
    def __init__(
        self,
        key_name: str = None,
        selected: bool = None,
    ):
        # The name of the metric.
        self.key_name = key_name
        # Specifies whether to select the metric. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.selected = selected

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key_name is not None:
            result['KeyName'] = self.key_name
        if self.selected is not None:
            result['Selected'] = self.selected
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('KeyName') is not None:
            self.key_name = m.get('KeyName')
        if m.get('Selected') is not None:
            self.selected = m.get('Selected')
        return self


class CreatePerformanceViewRequestViewDetailCategories(TeaModel):
    def __init__(
        self,
        category: str = None,
        keys: List[CreatePerformanceViewRequestViewDetailCategoriesKeys] = None,
    ):
        # The name of the metric category. Valid values:
        # 
        # *   **Node**\
        # *   **DiskData**\
        # *   **WorkLoad**\
        # *   **ResourceGroup**\
        self.category = category
        # The metrics.
        self.keys = keys

    def validate(self):
        if self.keys:
            for k in self.keys:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        result['Keys'] = []
        if self.keys is not None:
            for k in self.keys:
                result['Keys'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        self.keys = []
        if m.get('Keys') is not None:
            for k in m.get('Keys'):
                temp_model = CreatePerformanceViewRequestViewDetailCategoriesKeys()
                self.keys.append(temp_model.from_map(k))
        return self


class CreatePerformanceViewRequestViewDetail(TeaModel):
    def __init__(
        self,
        categories: List[CreatePerformanceViewRequestViewDetailCategories] = None,
        chart_linked: bool = None,
        charts_per_line: int = None,
    ):
        # The metric categories.
        self.categories = categories
        # Specifies whether to enable the filter interaction feature. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.chart_linked = chart_linked
        # The number of charts to display in each row.
        self.charts_per_line = charts_per_line

    def validate(self):
        if self.categories:
            for k in self.categories:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Categories'] = []
        if self.categories is not None:
            for k in self.categories:
                result['Categories'].append(k.to_map() if k else None)
        if self.chart_linked is not None:
            result['ChartLinked'] = self.chart_linked
        if self.charts_per_line is not None:
            result['ChartsPerLine'] = self.charts_per_line
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.categories = []
        if m.get('Categories') is not None:
            for k in m.get('Categories'):
                temp_model = CreatePerformanceViewRequestViewDetailCategories()
                self.categories.append(temp_model.from_map(k))
        if m.get('ChartLinked') is not None:
            self.chart_linked = m.get('ChartLinked')
        if m.get('ChartsPerLine') is not None:
            self.charts_per_line = m.get('ChartsPerLine')
        return self


class CreatePerformanceViewRequest(TeaModel):
    def __init__(
        self,
        create_from_view_type: str = None,
        dbcluster_id: str = None,
        fill_origin_view_keys: bool = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        view_detail: CreatePerformanceViewRequestViewDetail = None,
        view_name: str = None,
    ):
        # The type of the view.
        self.create_from_view_type = create_from_view_type
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to populate the names of the metrics in the original monitoring view when you view the monitoring view. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.fill_origin_view_keys = fill_origin_view_keys
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The information about the monitoring view.
        # 
        # This parameter is required.
        self.view_detail = view_detail
        # The name of the view.
        # 
        # This parameter is required.
        self.view_name = view_name

    def validate(self):
        if self.view_detail:
            self.view_detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_from_view_type is not None:
            result['CreateFromViewType'] = self.create_from_view_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.fill_origin_view_keys is not None:
            result['FillOriginViewKeys'] = self.fill_origin_view_keys
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.view_detail is not None:
            result['ViewDetail'] = self.view_detail.to_map()
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateFromViewType') is not None:
            self.create_from_view_type = m.get('CreateFromViewType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FillOriginViewKeys') is not None:
            self.fill_origin_view_keys = m.get('FillOriginViewKeys')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ViewDetail') is not None:
            temp_model = CreatePerformanceViewRequestViewDetail()
            self.view_detail = temp_model.from_map(m['ViewDetail'])
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class CreatePerformanceViewShrinkRequest(TeaModel):
    def __init__(
        self,
        create_from_view_type: str = None,
        dbcluster_id: str = None,
        fill_origin_view_keys: bool = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        view_detail_shrink: str = None,
        view_name: str = None,
    ):
        # The type of the view.
        self.create_from_view_type = create_from_view_type
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to populate the names of the metrics in the original monitoring view when you view the monitoring view. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.fill_origin_view_keys = fill_origin_view_keys
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The information about the monitoring view.
        # 
        # This parameter is required.
        self.view_detail_shrink = view_detail_shrink
        # The name of the view.
        # 
        # This parameter is required.
        self.view_name = view_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_from_view_type is not None:
            result['CreateFromViewType'] = self.create_from_view_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.fill_origin_view_keys is not None:
            result['FillOriginViewKeys'] = self.fill_origin_view_keys
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.view_detail_shrink is not None:
            result['ViewDetail'] = self.view_detail_shrink
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateFromViewType') is not None:
            self.create_from_view_type = m.get('CreateFromViewType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FillOriginViewKeys') is not None:
            self.fill_origin_view_keys = m.get('FillOriginViewKeys')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ViewDetail') is not None:
            self.view_detail_shrink = m.get('ViewDetail')
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class CreatePerformanceViewResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        create_status: str = None,
        request_id: str = None,
    ):
        # The details about the access denial.
        # 
        # >  This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The creation result. Valid values:
        # 
        # *   **SUCCESS**\
        # *   **FAILED**\
        self.create_status = create_status
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.create_status is not None:
            result['CreateStatus'] = self.create_status
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('CreateStatus') is not None:
            self.create_status = m.get('CreateStatus')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreatePerformanceViewResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreatePerformanceViewResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreatePerformanceViewResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateSparkTemplateRequest(TeaModel):
    def __init__(
        self,
        app_type: str = None,
        dbcluster_id: str = None,
        name: str = None,
        parent_id: int = None,
        type: str = None,
    ):
        # The application type. Valid values:
        # 
        # *   **SQL**\
        # *   **STREAMING**\
        # *   **BATCH**\
        # 
        # >  You do not need to specify this parameter when Type is set to folder.
        self.app_type = app_type
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the application template. The name can be up to 64 characters in length.
        # 
        # This parameter is required.
        self.name = name
        # The ID of the directory to which the application template belongs.
        # 
        # >  You can call the [GetSparkTemplateFolderTree](https://help.aliyun.com/document_detail/456218.html) operation to query the directory ID.
        # 
        # This parameter is required.
        self.parent_id = parent_id
        # The type of the application template. Valid values:
        # 
        # *   **folder**: directory.
        # *   **file**: application.
        # 
        # This parameter is required.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_type is not None:
            result['AppType'] = self.app_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.name is not None:
            result['Name'] = self.name
        if self.parent_id is not None:
            result['ParentId'] = self.parent_id
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppType') is not None:
            self.app_type = m.get('AppType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ParentId') is not None:
            self.parent_id = m.get('ParentId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class CreateSparkTemplateResponseBodyData(TeaModel):
    def __init__(
        self,
        succeeded: bool = None,
    ):
        # Indicates whether the application template is created. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.succeeded = succeeded

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.succeeded is not None:
            result['Succeeded'] = self.succeeded
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Succeeded') is not None:
            self.succeeded = m.get('Succeeded')
        return self


class CreateSparkTemplateResponseBody(TeaModel):
    def __init__(
        self,
        data: CreateSparkTemplateResponseBodyData = None,
        request_id: str = None,
    ):
        # The creation result.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = CreateSparkTemplateResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateSparkTemplateResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: CreateSparkTemplateResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateSparkTemplateResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteAccountRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The name of the database account.
        # 
        # >  You can call the [DescribeAccounts](https://help.aliyun.com/document_detail/612430.html) operation to query the information about database accounts for a cluster, including the account name.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class DeleteAccountResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteAccountResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteAccountResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteAccountResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteApsDatasoureRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        datasource_id: int = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        # 
        # This parameter is required.
        self.datasource_id = datasource_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DeleteApsDatasoureResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: str = None,
        message: str = None,
        request_id: str = None,
        success: str = None,
    ):
        # The response code.
        self.code = code
        # The returned data.
        self.data = data
        # The HTTP status code.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DeleteApsDatasoureResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteApsDatasoureResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteApsDatasoureResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteApsJobRequest(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        region_id: str = None,
    ):
        # The job ID.
        # 
        # This parameter is required.
        self.aps_job_id = aps_job_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DeleteApsJobResponseBody(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        code: str = None,
        err_code: str = None,
        err_message: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The HTTP status code or the error code.
        self.code = code
        # The error code returned when the request fails.
        self.err_code = err_code
        # The error code returned when the request fails.
        self.err_message = err_message
        # The HTTP status code.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful.
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.code is not None:
            result['Code'] = self.code
        if self.err_code is not None:
            result['ErrCode'] = self.err_code
        if self.err_message is not None:
            result['ErrMessage'] = self.err_message
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('ErrCode') is not None:
            self.err_code = m.get('ErrCode')
        if m.get('ErrMessage') is not None:
            self.err_message = m.get('ErrMessage')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DeleteApsJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteApsJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteApsJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteBackupsRequest(TeaModel):
    def __init__(
        self,
        backup_ids: str = None,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The ID of the backup set that you want to delete. Separate multiple backup set IDs with commas (,).
        # 
        # This parameter is required.
        self.backup_ids = backup_ids
        # The ID of the AnalyticDB for MySQL cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID of the cluster.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.backup_ids is not None:
            result['BackupIds'] = self.backup_ids
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BackupIds') is not None:
            self.backup_ids = m.get('BackupIds')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DeleteBackupsResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # Id of the request
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteBackupsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteBackupsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteBackupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteDBClusterRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DeleteDBClusterResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        request_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        self.dbcluster_id = dbcluster_id
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteDBClusterResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteDBClusterResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteDBClusterResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteDBResourceGroupRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        group_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        # 
        # >  You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/612410.html) operation to query the information about resource groups of an AnalyticDB for MySQL cluster, including resource group names.
        # 
        # This parameter is required.
        self.group_name = group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        return self


class DeleteDBResourceGroupResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteDBResourceGroupResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteDBResourceGroupResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteDBResourceGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteElasticPlanRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # >  You can call the [DescribeElasticPlans](https://help.aliyun.com/document_detail/601334.html) operation to query the names of scaling plans.
        # 
        # This parameter is required.
        self.elastic_plan_name = elastic_plan_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        return self


class DeleteElasticPlanResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteElasticPlanResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteElasticPlanResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteElasticPlanResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteLakeStorageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lake_storage_id: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster.
        self.dbcluster_id = dbcluster_id
        # The ID of the lake storage.
        # 
        # This parameter is required.
        self.lake_storage_id = lake_storage_id
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DeleteLakeStorageResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The response code. The status code 200 indicates that the request was successful. Other status codes indicate that the request failed.
        self.code = code
        # Indicates whether the delete operation was successful.
        self.data = data
        # The HTTP status code.
        self.http_status_code = http_status_code
        # The returned message. If the operation is asynchronously implemented, the job ID is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DeleteLakeStorageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteLakeStorageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteLakeStorageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeletePerformanceViewRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        view_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The name of the view.
        # 
        # This parameter is required.
        self.view_name = view_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class DeletePerformanceViewResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        delete_status: bool = None,
        request_id: str = None,
    ):
        # The details about the access denial.
        # 
        # >  This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The delete status.
        self.delete_status = delete_status
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.delete_status is not None:
            result['DeleteStatus'] = self.delete_status
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('DeleteStatus') is not None:
            self.delete_status = m.get('DeleteStatus')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeletePerformanceViewResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeletePerformanceViewResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeletePerformanceViewResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteSparkTemplateRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        id: int = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The directory ID or application ID of the template files that you want to delete.
        # 
        # > 
        # 
        # *   You can call the [GetSparkTemplateFullTree](https://help.aliyun.com/document_detail/612467.html) operation to query the directory ID or application ID.
        # 
        # *   When you specify a directory ID, the directory and all template files that are included in the directory are deleted.
        # 
        # This parameter is required.
        self.id = id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.id is not None:
            result['Id'] = self.id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        return self


class DeleteSparkTemplateResponseBodyData(TeaModel):
    def __init__(
        self,
        succeeded: bool = None,
    ):
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.succeeded = succeeded

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.succeeded is not None:
            result['Succeeded'] = self.succeeded
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Succeeded') is not None:
            self.succeeded = m.get('Succeeded')
        return self


class DeleteSparkTemplateResponseBody(TeaModel):
    def __init__(
        self,
        data: DeleteSparkTemplateResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned result.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DeleteSparkTemplateResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteSparkTemplateResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteSparkTemplateResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteSparkTemplateResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteSparkTemplateFileRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        id: int = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the template file to be deleted.
        # 
        # >  You can call the [GetSparkTemplateFullTree](https://help.aliyun.com/document_detail/456205.html) operation to query all template file IDs.
        # 
        # This parameter is required.
        self.id = id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.id is not None:
            result['Id'] = self.id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        return self


class DeleteSparkTemplateFileResponseBodyData(TeaModel):
    def __init__(
        self,
        succeeded: bool = None,
    ):
        # Indicates whether the template file is deleted. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.succeeded = succeeded

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.succeeded is not None:
            result['Succeeded'] = self.succeeded
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Succeeded') is not None:
            self.succeeded = m.get('Succeeded')
        return self


class DeleteSparkTemplateFileResponseBody(TeaModel):
    def __init__(
        self,
        data: DeleteSparkTemplateFileResponseBodyData = None,
        request_id: str = None,
    ):
        # The deletion result.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DeleteSparkTemplateFileResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteSparkTemplateFileResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DeleteSparkTemplateFileResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteSparkTemplateFileResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAPSADBInstancesRequest(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
    ):
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        # 
        # This parameter is required.
        self.page_size = page_size
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeAPSADBInstancesResponseBodyItems(TeaModel):
    def __init__(
        self,
        compute_resource: str = None,
        dbcluster_description: str = None,
        dbcluster_id: str = None,
        dbcluster_status: str = None,
        reserved_acu: str = None,
        storage_resource: int = None,
        zone_id: str = None,
    ):
        # The specifications of the reserved computing resources.
        self.compute_resource = compute_resource
        # The description of the cluster.
        self.dbcluster_description = dbcluster_description
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The status of the cluster.
        self.dbcluster_status = dbcluster_status
        # The amount of remaining reserved computing resources that are available in the cluster.
        self.reserved_acu = reserved_acu
        # The specifications of the reserved storage resources.
        self.storage_resource = storage_resource
        # The zone ID of the cluster.
        self.zone_id = zone_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.compute_resource is not None:
            result['ComputeResource'] = self.compute_resource
        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.dbcluster_status is not None:
            result['DBClusterStatus'] = self.dbcluster_status
        if self.reserved_acu is not None:
            result['ReservedACU'] = self.reserved_acu
        if self.storage_resource is not None:
            result['StorageResource'] = self.storage_resource
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ComputeResource') is not None:
            self.compute_resource = m.get('ComputeResource')
        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DBClusterStatus') is not None:
            self.dbcluster_status = m.get('DBClusterStatus')
        if m.get('ReservedACU') is not None:
            self.reserved_acu = m.get('ReservedACU')
        if m.get('StorageResource') is not None:
            self.storage_resource = m.get('StorageResource')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class DescribeAPSADBInstancesResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        http_status_code: int = None,
        items: List[DescribeAPSADBInstancesResponseBodyItems] = None,
        message: str = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        success: bool = None,
        total_count: str = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The HTTP status code.
        self.http_status_code = http_status_code
        # The queried clusters.
        self.items = items
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeAPSADBInstancesResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAPSADBInstancesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAPSADBInstancesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAPSADBInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAbnormalPatternDetectionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.end_time = end_time
        # The language. Valid values:
        # 
        # *   **zh** (default): simplified Chinese.
        # *   **en**: English.
        self.lang = lang
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeAbnormalPatternDetectionResponseBodyDetectionItemsResults(TeaModel):
    def __init__(
        self,
        access_ip: str = None,
        detail: str = None,
        failed_count: int = None,
        pattern_id: str = None,
        query_count: int = None,
        related_metrics: str = None,
        sqlpattern: str = None,
        tables: str = None,
        user: str = None,
    ):
        # The IP address of the SQL client that submits the SQL pattern.
        self.access_ip = access_ip
        # The description of the detection result.
        self.detail = detail
        # The number of failed SQL patterns within the time range.
        self.failed_count = failed_count
        # The SQL pattern ID.
        self.pattern_id = pattern_id
        # The number of queries.
        self.query_count = query_count
        # The metrics related to the SQL pattern.
        self.related_metrics = related_metrics
        # The SQL statement that represents the SQL pattern.
        self.sqlpattern = sqlpattern
        # The names of tables.
        self.tables = tables
        # The name of the database account that is used to submit the query.
        self.user = user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_ip is not None:
            result['AccessIp'] = self.access_ip
        if self.detail is not None:
            result['Detail'] = self.detail
        if self.failed_count is not None:
            result['FailedCount'] = self.failed_count
        if self.pattern_id is not None:
            result['PatternId'] = self.pattern_id
        if self.query_count is not None:
            result['QueryCount'] = self.query_count
        if self.related_metrics is not None:
            result['RelatedMetrics'] = self.related_metrics
        if self.sqlpattern is not None:
            result['SQLPattern'] = self.sqlpattern
        if self.tables is not None:
            result['Tables'] = self.tables
        if self.user is not None:
            result['User'] = self.user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessIp') is not None:
            self.access_ip = m.get('AccessIp')
        if m.get('Detail') is not None:
            self.detail = m.get('Detail')
        if m.get('FailedCount') is not None:
            self.failed_count = m.get('FailedCount')
        if m.get('PatternId') is not None:
            self.pattern_id = m.get('PatternId')
        if m.get('QueryCount') is not None:
            self.query_count = m.get('QueryCount')
        if m.get('RelatedMetrics') is not None:
            self.related_metrics = m.get('RelatedMetrics')
        if m.get('SQLPattern') is not None:
            self.sqlpattern = m.get('SQLPattern')
        if m.get('Tables') is not None:
            self.tables = m.get('Tables')
        if m.get('User') is not None:
            self.user = m.get('User')
        return self


class DescribeAbnormalPatternDetectionResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        name: str = None,
        results: List[DescribeAbnormalPatternDetectionResponseBodyDetectionItemsResults] = None,
    ):
        # The name of the detection item.
        self.name = name
        # The detection result items.
        self.results = results

    def validate(self):
        if self.results:
            for k in self.results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        result['Results'] = []
        if self.results is not None:
            for k in self.results:
                result['Results'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        self.results = []
        if m.get('Results') is not None:
            for k in m.get('Results'):
                temp_model = DescribeAbnormalPatternDetectionResponseBodyDetectionItemsResults()
                self.results.append(temp_model.from_map(k))
        return self


class DescribeAbnormalPatternDetectionResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        detection_items: List[DescribeAbnormalPatternDetectionResponseBodyDetectionItems] = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeAbnormalPatternDetectionResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAbnormalPatternDetectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAbnormalPatternDetectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAbnormalPatternDetectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAccountAllPrivilegesRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        dbcluster_id: str = None,
        marker: str = None,
        region_id: str = None,
    ):
        # The name of the database account.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies the start position marker from which to return results. If you receive a response indicating that the results are truncated, set this parameter to the value of the `Marker` parameter in the response that you received.
        self.marker = marker
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.marker is not None:
            result['Marker'] = self.marker
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Marker') is not None:
            self.marker = m.get('Marker')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeAccountAllPrivilegesResponseBodyDataResultPrivilegeObject(TeaModel):
    def __init__(
        self,
        column: str = None,
        database: str = None,
        description: str = None,
        table: str = None,
    ):
        # The name of the column.
        self.column = column
        # The name of the database.
        self.database = database
        # The description of the permission object.
        self.description = description
        # The name of the table.
        self.table = table

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column is not None:
            result['Column'] = self.column
        if self.database is not None:
            result['Database'] = self.database
        if self.description is not None:
            result['Description'] = self.description
        if self.table is not None:
            result['Table'] = self.table
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Column') is not None:
            self.column = m.get('Column')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Table') is not None:
            self.table = m.get('Table')
        return self


class DescribeAccountAllPrivilegesResponseBodyDataResult(TeaModel):
    def __init__(
        self,
        privilege_object: DescribeAccountAllPrivilegesResponseBodyDataResultPrivilegeObject = None,
        privilege_type: str = None,
        privileges: List[str] = None,
    ):
        # The objects on which the permission takes effect, including databases, tables, and columns. If Global is returned for the PrivilegeType parameter, an empty string is returned for this parameter.
        self.privilege_object = privilege_object
        # The permission level of the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.
        self.privilege_type = privilege_type
        # The name of the permission, which is the same as the permission name returned by the `DescribeEnabledPrivileges` operation.
        self.privileges = privileges

    def validate(self):
        if self.privilege_object:
            self.privilege_object.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.privilege_object is not None:
            result['PrivilegeObject'] = self.privilege_object.to_map()
        if self.privilege_type is not None:
            result['PrivilegeType'] = self.privilege_type
        if self.privileges is not None:
            result['Privileges'] = self.privileges
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PrivilegeObject') is not None:
            temp_model = DescribeAccountAllPrivilegesResponseBodyDataResultPrivilegeObject()
            self.privilege_object = temp_model.from_map(m['PrivilegeObject'])
        if m.get('PrivilegeType') is not None:
            self.privilege_type = m.get('PrivilegeType')
        if m.get('Privileges') is not None:
            self.privileges = m.get('Privileges')
        return self


class DescribeAccountAllPrivilegesResponseBodyData(TeaModel):
    def __init__(
        self,
        marker: str = None,
        result: List[DescribeAccountAllPrivilegesResponseBodyDataResult] = None,
        truncated: bool = None,
    ):
        # Indicates the position where the results are truncated. When a value of `true` is returned for the `Truncated` parameter, this parameter is present and contains the value to use for the Marker parameter in a subsequent call.
        self.marker = marker
        # The permissions.
        self.result = result
        # Indicates whether the results are truncated. If the results are truncated, a value of `true` is returned. In this case, you must call this operation again to obtain all the results until a value of `false` is returned for this parameter.
        self.truncated = truncated

    def validate(self):
        if self.result:
            for k in self.result:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.marker is not None:
            result['Marker'] = self.marker
        result['Result'] = []
        if self.result is not None:
            for k in self.result:
                result['Result'].append(k.to_map() if k else None)
        if self.truncated is not None:
            result['Truncated'] = self.truncated
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Marker') is not None:
            self.marker = m.get('Marker')
        self.result = []
        if m.get('Result') is not None:
            for k in m.get('Result'):
                temp_model = DescribeAccountAllPrivilegesResponseBodyDataResult()
                self.result.append(temp_model.from_map(k))
        if m.get('Truncated') is not None:
            self.truncated = m.get('Truncated')
        return self


class DescribeAccountAllPrivilegesResponseBody(TeaModel):
    def __init__(
        self,
        data: DescribeAccountAllPrivilegesResponseBodyData = None,
        request_id: str = None,
    ):
        # Details of the permissions.
        self.data = data
        # The ID of the request.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DescribeAccountAllPrivilegesResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeAccountAllPrivilegesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAccountAllPrivilegesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAccountAllPrivilegesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAccountPrivilegeObjectsRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        column_privilege_object: str = None,
        dbcluster_id: str = None,
        database_privilege_object: str = None,
        page_number: str = None,
        page_size: str = None,
        privilege_type: str = None,
        region_id: str = None,
        table_privilege_object: str = None,
    ):
        # The name of the database account.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The column name that is used to filter columns.
        self.column_privilege_object = column_privilege_object
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database name that is used to filter databases.
        self.database_privilege_object = database_privilege_object
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Default value: 20.
        self.page_size = page_size
        # The permission level. Valid values: Database, Table, and Column. Global is not supported.
        self.privilege_type = privilege_type
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The table name that is used to filter tables.
        self.table_privilege_object = table_privilege_object

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.column_privilege_object is not None:
            result['ColumnPrivilegeObject'] = self.column_privilege_object
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database_privilege_object is not None:
            result['DatabasePrivilegeObject'] = self.database_privilege_object
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.privilege_type is not None:
            result['PrivilegeType'] = self.privilege_type
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.table_privilege_object is not None:
            result['TablePrivilegeObject'] = self.table_privilege_object
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('ColumnPrivilegeObject') is not None:
            self.column_privilege_object = m.get('ColumnPrivilegeObject')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabasePrivilegeObject') is not None:
            self.database_privilege_object = m.get('DatabasePrivilegeObject')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('PrivilegeType') is not None:
            self.privilege_type = m.get('PrivilegeType')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('TablePrivilegeObject') is not None:
            self.table_privilege_object = m.get('TablePrivilegeObject')
        return self


class DescribeAccountPrivilegeObjectsResponseBodyData(TeaModel):
    def __init__(
        self,
        column: str = None,
        database: str = None,
        description: str = None,
        table: str = None,
    ):
        # The name of the column. This parameter is returned when PrivilegeType is set to Column.
        self.column = column
        # The name of the database. This parameter is returned when PrivilegeType is set to Database, Table, or Column.
        self.database = database
        # The description that is specified when you create a table or column. This parameter is returned only when PrivilegeType is set to Database or Table, indicating the database description or table description.
        self.description = description
        # The name of the table. This parameter is returned when PrivilegeType is set to Table or Column.
        self.table = table

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column is not None:
            result['Column'] = self.column
        if self.database is not None:
            result['Database'] = self.database
        if self.description is not None:
            result['Description'] = self.description
        if self.table is not None:
            result['Table'] = self.table
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Column') is not None:
            self.column = m.get('Column')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Table') is not None:
            self.table = m.get('Table')
        return self


class DescribeAccountPrivilegeObjectsResponseBody(TeaModel):
    def __init__(
        self,
        data: List[DescribeAccountPrivilegeObjectsResponseBodyData] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The permissions.
        self.data = data
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            for k in self.data:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Data'] = []
        if self.data is not None:
            for k in self.data:
                result['Data'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.data = []
        if m.get('Data') is not None:
            for k in m.get('Data'):
                temp_model = DescribeAccountPrivilegeObjectsResponseBodyData()
                self.data.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAccountPrivilegeObjectsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAccountPrivilegeObjectsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAccountPrivilegeObjectsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAccountPrivilegesRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        column_privilege_object: str = None,
        dbcluster_id: str = None,
        database_privilege_object: str = None,
        page_number: str = None,
        page_size: str = None,
        privilege_type: str = None,
        region_id: str = None,
        table_privilege_object: str = None,
    ):
        # The name of the database account.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The columns that you want to query. You can use this parameter to query the permissions of the database account on specific columns. This parameter is available only if the PrivilegeType parameter is set to Column.
        self.column_privilege_object = column_privilege_object
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The databases that you want to query. You can use this parameter to query the permissions of the database account on specific databases. This parameter is available only if the PrivilegeType parameter is set to Database, Table, or Column.
        self.database_privilege_object = database_privilege_object
        # The number of the page to return. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries to return on each page. Default value: 20.
        self.page_size = page_size
        # The permission level that you want to query. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.
        self.privilege_type = privilege_type
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The tables that you want to query. You can use this parameter to query the permissions of the database account on specific tables. This parameter can be used together with the DatabasePrivilegeObject parameter. This parameter is available only if the PrivilegeType parameter is set to Table or Column.
        self.table_privilege_object = table_privilege_object

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.column_privilege_object is not None:
            result['ColumnPrivilegeObject'] = self.column_privilege_object
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database_privilege_object is not None:
            result['DatabasePrivilegeObject'] = self.database_privilege_object
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.privilege_type is not None:
            result['PrivilegeType'] = self.privilege_type
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.table_privilege_object is not None:
            result['TablePrivilegeObject'] = self.table_privilege_object
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('ColumnPrivilegeObject') is not None:
            self.column_privilege_object = m.get('ColumnPrivilegeObject')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabasePrivilegeObject') is not None:
            self.database_privilege_object = m.get('DatabasePrivilegeObject')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('PrivilegeType') is not None:
            self.privilege_type = m.get('PrivilegeType')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('TablePrivilegeObject') is not None:
            self.table_privilege_object = m.get('TablePrivilegeObject')
        return self


class DescribeAccountPrivilegesResponseBodyDataPrivilegeObject(TeaModel):
    def __init__(
        self,
        column: str = None,
        database: str = None,
        description: str = None,
        table: str = None,
    ):
        # The name of the column.
        self.column = column
        # The name of the database.
        self.database = database
        # The description of the permission object.
        self.description = description
        # The name of the table.
        self.table = table

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column is not None:
            result['Column'] = self.column
        if self.database is not None:
            result['Database'] = self.database
        if self.description is not None:
            result['Description'] = self.description
        if self.table is not None:
            result['Table'] = self.table
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Column') is not None:
            self.column = m.get('Column')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Table') is not None:
            self.table = m.get('Table')
        return self


class DescribeAccountPrivilegesResponseBodyData(TeaModel):
    def __init__(
        self,
        privilege_object: DescribeAccountPrivilegesResponseBodyDataPrivilegeObject = None,
        privilege_type: str = None,
        privileges: List[str] = None,
    ):
        # The objects on which the permission takes effect, including databases, tables, columns, and additional descriptions.
        self.privilege_object = privilege_object
        # The permission level of the permission. Valid values: `Global`, `Database`, `Table`, and `Column`. You can call the `DescribeEnabledPrivileges` parameter to query the permission level of a specific permission.
        self.privilege_type = privilege_type
        # The name of the permission. You can call the `DescribeEnabledPrivileges` operation to query the name of the permission.
        self.privileges = privileges

    def validate(self):
        if self.privilege_object:
            self.privilege_object.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.privilege_object is not None:
            result['PrivilegeObject'] = self.privilege_object.to_map()
        if self.privilege_type is not None:
            result['PrivilegeType'] = self.privilege_type
        if self.privileges is not None:
            result['Privileges'] = self.privileges
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PrivilegeObject') is not None:
            temp_model = DescribeAccountPrivilegesResponseBodyDataPrivilegeObject()
            self.privilege_object = temp_model.from_map(m['PrivilegeObject'])
        if m.get('PrivilegeType') is not None:
            self.privilege_type = m.get('PrivilegeType')
        if m.get('Privileges') is not None:
            self.privileges = m.get('Privileges')
        return self


class DescribeAccountPrivilegesResponseBody(TeaModel):
    def __init__(
        self,
        data: List[DescribeAccountPrivilegesResponseBodyData] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # Details of the permissions.
        self.data = data
        # The page number of the returned page.
        self.page_number = page_number
        # The number of entries returned per page.
        self.page_size = page_size
        # The ID of the request.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            for k in self.data:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Data'] = []
        if self.data is not None:
            for k in self.data:
                result['Data'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.data = []
        if m.get('Data') is not None:
            for k in m.get('Data'):
                temp_model = DescribeAccountPrivilegesResponseBodyData()
                self.data.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAccountPrivilegesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAccountPrivilegesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAccountPrivilegesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAccountsRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        dbcluster_id: str = None,
        engine: str = None,
        owner_id: str = None,
    ):
        # The name of the database account.
        # 
        # > If you do not specify this parameter, the information about all database accounts in the cluster is returned.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine
        self.owner_id = owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        return self


class DescribeAccountsResponseBodyAccountListDBAccount(TeaModel):
    def __init__(
        self,
        account_description: str = None,
        account_name: str = None,
        account_status: str = None,
        account_type: str = None,
        engine: str = None,
        ram_users: str = None,
    ):
        # The description of the database account.
        self.account_description = account_description
        # The name of the database account.
        self.account_name = account_name
        # The status of the database account. Valid values:
        # 
        # *   **Creating**\
        # *   **Available**\
        # *   **Deleting**\
        self.account_status = account_status
        # The type of the database account. Valid values:
        # 
        # *   **Normal**: standard account.
        # *   **Super**: privileged account.
        self.account_type = account_type
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB**: the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine
        # The ID of the Resource Access Management (RAM) user.
        self.ram_users = ram_users

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_description is not None:
            result['AccountDescription'] = self.account_description
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.account_status is not None:
            result['AccountStatus'] = self.account_status
        if self.account_type is not None:
            result['AccountType'] = self.account_type
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.ram_users is not None:
            result['RamUsers'] = self.ram_users
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountDescription') is not None:
            self.account_description = m.get('AccountDescription')
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('AccountStatus') is not None:
            self.account_status = m.get('AccountStatus')
        if m.get('AccountType') is not None:
            self.account_type = m.get('AccountType')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('RamUsers') is not None:
            self.ram_users = m.get('RamUsers')
        return self


class DescribeAccountsResponseBodyAccountList(TeaModel):
    def __init__(
        self,
        dbaccount: List[DescribeAccountsResponseBodyAccountListDBAccount] = None,
    ):
        self.dbaccount = dbaccount

    def validate(self):
        if self.dbaccount:
            for k in self.dbaccount:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['DBAccount'] = []
        if self.dbaccount is not None:
            for k in self.dbaccount:
                result['DBAccount'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.dbaccount = []
        if m.get('DBAccount') is not None:
            for k in m.get('DBAccount'):
                temp_model = DescribeAccountsResponseBodyAccountListDBAccount()
                self.dbaccount.append(temp_model.from_map(k))
        return self


class DescribeAccountsResponseBody(TeaModel):
    def __init__(
        self,
        account_list: DescribeAccountsResponseBodyAccountList = None,
        request_id: str = None,
    ):
        # The queried database accounts.
        self.account_list = account_list
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.account_list:
            self.account_list.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_list is not None:
            result['AccountList'] = self.account_list.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountList') is not None:
            temp_model = DescribeAccountsResponseBodyAccountList()
            self.account_list = temp_model.from_map(m['AccountList'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeAccountsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAccountsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAccountsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAdbMySqlColumnsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema = schema
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAdbMySqlColumnsResponseBodyColumns(TeaModel):
    def __init__(
        self,
        comment: str = None,
        name: str = None,
        type: str = None,
    ):
        # The comments of the column.
        self.comment = comment
        # The name of the column.
        self.name = name
        # The data type of the column.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.comment is not None:
            result['Comment'] = self.comment
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Comment') is not None:
            self.comment = m.get('Comment')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeAdbMySqlColumnsResponseBody(TeaModel):
    def __init__(
        self,
        column_count: int = None,
        columns: List[DescribeAdbMySqlColumnsResponseBodyColumns] = None,
        message: str = None,
        request_id: str = None,
        schema: str = None,
        success: bool = None,
        table_name: str = None,
    ):
        # The total number of columns.
        self.column_count = column_count
        # Details of the columns.
        self.columns = columns
        # The message returned for the operation. Valid values:
        # 
        # *   **Success** is returned if the operation is successful.
        # *   An error message is returned if the operation fails.
        self.message = message
        # The ID of the request.
        self.request_id = request_id
        # The name of the database.
        self.schema = schema
        # Indicates whether the operation is successful. Valid values:
        # 
        # *   **true**: The operation is successful.
        # *   **false**: The operation fails.
        self.success = success
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        if self.columns:
            for k in self.columns:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column_count is not None:
            result['ColumnCount'] = self.column_count
        result['Columns'] = []
        if self.columns is not None:
            for k in self.columns:
                result['Columns'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.success is not None:
            result['Success'] = self.success
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColumnCount') is not None:
            self.column_count = m.get('ColumnCount')
        self.columns = []
        if m.get('Columns') is not None:
            for k in m.get('Columns'):
                temp_model = DescribeAdbMySqlColumnsResponseBodyColumns()
                self.columns.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAdbMySqlColumnsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAdbMySqlColumnsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAdbMySqlColumnsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAdbMySqlIndexesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema: str = None,
        table_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema = schema
        # The name of the table.
        # 
        # >  If you leave this parameter empty, the information about all the current tables in the cluster is returned.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAdbMySqlIndexesResponseBodyIndexes(TeaModel):
    def __init__(
        self,
        column: str = None,
        name: str = None,
        type: str = None,
    ):
        # The name of the column.
        self.column = column
        # The name of the index.
        self.name = name
        # The index type.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column is not None:
            result['Column'] = self.column
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Column') is not None:
            self.column = m.get('Column')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeAdbMySqlIndexesResponseBody(TeaModel):
    def __init__(
        self,
        index_count: int = None,
        indexes: List[DescribeAdbMySqlIndexesResponseBodyIndexes] = None,
        message: str = None,
        request_id: str = None,
        schema: str = None,
        success: bool = None,
        table_name: str = None,
    ):
        # The number of indexes.````
        self.index_count = index_count
        # The queried indexes.
        self.indexes = indexes
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # The name of the database.
        # 
        # **\
        # 
        # ****\\
        self.schema = schema
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        if self.indexes:
            for k in self.indexes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.index_count is not None:
            result['IndexCount'] = self.index_count
        result['Indexes'] = []
        if self.indexes is not None:
            for k in self.indexes:
                result['Indexes'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.success is not None:
            result['Success'] = self.success
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('IndexCount') is not None:
            self.index_count = m.get('IndexCount')
        self.indexes = []
        if m.get('Indexes') is not None:
            for k in m.get('Indexes'):
                temp_model = DescribeAdbMySqlIndexesResponseBodyIndexes()
                self.indexes.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAdbMySqlIndexesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAdbMySqlIndexesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAdbMySqlIndexesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAdbMySqlSchemasRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeAdbMySqlSchemasResponseBody(TeaModel):
    def __init__(
        self,
        message: str = None,
        request_id: str = None,
        schemas: List[str] = None,
        success: bool = None,
    ):
        # The returned message.
        # 
        # *   If the request was successful, a **success** message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # The queried databases.
        self.schemas = schemas
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schemas is not None:
            result['Schemas'] = self.schemas
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Schemas') is not None:
            self.schemas = m.get('Schemas')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DescribeAdbMySqlSchemasResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAdbMySqlSchemasResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAdbMySqlSchemasResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAdbMySqlTableMetaRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        # 
        # This parameter is required.
        self.schema = schema
        # The name of the table.
        # 
        # >  If you leave this parameter empty, the information about all the current tables in the cluster is returned.
        # 
        # This parameter is required.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAdbMySqlTableMetaResponseBodyTableMeta(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        distribute_column: str = None,
        distribute_type: str = None,
        is_all_index: bool = None,
        is_dict_encode: bool = None,
        is_full_text_dict: bool = None,
        is_hidden: bool = None,
        partition_column: str = None,
        partition_type: str = None,
        primary_key_column: str = None,
        table_engine: str = None,
        table_name: str = None,
        table_schema: str = None,
        table_type: str = None,
        update_time: str = None,
    ):
        # The time when the table was created.
        self.create_time = create_time
        # The distribution key column.
        self.distribute_column = distribute_column
        # The distribution type.
        self.distribute_type = distribute_type
        # Indicates whether full-column indexes are used.
        self.is_all_index = is_all_index
        # Indicates whether dictionary encoding is used.
        self.is_dict_encode = is_dict_encode
        # Indicates whether full-text indexes are used.
        self.is_full_text_dict = is_full_text_dict
        # Indicates whether pages are hidden.
        # 
        # *   **false**\
        # *   **true**\
        self.is_hidden = is_hidden
        # The partition key column.
        self.partition_column = partition_column
        # The type of the partition.
        self.partition_type = partition_type
        # The primary key column.
        self.primary_key_column = primary_key_column
        # The table engine.
        self.table_engine = table_engine
        # The name of the table.
        # 
        # **\
        # 
        # ****\
        self.table_name = table_name
        # The database to which the table belongs.
        self.table_schema = table_schema
        # The type of the table.
        self.table_type = table_type
        # The time when the table was updated.
        self.update_time = update_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.distribute_column is not None:
            result['DistributeColumn'] = self.distribute_column
        if self.distribute_type is not None:
            result['DistributeType'] = self.distribute_type
        if self.is_all_index is not None:
            result['IsAllIndex'] = self.is_all_index
        if self.is_dict_encode is not None:
            result['IsDictEncode'] = self.is_dict_encode
        if self.is_full_text_dict is not None:
            result['IsFullTextDict'] = self.is_full_text_dict
        if self.is_hidden is not None:
            result['IsHidden'] = self.is_hidden
        if self.partition_column is not None:
            result['PartitionColumn'] = self.partition_column
        if self.partition_type is not None:
            result['PartitionType'] = self.partition_type
        if self.primary_key_column is not None:
            result['PrimaryKeyColumn'] = self.primary_key_column
        if self.table_engine is not None:
            result['TableEngine'] = self.table_engine
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.table_schema is not None:
            result['TableSchema'] = self.table_schema
        if self.table_type is not None:
            result['TableType'] = self.table_type
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DistributeColumn') is not None:
            self.distribute_column = m.get('DistributeColumn')
        if m.get('DistributeType') is not None:
            self.distribute_type = m.get('DistributeType')
        if m.get('IsAllIndex') is not None:
            self.is_all_index = m.get('IsAllIndex')
        if m.get('IsDictEncode') is not None:
            self.is_dict_encode = m.get('IsDictEncode')
        if m.get('IsFullTextDict') is not None:
            self.is_full_text_dict = m.get('IsFullTextDict')
        if m.get('IsHidden') is not None:
            self.is_hidden = m.get('IsHidden')
        if m.get('PartitionColumn') is not None:
            self.partition_column = m.get('PartitionColumn')
        if m.get('PartitionType') is not None:
            self.partition_type = m.get('PartitionType')
        if m.get('PrimaryKeyColumn') is not None:
            self.primary_key_column = m.get('PrimaryKeyColumn')
        if m.get('TableEngine') is not None:
            self.table_engine = m.get('TableEngine')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TableSchema') is not None:
            self.table_schema = m.get('TableSchema')
        if m.get('TableType') is not None:
            self.table_type = m.get('TableType')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class DescribeAdbMySqlTableMetaResponseBody(TeaModel):
    def __init__(
        self,
        message: str = None,
        request_id: str = None,
        success: bool = None,
        table_meta: DescribeAdbMySqlTableMetaResponseBodyTableMeta = None,
    ):
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The queried table metadata.
        self.table_meta = table_meta

    def validate(self):
        if self.table_meta:
            self.table_meta.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.table_meta is not None:
            result['TableMeta'] = self.table_meta.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TableMeta') is not None:
            temp_model = DescribeAdbMySqlTableMetaResponseBodyTableMeta()
            self.table_meta = temp_model.from_map(m['TableMeta'])
        return self


class DescribeAdbMySqlTableMetaResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAdbMySqlTableMetaResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAdbMySqlTableMetaResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAdbMySqlTablesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema = schema

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema is not None:
            result['Schema'] = self.schema
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        return self


class DescribeAdbMySqlTablesResponseBody(TeaModel):
    def __init__(
        self,
        message: str = None,
        request_id: str = None,
        schema: str = None,
        success: bool = None,
        tables: List[str] = None,
    ):
        # The message returned for the operation. Valid values:
        # 
        # *   **Success** is returned if the operation is successful.
        # *   An error message is returned if the operation fails.
        self.message = message
        # The ID of the request.
        self.request_id = request_id
        # The name of the database.
        self.schema = schema
        # Indicates whether the operation is successful. Valid values:
        # 
        # *   **true**: The operation is successful.
        # *   **false**: The operation fails.
        self.success = success
        # The names of tables.
        self.tables = tables

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.success is not None:
            result['Success'] = self.success
        if self.tables is not None:
            result['Tables'] = self.tables
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('Tables') is not None:
            self.tables = m.get('Tables')
        return self


class DescribeAdbMySqlTablesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAdbMySqlTablesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAdbMySqlTablesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAdviceServiceEnabledRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeAdviceServiceEnabledResponseBody(TeaModel):
    def __init__(
        self,
        message: str = None,
        request_id: str = None,
        result: bool = None,
    ):
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a **Success** message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the suggestion feature is enabled. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.result = result

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.result is not None:
            result['Result'] = self.result
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Result') is not None:
            self.result = m.get('Result')
        return self


class DescribeAdviceServiceEnabledResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAdviceServiceEnabledResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAdviceServiceEnabledResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAllDataSourceRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAllDataSourceResponseBodyColumnsColumn(TeaModel):
    def __init__(
        self,
        auto_increment_column: bool = None,
        column_name: str = None,
        dbcluster_id: str = None,
        primary_key: bool = None,
        schema_name: str = None,
        table_name: str = None,
        type: str = None,
    ):
        # Indicates whether the column is an auto-increment column. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.auto_increment_column = auto_increment_column
        # The name of the column.
        self.column_name = column_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # Indicates whether the column is the primary key of the table. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.primary_key = primary_key
        # The logical name of the database.
        self.schema_name = schema_name
        # The logical name of the table.
        self.table_name = table_name
        # The data type of the column.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_increment_column is not None:
            result['AutoIncrementColumn'] = self.auto_increment_column
        if self.column_name is not None:
            result['ColumnName'] = self.column_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.primary_key is not None:
            result['PrimaryKey'] = self.primary_key
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoIncrementColumn') is not None:
            self.auto_increment_column = m.get('AutoIncrementColumn')
        if m.get('ColumnName') is not None:
            self.column_name = m.get('ColumnName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PrimaryKey') is not None:
            self.primary_key = m.get('PrimaryKey')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeAllDataSourceResponseBodyColumns(TeaModel):
    def __init__(
        self,
        column: List[DescribeAllDataSourceResponseBodyColumnsColumn] = None,
    ):
        self.column = column

    def validate(self):
        if self.column:
            for k in self.column:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Column'] = []
        if self.column is not None:
            for k in self.column:
                result['Column'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.column = []
        if m.get('Column') is not None:
            for k in m.get('Column'):
                temp_model = DescribeAllDataSourceResponseBodyColumnsColumn()
                self.column.append(temp_model.from_map(k))
        return self


class DescribeAllDataSourceResponseBodySchemasSchema(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        schema_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The logical name of the database.
        self.schema_name = schema_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        return self


class DescribeAllDataSourceResponseBodySchemas(TeaModel):
    def __init__(
        self,
        schema: List[DescribeAllDataSourceResponseBodySchemasSchema] = None,
    ):
        self.schema = schema

    def validate(self):
        if self.schema:
            for k in self.schema:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Schema'] = []
        if self.schema is not None:
            for k in self.schema:
                result['Schema'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.schema = []
        if m.get('Schema') is not None:
            for k in m.get('Schema'):
                temp_model = DescribeAllDataSourceResponseBodySchemasSchema()
                self.schema.append(temp_model.from_map(k))
        return self


class DescribeAllDataSourceResponseBodyTablesTable(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The name of the database.
        self.schema_name = schema_name
        # The logical name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeAllDataSourceResponseBodyTables(TeaModel):
    def __init__(
        self,
        table: List[DescribeAllDataSourceResponseBodyTablesTable] = None,
    ):
        self.table = table

    def validate(self):
        if self.table:
            for k in self.table:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Table'] = []
        if self.table is not None:
            for k in self.table:
                result['Table'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.table = []
        if m.get('Table') is not None:
            for k in m.get('Table'):
                temp_model = DescribeAllDataSourceResponseBodyTablesTable()
                self.table.append(temp_model.from_map(k))
        return self


class DescribeAllDataSourceResponseBody(TeaModel):
    def __init__(
        self,
        columns: DescribeAllDataSourceResponseBodyColumns = None,
        request_id: str = None,
        schemas: DescribeAllDataSourceResponseBodySchemas = None,
        tables: DescribeAllDataSourceResponseBodyTables = None,
    ):
        # The queried columns.
        self.columns = columns
        # The request ID.
        self.request_id = request_id
        # The queried databases.
        self.schemas = schemas
        # The queried tables.
        self.tables = tables

    def validate(self):
        if self.columns:
            self.columns.validate()
        if self.schemas:
            self.schemas.validate()
        if self.tables:
            self.tables.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.columns is not None:
            result['Columns'] = self.columns.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schemas is not None:
            result['Schemas'] = self.schemas.to_map()
        if self.tables is not None:
            result['Tables'] = self.tables.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Columns') is not None:
            temp_model = DescribeAllDataSourceResponseBodyColumns()
            self.columns = temp_model.from_map(m['Columns'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Schemas') is not None:
            temp_model = DescribeAllDataSourceResponseBodySchemas()
            self.schemas = temp_model.from_map(m['Schemas'])
        if m.get('Tables') is not None:
            temp_model = DescribeAllDataSourceResponseBodyTables()
            self.tables = temp_model.from_map(m['Tables'])
        return self


class DescribeAllDataSourceResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAllDataSourceResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAllDataSourceResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAppliedAdvicesRequest(TeaModel):
    def __init__(
        self,
        advice_type: str = None,
        dbcluster_id: str = None,
        end_time: int = None,
        keyword: str = None,
        lang: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        schema_table_name: str = None,
        start_time: int = None,
    ):
        # The type of the suggestion. Valid values:
        # 
        # *   **INDEX**: index optimization.
        # *   **TIERING**: hot and cold data optimization.
        self.advice_type = advice_type
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end date of the time range to query. Specify the date in the yyyyMMdd format.
        self.end_time = end_time
        # The keyword that is used to query information by table name.
        self.keyword = keyword
        # The display language of the suggestion. Valid values:
        # 
        # *   **zh** (default): simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order by which to sort query results. Specify the parameter value in the JSON format. Example: `[{"Field":"SchemaName","Type":"Asc"}]`.
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `SchemaName`: the name of the database.
        #     *   `TableName`: the name of the table.
        #     *   `JobStatus`: the status of the BUILD job that is triggered on the table.
        #     *   `SubmitTime`: the time when the suggestion was submitted.
        #     *   `Benefit`: the expected benefits of the applied optimization suggestion.
        # 
        # *   `Type` specifies the sorting order. Valid values:
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        # 
        # >  If you do not specify this parameter, optimization suggestions are sorted in descending order based on the submission time.
        self.order = order
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30**(Default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the table in the **DatabaseName.TableName** format.
        self.schema_table_name = schema_table_name
        # The start date of the time range to query. Specify the date in the yyyyMMdd format.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advice_type is not None:
            result['AdviceType'] = self.advice_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_table_name is not None:
            result['SchemaTableName'] = self.schema_table_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdviceType') is not None:
            self.advice_type = m.get('AdviceType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaTableName') is not None:
            self.schema_table_name = m.get('SchemaTableName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeAppliedAdvicesResponseBodyItems(TeaModel):
    def __init__(
        self,
        advice_id: str = None,
        benefit: str = None,
        build_sql: str = None,
        index_fields: str = None,
        job_status: str = None,
        page_number: int = None,
        page_size: int = None,
        rollback_sql: str = None,
        sql: str = None,
        schema_name: str = None,
        submit_status: str = None,
        submit_time: str = None,
        table_name: str = None,
        total_count: int = None,
    ):
        # The suggestion ID.
        self.advice_id = advice_id
        # The benefit of the suggestion.
        self.benefit = benefit
        # The SQL statement that is used to execute the BUILD job.
        self.build_sql = build_sql
        self.index_fields = index_fields
        # The status of the suggestion execution job. Valid values:
        # 
        # *   **SUCCEED**\
        # *   **FAILED**\
        self.job_status = job_status
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30**(Default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The SQL statement that is used to roll back the suggestion.
        self.rollback_sql = rollback_sql
        # The SQL statement that is used to apply the suggestion.
        self.sql = sql
        # The name of the database.
        self.schema_name = schema_name
        # The submission status of the suggestion. Valid values:
        # 
        # *   **SUCCEED**\
        # *   **FAILED**\
        self.submit_status = submit_status
        # The time when the suggestion was submitted. The time follows the ISO 8601 standard in the yyMMddHHmm format. The time is displayed in UTC.
        self.submit_time = submit_time
        # The name of the table.
        self.table_name = table_name
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advice_id is not None:
            result['AdviceId'] = self.advice_id
        if self.benefit is not None:
            result['Benefit'] = self.benefit
        if self.build_sql is not None:
            result['BuildSQL'] = self.build_sql
        if self.index_fields is not None:
            result['IndexFields'] = self.index_fields
        if self.job_status is not None:
            result['JobStatus'] = self.job_status
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.rollback_sql is not None:
            result['RollbackSQL'] = self.rollback_sql
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.submit_status is not None:
            result['SubmitStatus'] = self.submit_status
        if self.submit_time is not None:
            result['SubmitTime'] = self.submit_time
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdviceId') is not None:
            self.advice_id = m.get('AdviceId')
        if m.get('Benefit') is not None:
            self.benefit = m.get('Benefit')
        if m.get('BuildSQL') is not None:
            self.build_sql = m.get('BuildSQL')
        if m.get('IndexFields') is not None:
            self.index_fields = m.get('IndexFields')
        if m.get('JobStatus') is not None:
            self.job_status = m.get('JobStatus')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RollbackSQL') is not None:
            self.rollback_sql = m.get('RollbackSQL')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('SubmitStatus') is not None:
            self.submit_status = m.get('SubmitStatus')
        if m.get('SubmitTime') is not None:
            self.submit_time = m.get('SubmitTime')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAppliedAdvicesResponseBody(TeaModel):
    def __init__(
        self,
        items: List[DescribeAppliedAdvicesResponseBodyItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        schema_table_names: List[str] = None,
        total_count: int = None,
    ):
        # The queried applied optimization suggestions.
        self.items = items
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30**(Default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The name of the table in the DatabaseName.TableName format.
        self.schema_table_names = schema_table_names
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schema_table_names is not None:
            result['SchemaTableNames'] = self.schema_table_names
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeAppliedAdvicesResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SchemaTableNames') is not None:
            self.schema_table_names = m.get('SchemaTableNames')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAppliedAdvicesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAppliedAdvicesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAppliedAdvicesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsActionLogsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        keyword: str = None,
        owner_account: str = None,
        owner_id: int = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        stage: str = None,
        start_time: str = None,
        state: str = None,
        workload_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mmZ** format. The time must be in UTC.
        # 
        # >  The end time must be later than the start time. The maximum time range that can be specified is 30 days.
        # 
        # This parameter is required.
        self.end_time = end_time
        # The keyword that you want to use for fuzzy match in the query.
        self.keyword = keyword
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The phase during which the logs to be queried were generated. Valid values:
        # 
        # *   **StructureMigrate**: schema migration.
        # *   **FullDataSync**: full data synchronization.
        # *   **IncrementalSync**: incremental data synchronization.
        # 
        # >  If you do not specify this parameter, logs of all the phases are queried.
        self.stage = stage
        # The start time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mmZ** format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time
        # The types of the logs. Separate multiple log types with commas (,). Valid values:
        # 
        # *   **INFO**\
        # *   **WARN**\
        # *   **ERROR**\
        # 
        # >  If you do not specify this parameter, logs of all types are queried.
        self.state = state
        # The ID of the real-time data ingestion job.
        # 
        # This parameter is required.
        self.workload_id = workload_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.stage is not None:
            result['Stage'] = self.stage
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.state is not None:
            result['State'] = self.state
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('Stage') is not None:
            self.stage = m.get('Stage')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        return self


class DescribeApsActionLogsResponseBodyActionLogs(TeaModel):
    def __init__(
        self,
        context: str = None,
        stage: str = None,
        state: str = None,
        time: str = None,
    ):
        # The content of the log.
        self.context = context
        # The phase during which the log was generated. Valid values:
        # 
        # *   **StructureMigrate**: schema migration.
        # *   **FullDataSync**: full data synchronization.
        # *   **IncrementalSync**: incremental data synchronization.
        self.stage = stage
        # The type of the log. Multiple log types are separated by commas (,). Valid values:
        # 
        # *   **INFO**\
        # *   **WARN**\
        # *   **ERROR**\
        self.state = state
        # The time when the log was generated. The time follows the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time is displayed in UTC.
        self.time = time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.context is not None:
            result['Context'] = self.context
        if self.stage is not None:
            result['Stage'] = self.stage
        if self.state is not None:
            result['State'] = self.state
        if self.time is not None:
            result['Time'] = self.time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Context') is not None:
            self.context = m.get('Context')
        if m.get('Stage') is not None:
            self.stage = m.get('Stage')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('Time') is not None:
            self.time = m.get('Time')
        return self


class DescribeApsActionLogsResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        action_logs: List[DescribeApsActionLogsResponseBodyActionLogs] = None,
        dbcluster_id: str = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        total_count: str = None,
        workload_id: str = None,
    ):
        # The information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The queried logs.
        self.action_logs = action_logs
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        self.dbcluster_id = dbcluster_id
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count
        # The ID of the real-time data ingestion job.
        self.workload_id = workload_id

    def validate(self):
        if self.action_logs:
            for k in self.action_logs:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        result['ActionLogs'] = []
        if self.action_logs is not None:
            for k in self.action_logs:
                result['ActionLogs'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        self.action_logs = []
        if m.get('ActionLogs') is not None:
            for k in m.get('ActionLogs'):
                temp_model = DescribeApsActionLogsResponseBodyActionLogs()
                self.action_logs.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        return self


class DescribeApsActionLogsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsActionLogsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsActionLogsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsDatasourceRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        datasource_id: int = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        # 
        # This parameter is required.
        self.datasource_id = datasource_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeApsDatasourceResponseBodyApsDatasourceDatabricksInfo(TeaModel):
    def __init__(
        self,
        access_token: str = None,
        workspace_url: str = None,
    ):
        # The token that is used to access Databricks.
        self.access_token = access_token
        # The URL of the workspace.
        self.workspace_url = workspace_url

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_token is not None:
            result['accessToken'] = self.access_token
        if self.workspace_url is not None:
            result['workspaceURL'] = self.workspace_url
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('accessToken') is not None:
            self.access_token = m.get('accessToken')
        if m.get('workspaceURL') is not None:
            self.workspace_url = m.get('workspaceURL')
        return self


class DescribeApsDatasourceResponseBodyApsDatasourceHiveInfo(TeaModel):
    def __init__(
        self,
        emr_cluster_id: str = None,
        meta_store_uri: str = None,
        security_group: str = None,
        vswitch: str = None,
    ):
        # The ID of the E-MapReduce (EMR) cluster.
        self.emr_cluster_id = emr_cluster_id
        # The URL of the Hive Metastore.
        self.meta_store_uri = meta_store_uri
        # The security group ID.
        self.security_group = security_group
        # The vSwitch ID.
        self.vswitch = vswitch

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.emr_cluster_id is not None:
            result['EmrClusterId'] = self.emr_cluster_id
        if self.meta_store_uri is not None:
            result['MetaStoreUri'] = self.meta_store_uri
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.vswitch is not None:
            result['Vswitch'] = self.vswitch
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EmrClusterId') is not None:
            self.emr_cluster_id = m.get('EmrClusterId')
        if m.get('MetaStoreUri') is not None:
            self.meta_store_uri = m.get('MetaStoreUri')
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('Vswitch') is not None:
            self.vswitch = m.get('Vswitch')
        return self


class DescribeApsDatasourceResponseBodyApsDatasourceKafkaInfo(TeaModel):
    def __init__(
        self,
        kafka_cluster_id: str = None,
        kafka_topic: str = None,
    ):
        # The ID of the Kafka instance.
        self.kafka_cluster_id = kafka_cluster_id
        # The topic of the Kafka instance.
        self.kafka_topic = kafka_topic

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.kafka_cluster_id is not None:
            result['KafkaClusterId'] = self.kafka_cluster_id
        if self.kafka_topic is not None:
            result['KafkaTopic'] = self.kafka_topic
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('KafkaClusterId') is not None:
            self.kafka_cluster_id = m.get('KafkaClusterId')
        if m.get('KafkaTopic') is not None:
            self.kafka_topic = m.get('KafkaTopic')
        return self


class DescribeApsDatasourceResponseBodyApsDatasourcePolarDBMysqlInfo(TeaModel):
    def __init__(
        self,
        across: bool = None,
        across_role: str = None,
        across_uid: str = None,
        connect_url: str = None,
        instance_id: str = None,
        region_id: str = None,
        security_group: str = None,
        user_name: str = None,
    ):
        # The parameter is no longer supported.
        self.across = across
        # The parameter is no longer supported.
        self.across_role = across_role
        # The parameter is no longer supported.
        self.across_uid = across_uid
        # The parameter is no longer supported.
        self.connect_url = connect_url
        # The parameter is no longer supported.
        self.instance_id = instance_id
        # The parameter is no longer supported.
        self.region_id = region_id
        # The parameter is no longer supported.
        self.security_group = security_group
        # The parameter is no longer supported.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across is not None:
            result['Across'] = self.across
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.connect_url is not None:
            result['ConnectUrl'] = self.connect_url
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Across') is not None:
            self.across = m.get('Across')
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('ConnectUrl') is not None:
            self.connect_url = m.get('ConnectUrl')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeApsDatasourceResponseBodyApsDatasourceRdsMysqlInfo(TeaModel):
    def __init__(
        self,
        connect_url: str = None,
        instance_id: str = None,
        region_id: str = None,
        security_group: str = None,
        user_name: str = None,
    ):
        # The parameter is no longer supported.
        self.connect_url = connect_url
        # The parameter is no longer supported.
        self.instance_id = instance_id
        # The parameter is no longer supported.
        self.region_id = region_id
        # The parameter is no longer supported.
        self.security_group = security_group
        # The parameter is no longer supported.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connect_url is not None:
            result['ConnectUrl'] = self.connect_url
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectUrl') is not None:
            self.connect_url = m.get('ConnectUrl')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeApsDatasourceResponseBodyApsDatasourceSlsInfo(TeaModel):
    def __init__(
        self,
        across: bool = None,
        across_role: str = None,
        across_uid: str = None,
        project: str = None,
        source_region_id: str = None,
        store: str = None,
    ):
        # Indicates whether the data source is a cross-account resource. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.across = across
        # The name of the cross-account role.
        self.across_role = across_role
        # The cross-account UID.
        self.across_uid = across_uid
        # The name of the SLS project.
        self.project = project
        # The region ID.
        self.source_region_id = source_region_id
        # The name of the SLS Logstore.
        self.store = store

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across is not None:
            result['Across'] = self.across
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.project is not None:
            result['Project'] = self.project
        if self.source_region_id is not None:
            result['SourceRegionId'] = self.source_region_id
        if self.store is not None:
            result['Store'] = self.store
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Across') is not None:
            self.across = m.get('Across')
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('Project') is not None:
            self.project = m.get('Project')
        if m.get('SourceRegionId') is not None:
            self.source_region_id = m.get('SourceRegionId')
        if m.get('Store') is not None:
            self.store = m.get('Store')
        return self


class DescribeApsDatasourceResponseBodyApsDatasource(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        dbcluster_id: str = None,
        databricks_info: DescribeApsDatasourceResponseBodyApsDatasourceDatabricksInfo = None,
        datasource_description: str = None,
        datasource_name: str = None,
        datasource_type: str = None,
        hive_info: DescribeApsDatasourceResponseBodyApsDatasourceHiveInfo = None,
        kafka_info: DescribeApsDatasourceResponseBodyApsDatasourceKafkaInfo = None,
        polar_dbmysql_info: DescribeApsDatasourceResponseBodyApsDatasourcePolarDBMysqlInfo = None,
        rds_mysql_info: DescribeApsDatasourceResponseBodyApsDatasourceRdsMysqlInfo = None,
        sls_info: DescribeApsDatasourceResponseBodyApsDatasourceSlsInfo = None,
    ):
        # The time when the data source was created.
        self.create_time = create_time
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The information about Databricks.
        self.databricks_info = databricks_info
        # The description of the data source.
        self.datasource_description = datasource_description
        # The name of the data source.
        self.datasource_name = datasource_name
        # The type of the data source.
        self.datasource_type = datasource_type
        # The information about the Hive data source.
        self.hive_info = hive_info
        # The information about the Kafka instance.
        self.kafka_info = kafka_info
        # The parameter is no longer supported.
        self.polar_dbmysql_info = polar_dbmysql_info
        # The parameter is no longer supported.
        self.rds_mysql_info = rds_mysql_info
        # The Simple Log Service (SLS) project.
        self.sls_info = sls_info

    def validate(self):
        if self.databricks_info:
            self.databricks_info.validate()
        if self.hive_info:
            self.hive_info.validate()
        if self.kafka_info:
            self.kafka_info.validate()
        if self.polar_dbmysql_info:
            self.polar_dbmysql_info.validate()
        if self.rds_mysql_info:
            self.rds_mysql_info.validate()
        if self.sls_info:
            self.sls_info.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.databricks_info is not None:
            result['DatabricksInfo'] = self.databricks_info.to_map()
        if self.datasource_description is not None:
            result['DatasourceDescription'] = self.datasource_description
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.datasource_type is not None:
            result['DatasourceType'] = self.datasource_type
        if self.hive_info is not None:
            result['HiveInfo'] = self.hive_info.to_map()
        if self.kafka_info is not None:
            result['KafkaInfo'] = self.kafka_info.to_map()
        if self.polar_dbmysql_info is not None:
            result['PolarDBMysqlInfo'] = self.polar_dbmysql_info.to_map()
        if self.rds_mysql_info is not None:
            result['RdsMysqlInfo'] = self.rds_mysql_info.to_map()
        if self.sls_info is not None:
            result['SlsInfo'] = self.sls_info.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabricksInfo') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasourceDatabricksInfo()
            self.databricks_info = temp_model.from_map(m['DatabricksInfo'])
        if m.get('DatasourceDescription') is not None:
            self.datasource_description = m.get('DatasourceDescription')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('DatasourceType') is not None:
            self.datasource_type = m.get('DatasourceType')
        if m.get('HiveInfo') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasourceHiveInfo()
            self.hive_info = temp_model.from_map(m['HiveInfo'])
        if m.get('KafkaInfo') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasourceKafkaInfo()
            self.kafka_info = temp_model.from_map(m['KafkaInfo'])
        if m.get('PolarDBMysqlInfo') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasourcePolarDBMysqlInfo()
            self.polar_dbmysql_info = temp_model.from_map(m['PolarDBMysqlInfo'])
        if m.get('RdsMysqlInfo') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasourceRdsMysqlInfo()
            self.rds_mysql_info = temp_model.from_map(m['RdsMysqlInfo'])
        if m.get('SlsInfo') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasourceSlsInfo()
            self.sls_info = temp_model.from_map(m['SlsInfo'])
        return self


class DescribeApsDatasourceResponseBody(TeaModel):
    def __init__(
        self,
        aps_datasource: DescribeApsDatasourceResponseBodyApsDatasource = None,
        request_id: str = None,
    ):
        # The queried APS data source.
        self.aps_datasource = aps_datasource
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.aps_datasource:
            self.aps_datasource.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_datasource is not None:
            result['ApsDatasource'] = self.aps_datasource.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsDatasource') is not None:
            temp_model = DescribeApsDatasourceResponseBodyApsDatasource()
            self.aps_datasource = temp_model.from_map(m['ApsDatasource'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeApsDatasourceResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsDatasourceResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsDatasourceResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsDatasourcesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        datasource_name: str = None,
        datasource_type: str = None,
        end_time: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        start_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster.
        self.dbcluster_id = dbcluster_id
        # The name of the data source.
        self.datasource_name = datasource_name
        # The type of the data source.
        self.datasource_type = datasource_type
        # The end of the time range to query.
        self.end_time = end_time
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        # 
        # This parameter is required.
        self.page_size = page_size
        # The region ID.
        self.region_id = region_id
        # The beginning of the time range to query.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.datasource_type is not None:
            result['DatasourceType'] = self.datasource_type
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('DatasourceType') is not None:
            self.datasource_type = m.get('DatasourceType')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeApsDatasourcesResponseBodyApsDatasources(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        datasource_description: str = None,
        datasource_id: int = None,
        datasource_name: str = None,
        datasource_type: str = None,
        has_job: bool = None,
    ):
        # The time when the data source was created.
        self.create_time = create_time
        # The description of the data source.
        self.datasource_description = datasource_description
        # The data source ID.
        self.datasource_id = datasource_id
        # The name of the data source.
        self.datasource_name = datasource_name
        # The type of the data source.
        self.datasource_type = datasource_type
        # Indicates whether a job is using the data source.
        self.has_job = has_job

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.datasource_description is not None:
            result['DatasourceDescription'] = self.datasource_description
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.datasource_type is not None:
            result['DatasourceType'] = self.datasource_type
        if self.has_job is not None:
            result['HasJob'] = self.has_job
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DatasourceDescription') is not None:
            self.datasource_description = m.get('DatasourceDescription')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('DatasourceType') is not None:
            self.datasource_type = m.get('DatasourceType')
        if m.get('HasJob') is not None:
            self.has_job = m.get('HasJob')
        return self


class DescribeApsDatasourcesResponseBody(TeaModel):
    def __init__(
        self,
        aps_datasources: List[DescribeApsDatasourcesResponseBodyApsDatasources] = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The queried APS data sources.
        self.aps_datasources = aps_datasources
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.aps_datasources:
            for k in self.aps_datasources:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ApsDatasources'] = []
        if self.aps_datasources is not None:
            for k in self.aps_datasources:
                result['ApsDatasources'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.aps_datasources = []
        if m.get('ApsDatasources') is not None:
            for k in m.get('ApsDatasources'):
                temp_model = DescribeApsDatasourcesResponseBodyApsDatasources()
                self.aps_datasources.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeApsDatasourcesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsDatasourcesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsDatasourcesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsHiveWorkloadRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        workload_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        self.region_id = region_id
        # The job ID.
        # 
        # This parameter is required.
        self.workload_id = workload_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        return self


class DescribeApsHiveWorkloadResponseBodyApsWorkload(TeaModel):
    def __init__(
        self,
        advanced_config: str = None,
        conflict_strategy: str = None,
        create_time: str = None,
        dbcluster_id: str = None,
        datasource_id: int = None,
        datasource_name: str = None,
        emr_cluster_id: str = None,
        full_compute_unit: str = None,
        meta_store_uri: str = None,
        oss_location: str = None,
        parallelism: int = None,
        region_id: str = None,
        resource_group: str = None,
        state: str = None,
        sync_allow_expression: str = None,
        sync_deny_expression: str = None,
        target_type: str = None,
        vswitch: str = None,
        workload_id: str = None,
        workload_name: str = None,
        workload_type_name: str = None,
    ):
        # The advanced configurations.
        self.advanced_config = advanced_config
        # The policy to handle tables with the same name in the destination cluster.
        self.conflict_strategy = conflict_strategy
        # The time when the workload was created.
        self.create_time = create_time
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The data source ID.
        self.datasource_id = datasource_id
        # The name of the data source.
        self.datasource_name = datasource_name
        # The ID of the E-MapReduce (EMR) cluster.
        self.emr_cluster_id = emr_cluster_id
        # The number of AnalyticDB compute units (ACUs) required for migration.
        self.full_compute_unit = full_compute_unit
        # The URL of the Hive Metastore.
        self.meta_store_uri = meta_store_uri
        # The Object Storage Service (OSS) URL of the AnalyticDB for MySQL cluster data.
        self.oss_location = oss_location
        # The number of tasks that are allowed in parallel.
        self.parallelism = parallelism
        # The region ID.
        self.region_id = region_id
        # The resource group to which the SQL statement belongs.
        self.resource_group = resource_group
        # The status of the workload.
        self.state = state
        # The expression that manually matches the source database table whitelist.
        self.sync_allow_expression = sync_allow_expression
        # Manually match the blacklist expressions for source database tables.
        self.sync_deny_expression = sync_deny_expression
        # The destination type.
        self.target_type = target_type
        # The name of the vSwitch.
        self.vswitch = vswitch
        # The job ID.
        self.workload_id = workload_id
        # The name of the workload.
        self.workload_name = workload_name
        # The name of the workload.
        self.workload_type_name = workload_type_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advanced_config is not None:
            result['AdvancedConfig'] = self.advanced_config
        if self.conflict_strategy is not None:
            result['ConflictStrategy'] = self.conflict_strategy
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.emr_cluster_id is not None:
            result['EmrClusterId'] = self.emr_cluster_id
        if self.full_compute_unit is not None:
            result['FullComputeUnit'] = self.full_compute_unit
        if self.meta_store_uri is not None:
            result['MetaStoreUri'] = self.meta_store_uri
        if self.oss_location is not None:
            result['OssLocation'] = self.oss_location
        if self.parallelism is not None:
            result['Parallelism'] = self.parallelism
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.state is not None:
            result['State'] = self.state
        if self.sync_allow_expression is not None:
            result['SyncAllowExpression'] = self.sync_allow_expression
        if self.sync_deny_expression is not None:
            result['SyncDenyExpression'] = self.sync_deny_expression
        if self.target_type is not None:
            result['TargetType'] = self.target_type
        if self.vswitch is not None:
            result['Vswitch'] = self.vswitch
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        if self.workload_type_name is not None:
            result['WorkloadTypeName'] = self.workload_type_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdvancedConfig') is not None:
            self.advanced_config = m.get('AdvancedConfig')
        if m.get('ConflictStrategy') is not None:
            self.conflict_strategy = m.get('ConflictStrategy')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('EmrClusterId') is not None:
            self.emr_cluster_id = m.get('EmrClusterId')
        if m.get('FullComputeUnit') is not None:
            self.full_compute_unit = m.get('FullComputeUnit')
        if m.get('MetaStoreUri') is not None:
            self.meta_store_uri = m.get('MetaStoreUri')
        if m.get('OssLocation') is not None:
            self.oss_location = m.get('OssLocation')
        if m.get('Parallelism') is not None:
            self.parallelism = m.get('Parallelism')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('SyncAllowExpression') is not None:
            self.sync_allow_expression = m.get('SyncAllowExpression')
        if m.get('SyncDenyExpression') is not None:
            self.sync_deny_expression = m.get('SyncDenyExpression')
        if m.get('TargetType') is not None:
            self.target_type = m.get('TargetType')
        if m.get('Vswitch') is not None:
            self.vswitch = m.get('Vswitch')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        if m.get('WorkloadTypeName') is not None:
            self.workload_type_name = m.get('WorkloadTypeName')
        return self


class DescribeApsHiveWorkloadResponseBody(TeaModel):
    def __init__(
        self,
        aps_workload: DescribeApsHiveWorkloadResponseBodyApsWorkload = None,
        request_id: str = None,
    ):
        # The queried job.
        self.aps_workload = aps_workload
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.aps_workload:
            self.aps_workload.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_workload is not None:
            result['ApsWorkload'] = self.aps_workload.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsWorkload') is not None:
            temp_model = DescribeApsHiveWorkloadResponseBodyApsWorkload()
            self.aps_workload = temp_model.from_map(m['ApsWorkload'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeApsHiveWorkloadResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsHiveWorkloadResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsHiveWorkloadResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsJobDetailRequest(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        region_id: str = None,
    ):
        # The job ID.
        # 
        # This parameter is required.
        self.aps_job_id = aps_job_id
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeApsJobDetailResponseBodyAPSJobDetail(TeaModel):
    def __init__(
        self,
        db_list: str = None,
        destination_endpoint_instance_id: str = None,
        destination_endpoint_region: str = None,
        partition_list: str = None,
        source_endpoint_instance_id: str = None,
        source_endpoint_region: str = None,
        status: str = None,
        target_table_mode: str = None,
    ):
        # The objects that are synchronized.
        self.db_list = db_list
        # The ID of the destination cluster.
        self.destination_endpoint_instance_id = destination_endpoint_instance_id
        # The region of the destination cluster.
        self.destination_endpoint_region = destination_endpoint_region
        # The partitions.
        self.partition_list = partition_list
        # The ID of the source instance.
        self.source_endpoint_instance_id = source_endpoint_instance_id
        # The region of the source instance.
        self.source_endpoint_region = source_endpoint_region
        # The status of the job.
        self.status = status
        # The mode of the destination table.
        self.target_table_mode = target_table_mode

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.db_list is not None:
            result['DbList'] = self.db_list
        if self.destination_endpoint_instance_id is not None:
            result['DestinationEndpointInstanceID'] = self.destination_endpoint_instance_id
        if self.destination_endpoint_region is not None:
            result['DestinationEndpointRegion'] = self.destination_endpoint_region
        if self.partition_list is not None:
            result['PartitionList'] = self.partition_list
        if self.source_endpoint_instance_id is not None:
            result['SourceEndpointInstanceID'] = self.source_endpoint_instance_id
        if self.source_endpoint_region is not None:
            result['SourceEndpointRegion'] = self.source_endpoint_region
        if self.status is not None:
            result['Status'] = self.status
        if self.target_table_mode is not None:
            result['TargetTableMode'] = self.target_table_mode
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DbList') is not None:
            self.db_list = m.get('DbList')
        if m.get('DestinationEndpointInstanceID') is not None:
            self.destination_endpoint_instance_id = m.get('DestinationEndpointInstanceID')
        if m.get('DestinationEndpointRegion') is not None:
            self.destination_endpoint_region = m.get('DestinationEndpointRegion')
        if m.get('PartitionList') is not None:
            self.partition_list = m.get('PartitionList')
        if m.get('SourceEndpointInstanceID') is not None:
            self.source_endpoint_instance_id = m.get('SourceEndpointInstanceID')
        if m.get('SourceEndpointRegion') is not None:
            self.source_endpoint_region = m.get('SourceEndpointRegion')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TargetTableMode') is not None:
            self.target_table_mode = m.get('TargetTableMode')
        return self


class DescribeApsJobDetailResponseBody(TeaModel):
    def __init__(
        self,
        apsjob_detail: DescribeApsJobDetailResponseBodyAPSJobDetail = None,
        request_id: str = None,
    ):
        # The queried job.
        self.apsjob_detail = apsjob_detail
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.apsjob_detail:
            self.apsjob_detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.apsjob_detail is not None:
            result['APSJobDetail'] = self.apsjob_detail.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('APSJobDetail') is not None:
            temp_model = DescribeApsJobDetailResponseBodyAPSJobDetail()
            self.apsjob_detail = temp_model.from_map(m['APSJobDetail'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeApsJobDetailResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsJobDetailResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsJobDetailResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsJobsRequest(TeaModel):
    def __init__(
        self,
        aps_job_name: str = None,
        create_time_end: str = None,
        create_time_start: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
    ):
        # The name of the APS job.
        self.aps_job_name = aps_job_name
        # The end of the time range to query.
        self.create_time_end = create_time_end
        # The beginning of the time range to query.
        self.create_time_start = create_time_start
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        # 
        # This parameter is required.
        self.page_size = page_size
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_name is not None:
            result['ApsJobName'] = self.aps_job_name
        if self.create_time_end is not None:
            result['CreateTimeEnd'] = self.create_time_end
        if self.create_time_start is not None:
            result['CreateTimeStart'] = self.create_time_start
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobName') is not None:
            self.aps_job_name = m.get('ApsJobName')
        if m.get('CreateTimeEnd') is not None:
            self.create_time_end = m.get('CreateTimeEnd')
        if m.get('CreateTimeStart') is not None:
            self.create_time_start = m.get('CreateTimeStart')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeApsJobsResponseBodyAPSJobs(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        aps_job_name: str = None,
        create_time: str = None,
        delay: int = None,
        destination_instance_id: str = None,
        err_message: str = None,
        projress: str = None,
        source_instance_id: str = None,
        status: str = None,
        sub_status: str = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The name of the APS job.
        self.aps_job_name = aps_job_name
        # The time when the APS job was created.
        self.create_time = create_time
        # The synchronization latency.
        self.delay = delay
        # The destination cluster ID.
        self.destination_instance_id = destination_instance_id
        # The error message.
        self.err_message = err_message
        # The progress.
        self.projress = projress
        # The ID of the source instance or cluster.
        self.source_instance_id = source_instance_id
        # The status of the APS job.
        self.status = status
        # The status of the task.
        self.sub_status = sub_status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.aps_job_name is not None:
            result['ApsJobName'] = self.aps_job_name
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.delay is not None:
            result['Delay'] = self.delay
        if self.destination_instance_id is not None:
            result['DestinationInstanceID'] = self.destination_instance_id
        if self.err_message is not None:
            result['ErrMessage'] = self.err_message
        if self.projress is not None:
            result['Projress'] = self.projress
        if self.source_instance_id is not None:
            result['SourceInstanceID'] = self.source_instance_id
        if self.status is not None:
            result['Status'] = self.status
        if self.sub_status is not None:
            result['SubStatus'] = self.sub_status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('ApsJobName') is not None:
            self.aps_job_name = m.get('ApsJobName')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('Delay') is not None:
            self.delay = m.get('Delay')
        if m.get('DestinationInstanceID') is not None:
            self.destination_instance_id = m.get('DestinationInstanceID')
        if m.get('ErrMessage') is not None:
            self.err_message = m.get('ErrMessage')
        if m.get('Projress') is not None:
            self.projress = m.get('Projress')
        if m.get('SourceInstanceID') is not None:
            self.source_instance_id = m.get('SourceInstanceID')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('SubStatus') is not None:
            self.sub_status = m.get('SubStatus')
        return self


class DescribeApsJobsResponseBody(TeaModel):
    def __init__(
        self,
        apsjobs: List[DescribeApsJobsResponseBodyAPSJobs] = None,
        code: str = None,
        http_status_code: int = None,
        message: str = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        success: bool = None,
        total_count: str = None,
    ):
        # The queried APS jobs.
        self.apsjobs = apsjobs
        # The HTTP status code.
        self.code = code
        # The status code. A value of 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.apsjobs:
            for k in self.apsjobs:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['APSJobs'] = []
        if self.apsjobs is not None:
            for k in self.apsjobs:
                result['APSJobs'].append(k.to_map() if k else None)
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.apsjobs = []
        if m.get('APSJobs') is not None:
            for k in m.get('APSJobs'):
                temp_model = DescribeApsJobsResponseBodyAPSJobs()
                self.apsjobs.append(temp_model.from_map(k))
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeApsJobsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsJobsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsJobsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsMigrationWorkloadsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        oss_location: str = None,
        page_number: int = None,
        page_size: int = None,
        start_time: str = None,
        workload_name: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query.
        self.end_time = end_time
        # The Object Storage Service (OSS) URL.
        self.oss_location = oss_location
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        # 
        # This parameter is required.
        self.page_size = page_size
        # The start of the time range to query.
        self.start_time = start_time
        # The name of the workload.
        self.workload_name = workload_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.oss_location is not None:
            result['OssLocation'] = self.oss_location
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('OssLocation') is not None:
            self.oss_location = m.get('OssLocation')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class DescribeApsMigrationWorkloadsResponseBodyMigrationWorkloads(TeaModel):
    def __init__(
        self,
        acu_count: int = None,
        create_time: str = None,
        failed_msg: str = None,
        id: str = None,
        max_rt: str = None,
        modify_time: str = None,
        name: str = None,
        oss_location: str = None,
        state: str = None,
        target_type: str = None,
        workload_sub_type: str = None,
    ):
        # The number of AnalyticDB compute units (ACUs).
        self.acu_count = acu_count
        # The time when the job was created.
        self.create_time = create_time
        # The error message.
        self.failed_msg = failed_msg
        # The job ID.
        self.id = id
        # The maximum response time.
        self.max_rt = max_rt
        # The time when the migration job was modified.
        self.modify_time = modify_time
        # The name of the workload.
        self.name = name
        # The OSS URL.
        self.oss_location = oss_location
        # The status.
        self.state = state
        # The destination type.
        self.target_type = target_type
        # The sub-type of the workload.
        self.workload_sub_type = workload_sub_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.acu_count is not None:
            result['AcuCount'] = self.acu_count
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.failed_msg is not None:
            result['FailedMsg'] = self.failed_msg
        if self.id is not None:
            result['Id'] = self.id
        if self.max_rt is not None:
            result['MaxRT'] = self.max_rt
        if self.modify_time is not None:
            result['ModifyTime'] = self.modify_time
        if self.name is not None:
            result['Name'] = self.name
        if self.oss_location is not None:
            result['OssLocation'] = self.oss_location
        if self.state is not None:
            result['State'] = self.state
        if self.target_type is not None:
            result['TargetType'] = self.target_type
        if self.workload_sub_type is not None:
            result['WorkloadSubType'] = self.workload_sub_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AcuCount') is not None:
            self.acu_count = m.get('AcuCount')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('FailedMsg') is not None:
            self.failed_msg = m.get('FailedMsg')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('MaxRT') is not None:
            self.max_rt = m.get('MaxRT')
        if m.get('ModifyTime') is not None:
            self.modify_time = m.get('ModifyTime')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('OssLocation') is not None:
            self.oss_location = m.get('OssLocation')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('TargetType') is not None:
            self.target_type = m.get('TargetType')
        if m.get('WorkloadSubType') is not None:
            self.workload_sub_type = m.get('WorkloadSubType')
        return self


class DescribeApsMigrationWorkloadsResponseBody(TeaModel):
    def __init__(
        self,
        migration_workloads: List[DescribeApsMigrationWorkloadsResponseBodyMigrationWorkloads] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The queried migration workloads.
        self.migration_workloads = migration_workloads
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.migration_workloads:
            for k in self.migration_workloads:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['MigrationWorkloads'] = []
        if self.migration_workloads is not None:
            for k in self.migration_workloads:
                result['MigrationWorkloads'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.migration_workloads = []
        if m.get('MigrationWorkloads') is not None:
            for k in m.get('MigrationWorkloads'):
                temp_model = DescribeApsMigrationWorkloadsResponseBodyMigrationWorkloads()
                self.migration_workloads.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeApsMigrationWorkloadsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsMigrationWorkloadsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsMigrationWorkloadsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsProgressRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        workload_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        self.region_id = region_id
        # The job ID.
        # 
        # This parameter is required.
        self.workload_id = workload_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        return self


class DescribeApsProgressResponseBodyApsHiveProgress(TeaModel):
    def __init__(
        self,
        db_name: str = None,
        progress: str = None,
        speed: str = None,
        tb_name: str = None,
    ):
        # The name of the database.
        self.db_name = db_name
        # The migration progress.
        self.progress = progress
        # The migration speed.
        self.speed = speed
        # The name of the table.
        self.tb_name = tb_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.progress is not None:
            result['Progress'] = self.progress
        if self.speed is not None:
            result['Speed'] = self.speed
        if self.tb_name is not None:
            result['TbName'] = self.tb_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('Progress') is not None:
            self.progress = m.get('Progress')
        if m.get('Speed') is not None:
            self.speed = m.get('Speed')
        if m.get('TbName') is not None:
            self.tb_name = m.get('TbName')
        return self


class DescribeApsProgressResponseBody(TeaModel):
    def __init__(
        self,
        aps_hive_progress: List[DescribeApsProgressResponseBodyApsHiveProgress] = None,
        request_id: str = None,
        success_percentage: int = None,
        success_table_count: int = None,
        total_table_count: int = None,
    ):
        # The migration progress.
        self.aps_hive_progress = aps_hive_progress
        # The request ID.
        self.request_id = request_id
        # The success rate.
        self.success_percentage = success_percentage
        # The total number of migrated tables returned.
        self.success_table_count = success_table_count
        # The total number of tables to be migrated.
        self.total_table_count = total_table_count

    def validate(self):
        if self.aps_hive_progress:
            for k in self.aps_hive_progress:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ApsHiveProgress'] = []
        if self.aps_hive_progress is not None:
            for k in self.aps_hive_progress:
                result['ApsHiveProgress'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success_percentage is not None:
            result['SuccessPercentage'] = self.success_percentage
        if self.success_table_count is not None:
            result['SuccessTableCount'] = self.success_table_count
        if self.total_table_count is not None:
            result['TotalTableCount'] = self.total_table_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.aps_hive_progress = []
        if m.get('ApsHiveProgress') is not None:
            for k in m.get('ApsHiveProgress'):
                temp_model = DescribeApsProgressResponseBodyApsHiveProgress()
                self.aps_hive_progress.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SuccessPercentage') is not None:
            self.success_percentage = m.get('SuccessPercentage')
        if m.get('SuccessTableCount') is not None:
            self.success_table_count = m.get('SuccessTableCount')
        if m.get('TotalTableCount') is not None:
            self.total_table_count = m.get('TotalTableCount')
        return self


class DescribeApsProgressResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsProgressResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsProgressResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeApsResourceGroupsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        workload_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        self.region_id = region_id
        # The ID of the data synchronization job.
        self.workload_id = workload_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        return self


class DescribeApsResourceGroupsResponseBodyDataResourceGroups(TeaModel):
    def __init__(
        self,
        available: bool = None,
        cu_options: List[int] = None,
        group_name: str = None,
        group_type: str = None,
        left_compute_resource: int = None,
        max_compute_resource: int = None,
        min_compute_resource: int = None,
    ):
        # Indicates whether the resource group is available. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.available = available
        self.cu_options = cu_options
        # The name of the resource group.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # >  For more information about resource groups, see [Resource groups](https://help.aliyun.com/document_detail/428610.html).
        self.group_type = group_type
        # The amount of remaining computing resources. Unit: ACUs.
        self.left_compute_resource = left_compute_resource
        # The maximum amount of reserved computing resources. Unit: ACUs.
        # 
        # *   If the value of GroupType is **Interactive**, the amount of reserved computing resources that are not allocated in the cluster is returned in increments of 16 ACUs.
        # *   If the value of GroupType is **Job**, the amount of reserved computing resources that are not allocated in the cluster is returned in increments of 8 ACUs.
        self.max_compute_resource = max_compute_resource
        # The minimum amount of reserved computing resources. Unit: ACUs.
        # 
        # *   If the value of GroupType is **Interactive**, 16 is returned.
        # *   If the value of GroupType is **Job**, 0 is returned.
        self.min_compute_resource = min_compute_resource

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.available is not None:
            result['Available'] = self.available
        if self.cu_options is not None:
            result['CuOptions'] = self.cu_options
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.left_compute_resource is not None:
            result['LeftComputeResource'] = self.left_compute_resource
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Available') is not None:
            self.available = m.get('Available')
        if m.get('CuOptions') is not None:
            self.cu_options = m.get('CuOptions')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('LeftComputeResource') is not None:
            self.left_compute_resource = m.get('LeftComputeResource')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        return self


class DescribeApsResourceGroupsResponseBodyData(TeaModel):
    def __init__(
        self,
        resource_groups: List[DescribeApsResourceGroupsResponseBodyDataResourceGroups] = None,
        step: int = None,
    ):
        # The queried resource groups.
        self.resource_groups = resource_groups
        # The step size of resources. Unit: AnalyticDB compute units (ACUs).
        # 
        # *   If the value of GroupType is **Interactive**, 16 is returned.
        # *   If the value of GroupType is **Job**, 8 is returned.
        self.step = step

    def validate(self):
        if self.resource_groups:
            for k in self.resource_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ResourceGroups'] = []
        if self.resource_groups is not None:
            for k in self.resource_groups:
                result['ResourceGroups'].append(k.to_map() if k else None)
        if self.step is not None:
            result['Step'] = self.step
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.resource_groups = []
        if m.get('ResourceGroups') is not None:
            for k in m.get('ResourceGroups'):
                temp_model = DescribeApsResourceGroupsResponseBodyDataResourceGroups()
                self.resource_groups.append(temp_model.from_map(k))
        if m.get('Step') is not None:
            self.step = m.get('Step')
        return self


class DescribeApsResourceGroupsResponseBody(TeaModel):
    def __init__(
        self,
        data: DescribeApsResourceGroupsResponseBodyData = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The queried resource groups.
        self.data = data
        # The HTTP status code.
        self.http_status_code = http_status_code
        # The returned message.
        # 
        # *   If the request was successful, a success message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DescribeApsResourceGroupsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DescribeApsResourceGroupsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeApsResourceGroupsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeApsResourceGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAuditLogRecordsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        dbname: str = None,
        end_time: str = None,
        host_address: str = None,
        order: str = None,
        order_type: str = None,
        owner_account: str = None,
        owner_id: int = None,
        page_number: int = None,
        page_size: int = None,
        proxy_user: str = None,
        query_keyword: str = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        sql_type: str = None,
        start_time: str = None,
        succeed: str = None,
        user: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database on which the SQL statement was executed.
        self.dbname = dbname
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        # 
        # > 
        # 
        # *   The end time must be later than the start time.
        # 
        # *   The maximum time range that can be specified is 24 hours.
        self.end_time = end_time
        # The IP address and port number of the client that is used to execute the SQL statement.
        self.host_address = host_address
        # The order in which to sort the retrieved entries by field. Specify this parameter in the JSON format. The value is an ordered array that uses the order of the input array and contains `Field` and `Type`. Example: `[{"Field":"ExecutionStartTime","Type":"Desc"},{"Field":"ScanRows","Type":"Asc"}]`. Fields:
        # 
        # *   `Field`: the field that is used to sort the retrieved entries. Valid values:
        # 
        #     *   **HostAddress**: the IP address of the client that is used to connect to the database.
        #     *   **UserName**: the username.
        #     *   **ExecutionStartTime**: the start time of the query execution.
        #     *   **QueryTime**: the amount of time consumed to execute the SQL statement.
        #     *   **PeakMemoryUsage**: the maximum memory usage when the SQL statement is executed.
        #     *   **ScanRows**: the number of rows to be scanned from a data source in the task.
        #     *   **ScanSize**: the amount of data to be scanned.
        #     *   **ScanTime**: the total amount of time consumed to scan data.
        #     *   **PlanningTime**: the amount of time consumed to generate execution plans.
        #     *   **WallTime**: the accumulated CPU Time values of all operators in the query on each node.
        #     *   **ProcessID**: the process ID.
        # 
        # *   `Type`: the sorting type of the retrieved entries. Valid values:
        # 
        #     *   **Desc**: descending order.
        #     *   **Asc**: ascending order.
        self.order = order
        # The sorting order of the retrieved entries. Valid values:
        # 
        # *   **asc**: sorts the retrieved entries by time in ascending order.
        # *   **desc**: sorts the retrieved entries by time in descending order.
        self.order_type = order_type
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **10** (default)
        # *   **30**\
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # A reserved parameter.
        self.proxy_user = proxy_user
        # The keyword based on which audit logs are queried. You can set this parameter to a value of the STRING type.
        self.query_keyword = query_keyword
        # The region ID of the cluster.
        # 
        # > You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The type of the SQL statement. Valid values:
        # 
        # *   **DELETE**\
        # *   **SELECT**\
        # *   **UPDATE**\
        # *   **INSERT INTO SELECT**\
        # *   **ALTER**\
        # *   **DROP**\
        # *   **CREATE**\
        # 
        # >  You can query only a single type of SQL statements at a time. If you leave this parameter empty, all types of SQL statements are queried.
        self.sql_type = sql_type
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        # 
        # > SQL audit logs can be queried only when SQL audit is enabled. Only SQL audit logs within the last 30 days can be queried. If SQL audit was disabled and re-enabled, only SQL audit logs from the time when SQL audit was re-enabled can be queried.
        self.start_time = start_time
        # Specifies whether the execution of the SQL statement succeeds. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.succeed = succeed
        # The username that is used to execute the SQL statement.
        self.user = user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.dbname is not None:
            result['DBName'] = self.dbname
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.host_address is not None:
            result['HostAddress'] = self.host_address
        if self.order is not None:
            result['Order'] = self.order
        if self.order_type is not None:
            result['OrderType'] = self.order_type
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.proxy_user is not None:
            result['ProxyUser'] = self.proxy_user
        if self.query_keyword is not None:
            result['QueryKeyword'] = self.query_keyword
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.sql_type is not None:
            result['SqlType'] = self.sql_type
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.succeed is not None:
            result['Succeed'] = self.succeed
        if self.user is not None:
            result['User'] = self.user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DBName') is not None:
            self.dbname = m.get('DBName')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('HostAddress') is not None:
            self.host_address = m.get('HostAddress')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('OrderType') is not None:
            self.order_type = m.get('OrderType')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('ProxyUser') is not None:
            self.proxy_user = m.get('ProxyUser')
        if m.get('QueryKeyword') is not None:
            self.query_keyword = m.get('QueryKeyword')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('SqlType') is not None:
            self.sql_type = m.get('SqlType')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Succeed') is not None:
            self.succeed = m.get('Succeed')
        if m.get('User') is not None:
            self.user = m.get('User')
        return self


class DescribeAuditLogRecordsResponseBodyItems(TeaModel):
    def __init__(
        self,
        conn_id: str = None,
        dbname: str = None,
        execute_time: str = None,
        host_address: str = None,
        process_id: str = None,
        sqltext: str = None,
        sqltype: str = None,
        succeed: str = None,
        total_time: str = None,
        user: str = None,
    ):
        # The connection ID.
        self.conn_id = conn_id
        # The name of the database on which the SQL statement was executed.
        self.dbname = dbname
        # The start time of the execution of the SQL statement. The time is displayed in the ISO 8601 standard in the yyyy-MM-dd HH:mm:ss format. The time must be in UTC.
        self.execute_time = execute_time
        # The IP address and port number of the client that is used to execute the SQL statement.
        self.host_address = host_address
        # The task ID.
        self.process_id = process_id
        # The SQL statement.
        self.sqltext = sqltext
        # The type of the SQL statement.
        self.sqltype = sqltype
        # Indicates whether the SQL statement was successfully executed. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.succeed = succeed
        # The amount of time that is consumed to execute the SQL statement. Unit: milliseconds.
        self.total_time = total_time
        # The username that is used to execute the SQL statement.
        self.user = user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.conn_id is not None:
            result['ConnId'] = self.conn_id
        if self.dbname is not None:
            result['DBName'] = self.dbname
        if self.execute_time is not None:
            result['ExecuteTime'] = self.execute_time
        if self.host_address is not None:
            result['HostAddress'] = self.host_address
        if self.process_id is not None:
            result['ProcessID'] = self.process_id
        if self.sqltext is not None:
            result['SQLText'] = self.sqltext
        if self.sqltype is not None:
            result['SQLType'] = self.sqltype
        if self.succeed is not None:
            result['Succeed'] = self.succeed
        if self.total_time is not None:
            result['TotalTime'] = self.total_time
        if self.user is not None:
            result['User'] = self.user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnId') is not None:
            self.conn_id = m.get('ConnId')
        if m.get('DBName') is not None:
            self.dbname = m.get('DBName')
        if m.get('ExecuteTime') is not None:
            self.execute_time = m.get('ExecuteTime')
        if m.get('HostAddress') is not None:
            self.host_address = m.get('HostAddress')
        if m.get('ProcessID') is not None:
            self.process_id = m.get('ProcessID')
        if m.get('SQLText') is not None:
            self.sqltext = m.get('SQLText')
        if m.get('SQLType') is not None:
            self.sqltype = m.get('SQLType')
        if m.get('Succeed') is not None:
            self.succeed = m.get('Succeed')
        if m.get('TotalTime') is not None:
            self.total_time = m.get('TotalTime')
        if m.get('User') is not None:
            self.user = m.get('User')
        return self


class DescribeAuditLogRecordsResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        items: List[DescribeAuditLogRecordsResponseBodyItems] = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        self.dbcluster_id = dbcluster_id
        # The queried SQL audit logs.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeAuditLogRecordsResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAuditLogRecordsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAuditLogRecordsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAuditLogRecordsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAvailableAdvicesRequest(TeaModel):
    def __init__(
        self,
        advice_date: int = None,
        advice_type: str = None,
        dbcluster_id: str = None,
        keyword: str = None,
        lang: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        schema_table_name: str = None,
    ):
        # The date when the suggestion is generated. Specify the date in the yyyyMMdd format.
        # 
        # >  Suggestions are generated after analysis after midnight every day. You must specify a date that is at least one day earlier than the current date. For example, if the current date is 20240627, you must specify 20240626 or an earlier date.
        self.advice_date = advice_date
        # The type of the suggestion. Valid values:
        # 
        # *   **INDEX**: index optimization.
        # *   **TIERING**: hot and cold data optimization.
        self.advice_type = advice_type
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The keyword that is used to query information by table name.
        self.keyword = keyword
        # The display language of suggestions. Valid values:
        # 
        # *   **zh** (default): simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order by which to sort query results. Specify the parameter value in the JSON format. Example: `[{"Field":"SchemaName","Type":"Asc"}]`.
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `SchemaName`: the name of the database.
        #     *   `TableName`: the name of the table.
        #     *   `Benefit`: the expected benefits of the applied optimization suggestion.
        # 
        # *   `Type` specifies the sorting order. Valid values:
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        # 
        # >  If you do not specify this parameter, the query results are sorted in descending order based on the Benefit field.
        self.order = order
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the table in the DatabaseName.TableName format.
        self.schema_table_name = schema_table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advice_date is not None:
            result['AdviceDate'] = self.advice_date
        if self.advice_type is not None:
            result['AdviceType'] = self.advice_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_table_name is not None:
            result['SchemaTableName'] = self.schema_table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdviceDate') is not None:
            self.advice_date = m.get('AdviceDate')
        if m.get('AdviceType') is not None:
            self.advice_type = m.get('AdviceType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaTableName') is not None:
            self.schema_table_name = m.get('SchemaTableName')
        return self


class DescribeAvailableAdvicesResponseBodyItems(TeaModel):
    def __init__(
        self,
        advice_date: str = None,
        advice_id: str = None,
        advice_type: str = None,
        benefit: str = None,
        index_fields: str = None,
        page_number: int = None,
        page_size: int = None,
        reason: str = None,
        sql: str = None,
        schema_name: str = None,
        table_name: str = None,
        total_count: int = None,
    ):
        # The date when the suggestion is generated. The date is in the yyyyMMdd format.
        self.advice_date = advice_date
        # The suggestion ID.
        self.advice_id = advice_id
        # The type of the suggestion. Valid values:
        # 
        # *   **INDEX**: index optimization.
        # *   **TIERING**: hot and cold data optimization.
        self.advice_type = advice_type
        # The benefit of the suggestion.
        self.benefit = benefit
        self.index_fields = index_fields
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The reason why the suggestion was generated.
        self.reason = reason
        # The SQL statement that is used to apply the suggestion.
        self.sql = sql
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.advice_date is not None:
            result['AdviceDate'] = self.advice_date
        if self.advice_id is not None:
            result['AdviceId'] = self.advice_id
        if self.advice_type is not None:
            result['AdviceType'] = self.advice_type
        if self.benefit is not None:
            result['Benefit'] = self.benefit
        if self.index_fields is not None:
            result['IndexFields'] = self.index_fields
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.reason is not None:
            result['Reason'] = self.reason
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AdviceDate') is not None:
            self.advice_date = m.get('AdviceDate')
        if m.get('AdviceId') is not None:
            self.advice_id = m.get('AdviceId')
        if m.get('AdviceType') is not None:
            self.advice_type = m.get('AdviceType')
        if m.get('Benefit') is not None:
            self.benefit = m.get('Benefit')
        if m.get('IndexFields') is not None:
            self.index_fields = m.get('IndexFields')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('Reason') is not None:
            self.reason = m.get('Reason')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAvailableAdvicesResponseBody(TeaModel):
    def __init__(
        self,
        items: List[DescribeAvailableAdvicesResponseBodyItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        schema_table_names: List[str] = None,
        total_count: int = None,
    ):
        # The queried suggestions.
        self.items = items
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The name of the table in the DatabaseName.TableName format.
        self.schema_table_names = schema_table_names
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schema_table_names is not None:
            result['SchemaTableNames'] = self.schema_table_names
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeAvailableAdvicesResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SchemaTableNames') is not None:
            self.schema_table_names = m.get('SchemaTableNames')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAvailableAdvicesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeAvailableAdvicesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAvailableAdvicesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeBackupPolicyRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeBackupPolicyResponseBody(TeaModel):
    def __init__(
        self,
        backup_retention_period: int = None,
        enable_backup_log: str = None,
        log_backup_retention_period: int = None,
        preferred_backup_period: str = None,
        preferred_backup_time: str = None,
        request_id: str = None,
    ):
        # The number of days for which data backup files are retained.
        self.backup_retention_period = backup_retention_period
        # Indicates whether log backup is enabled. Valid values:
        # 
        # *   **Enable**\
        # *   **Disable**\
        self.enable_backup_log = enable_backup_log
        # The number of days for which the log backup files are retained.
        self.log_backup_retention_period = log_backup_retention_period
        # The cycle based on which backups are performed. If more than one day of the week is specified, the days of the week are separated by commas (,). Valid value:
        # 
        # *   Monday
        # *   Tuesday
        # *   Wednesday
        # *   Thursday
        # *   Friday
        # *   Saturday
        # *   Sunday
        self.preferred_backup_period = preferred_backup_period
        # The data backup time. The time is in the HH:mmZ-HH:mmZ format. The time is displayed in UTC.
        self.preferred_backup_time = preferred_backup_time
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.backup_retention_period is not None:
            result['BackupRetentionPeriod'] = self.backup_retention_period
        if self.enable_backup_log is not None:
            result['EnableBackupLog'] = self.enable_backup_log
        if self.log_backup_retention_period is not None:
            result['LogBackupRetentionPeriod'] = self.log_backup_retention_period
        if self.preferred_backup_period is not None:
            result['PreferredBackupPeriod'] = self.preferred_backup_period
        if self.preferred_backup_time is not None:
            result['PreferredBackupTime'] = self.preferred_backup_time
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BackupRetentionPeriod') is not None:
            self.backup_retention_period = m.get('BackupRetentionPeriod')
        if m.get('EnableBackupLog') is not None:
            self.enable_backup_log = m.get('EnableBackupLog')
        if m.get('LogBackupRetentionPeriod') is not None:
            self.log_backup_retention_period = m.get('LogBackupRetentionPeriod')
        if m.get('PreferredBackupPeriod') is not None:
            self.preferred_backup_period = m.get('PreferredBackupPeriod')
        if m.get('PreferredBackupTime') is not None:
            self.preferred_backup_time = m.get('PreferredBackupTime')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeBackupPolicyResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeBackupPolicyResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeBackupPolicyResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeBackupsRequest(TeaModel):
    def __init__(
        self,
        backup_id: str = None,
        dbcluster_id: str = None,
        end_time: str = None,
        owner_account: str = None,
        owner_id: int = None,
        page_number: int = None,
        page_size: int = None,
        remote: bool = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The backup set ID.
        self.backup_id = backup_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC. The end time must be later than the start time.
        # 
        # This parameter is required.
        self.end_time = end_time
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The page number. Pages start from page 1. Default value: 1
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   30
        # *   50
        # *   100
        # 
        # Default value: 30.
        self.page_size = page_size
        self.remote = remote
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.backup_id is not None:
            result['BackupId'] = self.backup_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.remote is not None:
            result['Remote'] = self.remote
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BackupId') is not None:
            self.backup_id = m.get('BackupId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('Remote') is not None:
            self.remote = m.get('Remote')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeBackupsResponseBodyItemsBackup(TeaModel):
    def __init__(
        self,
        backup_end_time: str = None,
        backup_expired_time: str = None,
        backup_id: str = None,
        backup_method: str = None,
        backup_region: str = None,
        backup_size: int = None,
        backup_start_time: str = None,
        backup_type: str = None,
        dbcluster_id: str = None,
        parent_backup_id: str = None,
    ):
        # The end time of the backup.
        self.backup_end_time = backup_end_time
        self.backup_expired_time = backup_expired_time
        # The backup set ID.
        self.backup_id = backup_id
        # The backup method. Snapshot is returned.
        self.backup_method = backup_method
        self.backup_region = backup_region
        # The size of the backup set. Unit: bytes.
        self.backup_size = backup_size
        # The start time of the backup.
        self.backup_start_time = backup_start_time
        # The backup type. Valid values:
        # 
        # *   **FullBackup**\
        # *   **IncrementalBackup**\
        self.backup_type = backup_type
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        self.parent_backup_id = parent_backup_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.backup_end_time is not None:
            result['BackupEndTime'] = self.backup_end_time
        if self.backup_expired_time is not None:
            result['BackupExpiredTime'] = self.backup_expired_time
        if self.backup_id is not None:
            result['BackupId'] = self.backup_id
        if self.backup_method is not None:
            result['BackupMethod'] = self.backup_method
        if self.backup_region is not None:
            result['BackupRegion'] = self.backup_region
        if self.backup_size is not None:
            result['BackupSize'] = self.backup_size
        if self.backup_start_time is not None:
            result['BackupStartTime'] = self.backup_start_time
        if self.backup_type is not None:
            result['BackupType'] = self.backup_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.parent_backup_id is not None:
            result['ParentBackupId'] = self.parent_backup_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BackupEndTime') is not None:
            self.backup_end_time = m.get('BackupEndTime')
        if m.get('BackupExpiredTime') is not None:
            self.backup_expired_time = m.get('BackupExpiredTime')
        if m.get('BackupId') is not None:
            self.backup_id = m.get('BackupId')
        if m.get('BackupMethod') is not None:
            self.backup_method = m.get('BackupMethod')
        if m.get('BackupRegion') is not None:
            self.backup_region = m.get('BackupRegion')
        if m.get('BackupSize') is not None:
            self.backup_size = m.get('BackupSize')
        if m.get('BackupStartTime') is not None:
            self.backup_start_time = m.get('BackupStartTime')
        if m.get('BackupType') is not None:
            self.backup_type = m.get('BackupType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ParentBackupId') is not None:
            self.parent_backup_id = m.get('ParentBackupId')
        return self


class DescribeBackupsResponseBodyItems(TeaModel):
    def __init__(
        self,
        backup: List[DescribeBackupsResponseBodyItemsBackup] = None,
    ):
        self.backup = backup

    def validate(self):
        if self.backup:
            for k in self.backup:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Backup'] = []
        if self.backup is not None:
            for k in self.backup:
                result['Backup'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.backup = []
        if m.get('Backup') is not None:
            for k in m.get('Backup'):
                temp_model = DescribeBackupsResponseBodyItemsBackup()
                self.backup.append(temp_model.from_map(k))
        return self


class DescribeBackupsResponseBody(TeaModel):
    def __init__(
        self,
        free_backup_size: int = None,
        items: DescribeBackupsResponseBodyItems = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        total_backup_size: int = None,
        total_count: str = None,
    ):
        self.free_backup_size = free_backup_size
        # The queried backup sets.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        self.total_backup_size = total_backup_size
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.free_backup_size is not None:
            result['FreeBackupSize'] = self.free_backup_size
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_backup_size is not None:
            result['TotalBackupSize'] = self.total_backup_size
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('FreeBackupSize') is not None:
            self.free_backup_size = m.get('FreeBackupSize')
        if m.get('Items') is not None:
            temp_model = DescribeBackupsResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalBackupSize') is not None:
            self.total_backup_size = m.get('TotalBackupSize')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeBackupsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeBackupsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeBackupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeBadSqlDetectionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. The end time must be later than the start time. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.end_time = end_time
        # The language. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        self.lang = lang
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeBadSqlDetectionResponseBodyDetectionItemsResultsDiagnosisResults(TeaModel):
    def __init__(
        self,
        code: str = None,
        detail: str = None,
        operator_id: str = None,
        stage_id: str = None,
    ):
        # The diagnostic code.
        self.code = code
        # The information about the diagnostic result.
        self.detail = detail
        # The operator ID.
        self.operator_id = operator_id
        # The stage ID.
        self.stage_id = stage_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.detail is not None:
            result['Detail'] = self.detail
        if self.operator_id is not None:
            result['OperatorId'] = self.operator_id
        if self.stage_id is not None:
            result['StageId'] = self.stage_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Detail') is not None:
            self.detail = m.get('Detail')
        if m.get('OperatorId') is not None:
            self.operator_id = m.get('OperatorId')
        if m.get('StageId') is not None:
            self.stage_id = m.get('StageId')
        return self


class DescribeBadSqlDetectionResponseBodyDetectionItemsResults(TeaModel):
    def __init__(
        self,
        cost: int = None,
        diagnosis_results: List[DescribeBadSqlDetectionResponseBodyDetectionItemsResultsDiagnosisResults] = None,
        operator_cost: int = None,
        output_data_size: int = None,
        pattern_id: str = None,
        peak_memory: int = None,
        process_id: str = None,
        sql: str = None,
        scan_size: int = None,
        start_time: str = None,
        total_stages: int = None,
    ):
        # The total execution duration. Unit: milliseconds.
        # 
        # >  This value is the cumulative value of the `QueuedTime`, `TotalPlanningTime`, and `ExecutionTime` parameters.
        self.cost = cost
        # The diagnostic result items.
        self.diagnosis_results = diagnosis_results
        # The total CPU time consumed by all operators in the stage, which is equivalent to the total CPU time of the stage. You can use this parameter to determine which parts of the stage consume a large amount of computing resources. Unit: milliseconds.
        self.operator_cost = operator_cost
        # The amount of returned data. Unit: bytes.
        self.output_data_size = output_data_size
        # The SQL pattern ID.
        self.pattern_id = pattern_id
        # The peak memory. Unit: bytes.
        self.peak_memory = peak_memory
        # The query ID.
        self.process_id = process_id
        # The SQL statement.
        # 
        # >  For performance considerations, an SQL statement cannot exceed 5,120 characters in length. Otherwise, the SQL statement is truncated. You can call the [DownloadDiagnosisRecords](https://help.aliyun.com/document_detail/308212.html) operation to download the information about SQL statements that meet a query condition for an AnalyticDB for MySQL cluster, including the complete SQL statements.
        self.sql = sql
        # The amount of scanned data. Unit: bytes.
        self.scan_size = scan_size
        # The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        self.start_time = start_time
        # The total number of stages generated.
        self.total_stages = total_stages

    def validate(self):
        if self.diagnosis_results:
            for k in self.diagnosis_results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cost is not None:
            result['Cost'] = self.cost
        result['DiagnosisResults'] = []
        if self.diagnosis_results is not None:
            for k in self.diagnosis_results:
                result['DiagnosisResults'].append(k.to_map() if k else None)
        if self.operator_cost is not None:
            result['OperatorCost'] = self.operator_cost
        if self.output_data_size is not None:
            result['OutputDataSize'] = self.output_data_size
        if self.pattern_id is not None:
            result['PatternId'] = self.pattern_id
        if self.peak_memory is not None:
            result['PeakMemory'] = self.peak_memory
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.scan_size is not None:
            result['ScanSize'] = self.scan_size
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.total_stages is not None:
            result['TotalStages'] = self.total_stages
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Cost') is not None:
            self.cost = m.get('Cost')
        self.diagnosis_results = []
        if m.get('DiagnosisResults') is not None:
            for k in m.get('DiagnosisResults'):
                temp_model = DescribeBadSqlDetectionResponseBodyDetectionItemsResultsDiagnosisResults()
                self.diagnosis_results.append(temp_model.from_map(k))
        if m.get('OperatorCost') is not None:
            self.operator_cost = m.get('OperatorCost')
        if m.get('OutputDataSize') is not None:
            self.output_data_size = m.get('OutputDataSize')
        if m.get('PatternId') is not None:
            self.pattern_id = m.get('PatternId')
        if m.get('PeakMemory') is not None:
            self.peak_memory = m.get('PeakMemory')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('ScanSize') is not None:
            self.scan_size = m.get('ScanSize')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('TotalStages') is not None:
            self.total_stages = m.get('TotalStages')
        return self


class DescribeBadSqlDetectionResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        results: List[DescribeBadSqlDetectionResponseBodyDetectionItemsResults] = None,
        status: str = None,
    ):
        # The information about the detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The detection result items.
        self.results = results
        # The severity level of the detection result. Valid values:
        # 
        # *   NORMAL
        # *   WARNING
        # *   CRITICAL
        self.status = status

    def validate(self):
        if self.results:
            for k in self.results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        result['Results'] = []
        if self.results is not None:
            for k in self.results:
                result['Results'].append(k.to_map() if k else None)
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        self.results = []
        if m.get('Results') is not None:
            for k in m.get('Results'):
                temp_model = DescribeBadSqlDetectionResponseBodyDetectionItemsResults()
                self.results.append(temp_model.from_map(k))
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeBadSqlDetectionResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        dbcluster_id: str = None,
        detection_items: List[DescribeBadSqlDetectionResponseBodyDetectionItems] = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeBadSqlDetectionResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeBadSqlDetectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeBadSqlDetectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeBadSqlDetectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeClusterAccessWhiteListRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        resource_owner_account: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class DescribeClusterAccessWhiteListResponseBodyItemsIPArray(TeaModel):
    def __init__(
        self,
        dbcluster_iparray_attribute: str = None,
        dbcluster_iparray_name: str = None,
        security_iplist: str = None,
    ):
        # The attribute of the IP address whitelist.
        # 
        # >  The IP address whitelists that have the **hidden** attribute are not displayed in the console. These IP address whitelists are used to access services such as Data Transmission Service (DTS) and PolarDB.
        self.dbcluster_iparray_attribute = dbcluster_iparray_attribute
        # The name of the IP address whitelist.
        # 
        # Each cluster supports up to 50 IP address whitelists.
        self.dbcluster_iparray_name = dbcluster_iparray_name
        # The IP addresses in the IP address whitelist. Up to 500 IP addresses can be returned. Multiple IP addresses are separated by commas (,).
        self.security_iplist = security_iplist

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_iparray_attribute is not None:
            result['DBClusterIPArrayAttribute'] = self.dbcluster_iparray_attribute
        if self.dbcluster_iparray_name is not None:
            result['DBClusterIPArrayName'] = self.dbcluster_iparray_name
        if self.security_iplist is not None:
            result['SecurityIPList'] = self.security_iplist
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterIPArrayAttribute') is not None:
            self.dbcluster_iparray_attribute = m.get('DBClusterIPArrayAttribute')
        if m.get('DBClusterIPArrayName') is not None:
            self.dbcluster_iparray_name = m.get('DBClusterIPArrayName')
        if m.get('SecurityIPList') is not None:
            self.security_iplist = m.get('SecurityIPList')
        return self


class DescribeClusterAccessWhiteListResponseBodyItems(TeaModel):
    def __init__(
        self,
        iparray: List[DescribeClusterAccessWhiteListResponseBodyItemsIPArray] = None,
    ):
        self.iparray = iparray

    def validate(self):
        if self.iparray:
            for k in self.iparray:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['IPArray'] = []
        if self.iparray is not None:
            for k in self.iparray:
                result['IPArray'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.iparray = []
        if m.get('IPArray') is not None:
            for k in m.get('IPArray'):
                temp_model = DescribeClusterAccessWhiteListResponseBodyItemsIPArray()
                self.iparray.append(temp_model.from_map(k))
        return self


class DescribeClusterAccessWhiteListResponseBody(TeaModel):
    def __init__(
        self,
        items: DescribeClusterAccessWhiteListResponseBodyItems = None,
        request_id: str = None,
    ):
        # The queried IP address whitelists.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Items') is not None:
            temp_model = DescribeClusterAccessWhiteListResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeClusterAccessWhiteListResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeClusterAccessWhiteListResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeClusterAccessWhiteListResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeClusterNetInfoRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class DescribeClusterNetInfoResponseBodyItemsAddressPortsPorts(TeaModel):
    def __init__(
        self,
        port: str = None,
        protocol: str = None,
    ):
        # The port.
        self.port = port
        # The type of the protocol. Valid values:
        # 
        # *   **tcp**\
        # *   **http**\
        # *   **https**\
        # *   **mysql**\
        self.protocol = protocol

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class DescribeClusterNetInfoResponseBodyItemsAddressPorts(TeaModel):
    def __init__(
        self,
        ports: List[DescribeClusterNetInfoResponseBodyItemsAddressPortsPorts] = None,
    ):
        self.ports = ports

    def validate(self):
        if self.ports:
            for k in self.ports:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ports'] = []
        if self.ports is not None:
            for k in self.ports:
                result['ports'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.ports = []
        if m.get('ports') is not None:
            for k in m.get('ports'):
                temp_model = DescribeClusterNetInfoResponseBodyItemsAddressPortsPorts()
                self.ports.append(temp_model.from_map(k))
        return self


class DescribeClusterNetInfoResponseBodyItemsAddress(TeaModel):
    def __init__(
        self,
        connection_string: str = None,
        connection_string_prefix: str = None,
        ipaddress: str = None,
        net_type: str = None,
        port: str = None,
        ports: DescribeClusterNetInfoResponseBodyItemsAddressPorts = None,
        vpcid: str = None,
        v_switch_id: str = None,
    ):
        # The endpoint of the cluster.
        # 
        # *   If NetType is set to VPC, the VPC endpoint of the cluster is returned.
        # *   If NetType is set to Public, the public endpoint of the cluster is returned.
        self.connection_string = connection_string
        # The prefix of the endpoint.
        # 
        # *   If NetType is set to VPC, the prefix of the VPC endpoint is returned.
        # *   If NetType is set to Public, the prefix of the public endpoint is returned.
        self.connection_string_prefix = connection_string_prefix
        # The IP address of the endpoint.
        # 
        # *   If NetType is set to VPC, the private IP address of the cluster is returned.
        # *   If NetType is set to Public, the public IP address of the cluster is returned.
        self.ipaddress = ipaddress
        # The network type of the cluster. Valid values:
        # 
        # *   **Public**: Internet.
        # *   **VPC**: VPC.
        self.net_type = net_type
        # The port number that is used to connect to the cluster. **3306** is returned.
        self.port = port
        # The ports.
        self.ports = ports
        # The VPC ID.
        # 
        # >  If NetType is set to Public, an empty string is returned.
        self.vpcid = vpcid
        # The vSwitch ID of the cluster.
        # 
        # >  If NetType is set to Public, an empty string is returned.
        self.v_switch_id = v_switch_id

    def validate(self):
        if self.ports:
            self.ports.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connection_string is not None:
            result['ConnectionString'] = self.connection_string
        if self.connection_string_prefix is not None:
            result['ConnectionStringPrefix'] = self.connection_string_prefix
        if self.ipaddress is not None:
            result['IPAddress'] = self.ipaddress
        if self.net_type is not None:
            result['NetType'] = self.net_type
        if self.port is not None:
            result['Port'] = self.port
        if self.ports is not None:
            result['Ports'] = self.ports.to_map()
        if self.vpcid is not None:
            result['VPCId'] = self.vpcid
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectionString') is not None:
            self.connection_string = m.get('ConnectionString')
        if m.get('ConnectionStringPrefix') is not None:
            self.connection_string_prefix = m.get('ConnectionStringPrefix')
        if m.get('IPAddress') is not None:
            self.ipaddress = m.get('IPAddress')
        if m.get('NetType') is not None:
            self.net_type = m.get('NetType')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Ports') is not None:
            temp_model = DescribeClusterNetInfoResponseBodyItemsAddressPorts()
            self.ports = temp_model.from_map(m['Ports'])
        if m.get('VPCId') is not None:
            self.vpcid = m.get('VPCId')
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        return self


class DescribeClusterNetInfoResponseBodyItems(TeaModel):
    def __init__(
        self,
        address: List[DescribeClusterNetInfoResponseBodyItemsAddress] = None,
    ):
        self.address = address

    def validate(self):
        if self.address:
            for k in self.address:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Address'] = []
        if self.address is not None:
            for k in self.address:
                result['Address'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.address = []
        if m.get('Address') is not None:
            for k in m.get('Address'):
                temp_model = DescribeClusterNetInfoResponseBodyItemsAddress()
                self.address.append(temp_model.from_map(k))
        return self


class DescribeClusterNetInfoResponseBody(TeaModel):
    def __init__(
        self,
        cluster_network_type: str = None,
        items: DescribeClusterNetInfoResponseBodyItems = None,
        request_id: str = None,
    ):
        # The network type of the cluster. Only the Virtual Private Cloud (VPC) network type is supported. **VPC** is returned.
        self.cluster_network_type = cluster_network_type
        # The queried network information about the cluster.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cluster_network_type is not None:
            result['ClusterNetworkType'] = self.cluster_network_type
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClusterNetworkType') is not None:
            self.cluster_network_type = m.get('ClusterNetworkType')
        if m.get('Items') is not None:
            temp_model = DescribeClusterNetInfoResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeClusterNetInfoResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeClusterNetInfoResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeClusterNetInfoResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeClusterResourceDetailRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DescribeClusterResourceDetailResponseBodyDataResourceGroupList(TeaModel):
    def __init__(
        self,
        cluster_mode: str = None,
        cluster_size_resource: str = None,
        enable_spot: bool = None,
        max_cluster_count: int = None,
        max_compute_resource: str = None,
        min_cluster_count: int = None,
        min_compute_resource: str = None,
        pool_id: int = None,
        pool_name: str = None,
        pool_type: str = None,
        pool_users: str = None,
        running_cluster_count: int = None,
        status: str = None,
    ):
        # A reserved parameter.
        # 
        # This parameter is required.
        self.cluster_mode = cluster_mode
        # A reserved parameter.
        self.cluster_size_resource = cluster_size_resource
        # Indicates whether the preemptible instance feature is enabled for the resource group. After the preemptible instance feature is enabled, you are charged for resources at a lower unit price but the resources are probably released. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        # 
        # The True value is returned only for job resource groups.
        self.enable_spot = enable_spot
        # A reserved parameter.
        self.max_cluster_count = max_cluster_count
        # The maximum amount of reserved computing resources.
        self.max_compute_resource = max_compute_resource
        # A reserved parameter.
        self.min_cluster_count = min_cluster_count
        # The minimum amount of reserved computing resources.
        self.min_compute_resource = min_compute_resource
        # The resource group ID.
        self.pool_id = pool_id
        # The name of the resource group.
        self.pool_name = pool_name
        # The type of the resource group.
        self.pool_type = pool_type
        # The user of the resource group.
        self.pool_users = pool_users
        # A reserved parameter.
        self.running_cluster_count = running_cluster_count
        # The status of the resource group. Valid values:
        # 
        # *   **running**\
        # *   **deleting**\
        # *   **scaling**\
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cluster_mode is not None:
            result['ClusterMode'] = self.cluster_mode
        if self.cluster_size_resource is not None:
            result['ClusterSizeResource'] = self.cluster_size_resource
        if self.enable_spot is not None:
            result['EnableSpot'] = self.enable_spot
        if self.max_cluster_count is not None:
            result['MaxClusterCount'] = self.max_cluster_count
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.min_cluster_count is not None:
            result['MinClusterCount'] = self.min_cluster_count
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        if self.pool_id is not None:
            result['PoolId'] = self.pool_id
        if self.pool_name is not None:
            result['PoolName'] = self.pool_name
        if self.pool_type is not None:
            result['PoolType'] = self.pool_type
        if self.pool_users is not None:
            result['PoolUsers'] = self.pool_users
        if self.running_cluster_count is not None:
            result['RunningClusterCount'] = self.running_cluster_count
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClusterMode') is not None:
            self.cluster_mode = m.get('ClusterMode')
        if m.get('ClusterSizeResource') is not None:
            self.cluster_size_resource = m.get('ClusterSizeResource')
        if m.get('EnableSpot') is not None:
            self.enable_spot = m.get('EnableSpot')
        if m.get('MaxClusterCount') is not None:
            self.max_cluster_count = m.get('MaxClusterCount')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MinClusterCount') is not None:
            self.min_cluster_count = m.get('MinClusterCount')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        if m.get('PoolId') is not None:
            self.pool_id = m.get('PoolId')
        if m.get('PoolName') is not None:
            self.pool_name = m.get('PoolName')
        if m.get('PoolType') is not None:
            self.pool_type = m.get('PoolType')
        if m.get('PoolUsers') is not None:
            self.pool_users = m.get('PoolUsers')
        if m.get('RunningClusterCount') is not None:
            self.running_cluster_count = m.get('RunningClusterCount')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeClusterResourceDetailResponseBodyData(TeaModel):
    def __init__(
        self,
        compute_resource: str = None,
        dbcluster_id: str = None,
        free_compute_resource: str = None,
        resource_group_list: List[DescribeClusterResourceDetailResponseBodyDataResourceGroupList] = None,
        storage_resource: str = None,
    ):
        # The amount of reserved computing resources. Unit: AnalyticDB compute units (ACUs). Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.
        self.compute_resource = compute_resource
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The amount of idle reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.
        self.free_compute_resource = free_compute_resource
        # The resource groups.
        self.resource_group_list = resource_group_list
        # The amount of reserved storage resources. Unit: ACUs. Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.
        self.storage_resource = storage_resource

    def validate(self):
        if self.resource_group_list:
            for k in self.resource_group_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.compute_resource is not None:
            result['ComputeResource'] = self.compute_resource
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.free_compute_resource is not None:
            result['FreeComputeResource'] = self.free_compute_resource
        result['ResourceGroupList'] = []
        if self.resource_group_list is not None:
            for k in self.resource_group_list:
                result['ResourceGroupList'].append(k.to_map() if k else None)
        if self.storage_resource is not None:
            result['StorageResource'] = self.storage_resource
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ComputeResource') is not None:
            self.compute_resource = m.get('ComputeResource')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FreeComputeResource') is not None:
            self.free_compute_resource = m.get('FreeComputeResource')
        self.resource_group_list = []
        if m.get('ResourceGroupList') is not None:
            for k in m.get('ResourceGroupList'):
                temp_model = DescribeClusterResourceDetailResponseBodyDataResourceGroupList()
                self.resource_group_list.append(temp_model.from_map(k))
        if m.get('StorageResource') is not None:
            self.storage_resource = m.get('StorageResource')
        return self


class DescribeClusterResourceDetailResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: DescribeClusterResourceDetailResponseBodyData = None,
        request_id: str = None,
    ):
        # The HTTP status code.
        self.code = code
        # The queried resource usage.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = DescribeClusterResourceDetailResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeClusterResourceDetailResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeClusterResourceDetailResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeClusterResourceDetailResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeClusterResourceUsageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.end_time = end_time
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeClusterResourceUsageResponseBodyDataAcuInfo(TeaModel):
    def __init__(
        self,
        name: str = None,
        values: List[str] = None,
    ):
        # The resource usage metric. Valid values:
        # 
        # *   `TotalAcuNumber`: the total number of ACUs.
        # *   `ReservedAcuNumber`: the number of ACUs for the reserved resources.
        # *   `ReservedAcuUsageNumber`: the number of ACUs for the reserved resources that are used.
        self.name = name
        # The values of the metric at specific points in time.
        self.values = values

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.values is not None:
            result['Values'] = self.values
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Values') is not None:
            self.values = m.get('Values')
        return self


class DescribeClusterResourceUsageResponseBodyData(TeaModel):
    def __init__(
        self,
        acu_info: List[DescribeClusterResourceUsageResponseBodyDataAcuInfo] = None,
        dbcluster_id: str = None,
        end_time: str = None,
        start_time: str = None,
    ):
        # The AnalyticDB compute unit (ACU) usage of the cluster.
        self.acu_info = acu_info
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        self.end_time = end_time
        # The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        self.start_time = start_time

    def validate(self):
        if self.acu_info:
            for k in self.acu_info:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcuInfo'] = []
        if self.acu_info is not None:
            for k in self.acu_info:
                result['AcuInfo'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.acu_info = []
        if m.get('AcuInfo') is not None:
            for k in m.get('AcuInfo'):
                temp_model = DescribeClusterResourceUsageResponseBodyDataAcuInfo()
                self.acu_info.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeClusterResourceUsageResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: DescribeClusterResourceUsageResponseBodyData = None,
        request_id: str = None,
    ):
        # The HTTP status code.
        self.code = code
        # The queried resource usage.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = DescribeClusterResourceUsageResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeClusterResourceUsageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeClusterResourceUsageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeClusterResourceUsageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeColumnsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeColumnsResponseBodyItemsColumn(TeaModel):
    def __init__(
        self,
        auto_increment_column: bool = None,
        column_name: str = None,
        dbcluster_id: str = None,
        primary_key: bool = None,
        schema_name: str = None,
        table_name: str = None,
        type: str = None,
    ):
        # Indicates whether the column is an auto-increment column. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.auto_increment_column = auto_increment_column
        # The name of the column.
        self.column_name = column_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # Indicates whether the column is the primary key of the table. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.primary_key = primary_key
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name
        # The data type of the column.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_increment_column is not None:
            result['AutoIncrementColumn'] = self.auto_increment_column
        if self.column_name is not None:
            result['ColumnName'] = self.column_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.primary_key is not None:
            result['PrimaryKey'] = self.primary_key
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoIncrementColumn') is not None:
            self.auto_increment_column = m.get('AutoIncrementColumn')
        if m.get('ColumnName') is not None:
            self.column_name = m.get('ColumnName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PrimaryKey') is not None:
            self.primary_key = m.get('PrimaryKey')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeColumnsResponseBodyItems(TeaModel):
    def __init__(
        self,
        column: List[DescribeColumnsResponseBodyItemsColumn] = None,
    ):
        self.column = column

    def validate(self):
        if self.column:
            for k in self.column:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Column'] = []
        if self.column is not None:
            for k in self.column:
                result['Column'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.column = []
        if m.get('Column') is not None:
            for k in m.get('Column'):
                temp_model = DescribeColumnsResponseBodyItemsColumn()
                self.column.append(temp_model.from_map(k))
        return self


class DescribeColumnsResponseBody(TeaModel):
    def __init__(
        self,
        items: DescribeColumnsResponseBodyItems = None,
        request_id: str = None,
    ):
        # The queried columns.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Items') is not None:
            temp_model = DescribeColumnsResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeColumnsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeColumnsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeColumnsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeCompactionServiceSwitchRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DescribeCompactionServiceSwitchResponseBodyData(TeaModel):
    def __init__(
        self,
        enable_compaction_service: bool = None,
    ):
        # Indicates whether the remote build feature is enabled.
        # 
        # Valid values:
        # 
        # *   true
        # *   false
        self.enable_compaction_service = enable_compaction_service

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.enable_compaction_service is not None:
            result['EnableCompactionService'] = self.enable_compaction_service
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EnableCompactionService') is not None:
            self.enable_compaction_service = m.get('EnableCompactionService')
        return self


class DescribeCompactionServiceSwitchResponseBody(TeaModel):
    def __init__(
        self,
        data: DescribeCompactionServiceSwitchResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DescribeCompactionServiceSwitchResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeCompactionServiceSwitchResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeCompactionServiceSwitchResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeCompactionServiceSwitchResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeComputeResourceUsageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        resource_group_name: str = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        # 
        # This parameter is required.
        self.end_time = end_time
        # The name of the resource group.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeComputeResourceUsageResponseBodyDataAcuInfo(TeaModel):
    def __init__(
        self,
        name: str = None,
        values: List[str] = None,
    ):
        # The resource usage metric. Valid values:
        # 
        # *   `TotalAcuNumber`: the total number of ACUs.
        # *   `ReservedAcuNumber`: the number of ACUs for the reserved resources.
        # *   `ReservedAcuUsageNumber`: the number of ACUs for the reserved resources that are used.
        self.name = name
        # The values of the metric at specific points in time.
        self.values = values

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.values is not None:
            result['Values'] = self.values
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Values') is not None:
            self.values = m.get('Values')
        return self


class DescribeComputeResourceUsageResponseBodyData(TeaModel):
    def __init__(
        self,
        acu_info: List[DescribeComputeResourceUsageResponseBodyDataAcuInfo] = None,
        dbcluster_id: str = None,
        end_time: str = None,
        resource_group_name: str = None,
        resource_group_type: str = None,
        start_time: str = None,
    ):
        # The AnalyticDB compute unit (ACU) usage of the cluster.
        self.acu_info = acu_info
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        self.end_time = end_time
        # The name of the resource group.
        self.resource_group_name = resource_group_name
        # The type of the resource group.
        self.resource_group_type = resource_group_type
        # The start time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.start_time = start_time

    def validate(self):
        if self.acu_info:
            for k in self.acu_info:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcuInfo'] = []
        if self.acu_info is not None:
            for k in self.acu_info:
                result['AcuInfo'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.resource_group_type is not None:
            result['ResourceGroupType'] = self.resource_group_type
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.acu_info = []
        if m.get('AcuInfo') is not None:
            for k in m.get('AcuInfo'):
                temp_model = DescribeComputeResourceUsageResponseBodyDataAcuInfo()
                self.acu_info.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('ResourceGroupType') is not None:
            self.resource_group_type = m.get('ResourceGroupType')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeComputeResourceUsageResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: DescribeComputeResourceUsageResponseBodyData = None,
        request_id: str = None,
    ):
        # The HTTP status code.
        self.code = code
        # The queried resource usage.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = DescribeComputeResourceUsageResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeComputeResourceUsageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeComputeResourceUsageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeComputeResourceUsageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeControllerDetectionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # > 
        # 
        # *   You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/98094.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mmZ** format. The time must be in UTC.
        # 
        # >  The end time must be later than the start time. The maximum time range that can be specified is 30 days.
        self.end_time = end_time
        # The language. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        self.lang = lang
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeControllerDetectionResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        status: str = None,
    ):
        # The information about the detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The severity level of the detection result. Valid values:
        # 
        # *   NORMAL
        # *   WARNING
        # *   CRITICAL
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeControllerDetectionResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        detection_items: List[DescribeControllerDetectionResponseBodyDetectionItems] = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeControllerDetectionResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeControllerDetectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeControllerDetectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeControllerDetectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBClusterAttributeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DescribeDBClusterAttributeResponseBodyItemsDBClusterTagsTag(TeaModel):
    def __init__(
        self,
        key: str = None,
        value: str = None,
    ):
        # The tag key.
        # 
        # >  You can call the [TagResources](https://help.aliyun.com/document_detail/179253.html) operation to add tags to a cluster.
        self.key = key
        # The tag value.
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeDBClusterAttributeResponseBodyItemsDBClusterTags(TeaModel):
    def __init__(
        self,
        tag: List[DescribeDBClusterAttributeResponseBodyItemsDBClusterTagsTag] = None,
    ):
        self.tag = tag

    def validate(self):
        if self.tag:
            for k in self.tag:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Tag'] = []
        if self.tag is not None:
            for k in self.tag:
                result['Tag'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.tag = []
        if m.get('Tag') is not None:
            for k in m.get('Tag'):
                temp_model = DescribeDBClusterAttributeResponseBodyItemsDBClusterTagsTag()
                self.tag.append(temp_model.from_map(k))
        return self


class DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfoStepListStepList(TeaModel):
    def __init__(
        self,
        end_time: str = None,
        start_time: str = None,
        step_desc: str = None,
        step_name: str = None,
        step_progress: str = None,
        step_status: str = None,
    ):
        # The end time of the job step. The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. The time is displayed in UTC.
        self.end_time = end_time
        # The start time of the job step. The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. The time is displayed in UTC.
        self.start_time = start_time
        # The description of the job step.
        self.step_desc = step_desc
        # The name of the job step.
        self.step_name = step_name
        # The progress of the job step. Unit: %.
        self.step_progress = step_progress
        # The status of the job step. Valid values:
        # 
        # *   NOT_RUN
        # *   RUNNING
        # *   SUCCEED
        self.step_status = step_status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.step_desc is not None:
            result['StepDesc'] = self.step_desc
        if self.step_name is not None:
            result['StepName'] = self.step_name
        if self.step_progress is not None:
            result['StepProgress'] = self.step_progress
        if self.step_status is not None:
            result['StepStatus'] = self.step_status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StepDesc') is not None:
            self.step_desc = m.get('StepDesc')
        if m.get('StepName') is not None:
            self.step_name = m.get('StepName')
        if m.get('StepProgress') is not None:
            self.step_progress = m.get('StepProgress')
        if m.get('StepStatus') is not None:
            self.step_status = m.get('StepStatus')
        return self


class DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfoStepList(TeaModel):
    def __init__(
        self,
        step_list: List[DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfoStepListStepList] = None,
    ):
        self.step_list = step_list

    def validate(self):
        if self.step_list:
            for k in self.step_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['StepList'] = []
        if self.step_list is not None:
            for k in self.step_list:
                result['StepList'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.step_list = []
        if m.get('StepList') is not None:
            for k in m.get('StepList'):
                temp_model = DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfoStepListStepList()
                self.step_list.append(temp_model.from_map(k))
        return self


class DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfo(TeaModel):
    def __init__(
        self,
        name: str = None,
        progress: str = None,
        status: str = None,
        step_list: DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfoStepList = None,
    ):
        # The name of the job.
        self.name = name
        # The progress of the job. Unit: %.
        self.progress = progress
        # The status of the job. Valid values:
        # 
        # *   NOT_RUN
        # *   RUNNING
        # *   SUCCEED
        self.status = status
        # The job steps.
        self.step_list = step_list

    def validate(self):
        if self.step_list:
            self.step_list.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.progress is not None:
            result['Progress'] = self.progress
        if self.status is not None:
            result['Status'] = self.status
        if self.step_list is not None:
            result['StepList'] = self.step_list.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Progress') is not None:
            self.progress = m.get('Progress')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('StepList') is not None:
            temp_model = DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfoStepList()
            self.step_list = temp_model.from_map(m['StepList'])
        return self


class DescribeDBClusterAttributeResponseBodyItemsDBCluster(TeaModel):
    def __init__(
        self,
        ainode_number: int = None,
        ainode_spec: str = None,
        clickhouse_engine_cache_size: int = None,
        clickhouse_engine_enabled: bool = None,
        commodity_code: str = None,
        compute_resource: str = None,
        compute_resource_total: str = None,
        connection_string: str = None,
        creation_time: str = None,
        dbcluster_description: str = None,
        dbcluster_id: str = None,
        dbcluster_network_type: str = None,
        dbcluster_status: str = None,
        dbcluster_type: str = None,
        dbversion: str = None,
        disk_encryption: bool = None,
        engine: str = None,
        engine_version: str = None,
        expire_time: str = None,
        expired: str = None,
        kms_id: str = None,
        lock_mode: str = None,
        lock_reason: str = None,
        maintain_time: str = None,
        mode: str = None,
        pay_type: str = None,
        port: int = None,
        product_form: str = None,
        product_version: str = None,
        region_id: str = None,
        reserved_acu: str = None,
        reserved_node_count: int = None,
        reserved_node_size: str = None,
        resource_group_id: str = None,
        secondary_vswitch_id: str = None,
        secondary_zone_id: str = None,
        storage_resource: str = None,
        storage_resource_total: str = None,
        supported_features: Dict[str, str] = None,
        tags: DescribeDBClusterAttributeResponseBodyItemsDBClusterTags = None,
        task_info: DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfo = None,
        user_enistatus: bool = None,
        user_enivswitch_options: str = None,
        user_enivpc_id: str = None,
        user_enizone_options: str = None,
        vpcid: str = None,
        v_switch_id: str = None,
        zone_id: str = None,
    ):
        self.ainode_number = ainode_number
        self.ainode_spec = ainode_spec
        # The cache size of the ClickHouse wide table engine. Unit: GB. If a value of -1 is returned, the ClickHouse wide table engine is disabled. If a value other than -1 is returned, this parameter indicates the disk cache size.
        self.clickhouse_engine_cache_size = clickhouse_engine_cache_size
        # Indicates whether the ClickHouse wide table engine is enabled. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.clickhouse_engine_enabled = clickhouse_engine_enabled
        # The billing method of the cluster. Valid values:
        # 
        # *   **ads**: pay-as-you-go.
        # *   **ads_pre**: subscription.
        self.commodity_code = commodity_code
        # The specifications of reserved computing resources. Each ACU is approximately equal to 1 core and 4 GB memory. Computing resources are used to compute data. The increase in the computing resources can accelerate queries. You can scale computing resources based on your business requirements.
        self.compute_resource = compute_resource
        # The total amount of computing resources in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.
        self.compute_resource_total = compute_resource_total
        # The public endpoint that is used to connect to the cluster.
        self.connection_string = connection_string
        # The time when the cluster was created. The time follows the ISO 8601 standard in the `YYYY-MM-DDThh:mm:ssZ` format. The time is displayed in UTC.
        self.creation_time = creation_time
        # The description of the cluster.
        self.dbcluster_description = dbcluster_description
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        self.dbcluster_id = dbcluster_id
        # The network type of the cluster. **VPC** is returned.
        self.dbcluster_network_type = dbcluster_network_type
        # The status of the cluster. Valid values:
        # 
        # *   **Preparing**\
        # *   **Creating**\
        # *   **Running**\
        # *   **Deleting**\
        # *   **Restoring**\
        # *   **ClassChanging**\
        # *   **NetAddressCreating**\
        # *   **NetAddressDeleting**\
        # *   **NetAddressModifying**\
        self.dbcluster_status = dbcluster_status
        # The type of the cluster. By default, **Common** is returned, which indicates a common cluster.
        self.dbcluster_type = dbcluster_type
        # The engine version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. **5.0** is returned.
        self.dbversion = dbversion
        self.disk_encryption = disk_encryption
        # The engine of the cluster. **AnalyticDB** is returned.
        self.engine = engine
        # The minor version of the cluster.
        self.engine_version = engine_version
        # The time when the cluster expires.
        # 
        # *   If the billing method of the cluster is subscription, the actual expiration time is returned.
        # *   If the billing method of the cluster is pay-as-you-go, null is returned.
        self.expire_time = expire_time
        # Indicates whether the subscription cluster has expired. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        # 
        # > 
        # 
        # *   If the cluster has expired, the system locks or releases the cluster within a period of time. We recommend that you renew the expired cluster. For more information, see [Renewal policy](https://help.aliyun.com/document_detail/135248.html).
        # 
        # *   This parameter is not returned for pay-as-you-go clusters.
        self.expired = expired
        # The ID of the key that is used to encrypt disk data.
        # 
        # >  This parameter is returned only when disk encryption is enabled.
        self.kms_id = kms_id
        # The lock mode of the cluster. Valid values:
        # 
        # *   **Unlock**: The cluster is not locked.
        # *   **ManualLock**: The cluster is manually locked.
        # *   **LockByExpiration**: The cluster is automatically locked due to cluster expiration.
        self.lock_mode = lock_mode
        # The reason why the cluster is locked.
        # 
        # >  This parameter is returned only when the cluster was locked. **instance_expire** is returned.
        self.lock_reason = lock_reason
        # The maintenance window of the cluster. The time is displayed in the `HH:mmZ-HH:mmZ` format in UTC.
        # 
        # >  For more information about maintenance windows, see [Configure a maintenance window](https://help.aliyun.com/document_detail/122569.html).
        self.maintain_time = maintain_time
        # The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.
        self.mode = mode
        # The billing method of the cluster. Valid values:
        # 
        # *   **Postpaid**: pay-as-you-go.
        # *   **Prepaid**: subscription.
        self.pay_type = pay_type
        # The port number that is used to connect to the cluster.
        self.port = port
        # A reserved parameter.
        self.product_form = product_form
        # The edition of the cluster. Valid values:
        # 
        # *   **BasicVersion**: Basic Edition.
        # *   **EnterpriseVersion**: Enterprise Edition.
        self.product_version = product_version
        # The region ID of the cluster.
        self.region_id = region_id
        # The amount of remaining reserved computing resources that are available in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.
        self.reserved_acu = reserved_acu
        # A reserved parameter.
        self.reserved_node_count = reserved_node_count
        # A reserved parameter.
        self.reserved_node_size = reserved_node_size
        # The resource group ID.
        self.resource_group_id = resource_group_id
        self.secondary_vswitch_id = secondary_vswitch_id
        self.secondary_zone_id = secondary_zone_id
        # The specifications of reserved storage resources. Each AnalyticDB compute unit (ACU) is approximately equal to 1 core and 4 GB memory. Storage resources are used to read and write data. The increase in the storage resources can improve the read and write performance of the cluster.
        self.storage_resource = storage_resource
        # The total amount of storage resources in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.
        self.storage_resource_total = storage_resource_total
        # Reserved parameters.
        self.supported_features = supported_features
        # The tags that are added to the cluster.
        self.tags = tags
        # The job information.
        self.task_info = task_info
        # Indicates whether Elastic Network Interface (ENI) is enabled. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.user_enistatus = user_enistatus
        # The vSwitch connected to the ENI. Separate multiple vSwitches with commas (,).
        self.user_enivswitch_options = user_enivswitch_options
        # The VPC information of the ENI.
        self.user_enivpc_id = user_enivpc_id
        # The zone associated with the ENI. Separate multiple zones with commas (,).
        self.user_enizone_options = user_enizone_options
        # The virtual private cloud (VPC) ID of the cluster.
        self.vpcid = vpcid
        # The vSwitch ID of the cluster.
        self.v_switch_id = v_switch_id
        # The zone ID of the cluster.
        self.zone_id = zone_id

    def validate(self):
        if self.tags:
            self.tags.validate()
        if self.task_info:
            self.task_info.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.ainode_number is not None:
            result['AINodeNumber'] = self.ainode_number
        if self.ainode_spec is not None:
            result['AINodeSpec'] = self.ainode_spec
        if self.clickhouse_engine_cache_size is not None:
            result['ClickhouseEngineCacheSize'] = self.clickhouse_engine_cache_size
        if self.clickhouse_engine_enabled is not None:
            result['ClickhouseEngineEnabled'] = self.clickhouse_engine_enabled
        if self.commodity_code is not None:
            result['CommodityCode'] = self.commodity_code
        if self.compute_resource is not None:
            result['ComputeResource'] = self.compute_resource
        if self.compute_resource_total is not None:
            result['ComputeResourceTotal'] = self.compute_resource_total
        if self.connection_string is not None:
            result['ConnectionString'] = self.connection_string
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.dbcluster_network_type is not None:
            result['DBClusterNetworkType'] = self.dbcluster_network_type
        if self.dbcluster_status is not None:
            result['DBClusterStatus'] = self.dbcluster_status
        if self.dbcluster_type is not None:
            result['DBClusterType'] = self.dbcluster_type
        if self.dbversion is not None:
            result['DBVersion'] = self.dbversion
        if self.disk_encryption is not None:
            result['DiskEncryption'] = self.disk_encryption
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.engine_version is not None:
            result['EngineVersion'] = self.engine_version
        if self.expire_time is not None:
            result['ExpireTime'] = self.expire_time
        if self.expired is not None:
            result['Expired'] = self.expired
        if self.kms_id is not None:
            result['KmsId'] = self.kms_id
        if self.lock_mode is not None:
            result['LockMode'] = self.lock_mode
        if self.lock_reason is not None:
            result['LockReason'] = self.lock_reason
        if self.maintain_time is not None:
            result['MaintainTime'] = self.maintain_time
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.pay_type is not None:
            result['PayType'] = self.pay_type
        if self.port is not None:
            result['Port'] = self.port
        if self.product_form is not None:
            result['ProductForm'] = self.product_form
        if self.product_version is not None:
            result['ProductVersion'] = self.product_version
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.reserved_acu is not None:
            result['ReservedACU'] = self.reserved_acu
        if self.reserved_node_count is not None:
            result['ReservedNodeCount'] = self.reserved_node_count
        if self.reserved_node_size is not None:
            result['ReservedNodeSize'] = self.reserved_node_size
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.secondary_vswitch_id is not None:
            result['SecondaryVSwitchId'] = self.secondary_vswitch_id
        if self.secondary_zone_id is not None:
            result['SecondaryZoneId'] = self.secondary_zone_id
        if self.storage_resource is not None:
            result['StorageResource'] = self.storage_resource
        if self.storage_resource_total is not None:
            result['StorageResourceTotal'] = self.storage_resource_total
        if self.supported_features is not None:
            result['SupportedFeatures'] = self.supported_features
        if self.tags is not None:
            result['Tags'] = self.tags.to_map()
        if self.task_info is not None:
            result['TaskInfo'] = self.task_info.to_map()
        if self.user_enistatus is not None:
            result['UserENIStatus'] = self.user_enistatus
        if self.user_enivswitch_options is not None:
            result['UserENIVSwitchOptions'] = self.user_enivswitch_options
        if self.user_enivpc_id is not None:
            result['UserENIVpcId'] = self.user_enivpc_id
        if self.user_enizone_options is not None:
            result['UserENIZoneOptions'] = self.user_enizone_options
        if self.vpcid is not None:
            result['VPCId'] = self.vpcid
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AINodeNumber') is not None:
            self.ainode_number = m.get('AINodeNumber')
        if m.get('AINodeSpec') is not None:
            self.ainode_spec = m.get('AINodeSpec')
        if m.get('ClickhouseEngineCacheSize') is not None:
            self.clickhouse_engine_cache_size = m.get('ClickhouseEngineCacheSize')
        if m.get('ClickhouseEngineEnabled') is not None:
            self.clickhouse_engine_enabled = m.get('ClickhouseEngineEnabled')
        if m.get('CommodityCode') is not None:
            self.commodity_code = m.get('CommodityCode')
        if m.get('ComputeResource') is not None:
            self.compute_resource = m.get('ComputeResource')
        if m.get('ComputeResourceTotal') is not None:
            self.compute_resource_total = m.get('ComputeResourceTotal')
        if m.get('ConnectionString') is not None:
            self.connection_string = m.get('ConnectionString')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DBClusterNetworkType') is not None:
            self.dbcluster_network_type = m.get('DBClusterNetworkType')
        if m.get('DBClusterStatus') is not None:
            self.dbcluster_status = m.get('DBClusterStatus')
        if m.get('DBClusterType') is not None:
            self.dbcluster_type = m.get('DBClusterType')
        if m.get('DBVersion') is not None:
            self.dbversion = m.get('DBVersion')
        if m.get('DiskEncryption') is not None:
            self.disk_encryption = m.get('DiskEncryption')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('EngineVersion') is not None:
            self.engine_version = m.get('EngineVersion')
        if m.get('ExpireTime') is not None:
            self.expire_time = m.get('ExpireTime')
        if m.get('Expired') is not None:
            self.expired = m.get('Expired')
        if m.get('KmsId') is not None:
            self.kms_id = m.get('KmsId')
        if m.get('LockMode') is not None:
            self.lock_mode = m.get('LockMode')
        if m.get('LockReason') is not None:
            self.lock_reason = m.get('LockReason')
        if m.get('MaintainTime') is not None:
            self.maintain_time = m.get('MaintainTime')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('PayType') is not None:
            self.pay_type = m.get('PayType')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ProductForm') is not None:
            self.product_form = m.get('ProductForm')
        if m.get('ProductVersion') is not None:
            self.product_version = m.get('ProductVersion')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ReservedACU') is not None:
            self.reserved_acu = m.get('ReservedACU')
        if m.get('ReservedNodeCount') is not None:
            self.reserved_node_count = m.get('ReservedNodeCount')
        if m.get('ReservedNodeSize') is not None:
            self.reserved_node_size = m.get('ReservedNodeSize')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('SecondaryVSwitchId') is not None:
            self.secondary_vswitch_id = m.get('SecondaryVSwitchId')
        if m.get('SecondaryZoneId') is not None:
            self.secondary_zone_id = m.get('SecondaryZoneId')
        if m.get('StorageResource') is not None:
            self.storage_resource = m.get('StorageResource')
        if m.get('StorageResourceTotal') is not None:
            self.storage_resource_total = m.get('StorageResourceTotal')
        if m.get('SupportedFeatures') is not None:
            self.supported_features = m.get('SupportedFeatures')
        if m.get('Tags') is not None:
            temp_model = DescribeDBClusterAttributeResponseBodyItemsDBClusterTags()
            self.tags = temp_model.from_map(m['Tags'])
        if m.get('TaskInfo') is not None:
            temp_model = DescribeDBClusterAttributeResponseBodyItemsDBClusterTaskInfo()
            self.task_info = temp_model.from_map(m['TaskInfo'])
        if m.get('UserENIStatus') is not None:
            self.user_enistatus = m.get('UserENIStatus')
        if m.get('UserENIVSwitchOptions') is not None:
            self.user_enivswitch_options = m.get('UserENIVSwitchOptions')
        if m.get('UserENIVpcId') is not None:
            self.user_enivpc_id = m.get('UserENIVpcId')
        if m.get('UserENIZoneOptions') is not None:
            self.user_enizone_options = m.get('UserENIZoneOptions')
        if m.get('VPCId') is not None:
            self.vpcid = m.get('VPCId')
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class DescribeDBClusterAttributeResponseBodyItems(TeaModel):
    def __init__(
        self,
        dbcluster: List[DescribeDBClusterAttributeResponseBodyItemsDBCluster] = None,
    ):
        self.dbcluster = dbcluster

    def validate(self):
        if self.dbcluster:
            for k in self.dbcluster:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['DBCluster'] = []
        if self.dbcluster is not None:
            for k in self.dbcluster:
                result['DBCluster'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.dbcluster = []
        if m.get('DBCluster') is not None:
            for k in m.get('DBCluster'):
                temp_model = DescribeDBClusterAttributeResponseBodyItemsDBCluster()
                self.dbcluster.append(temp_model.from_map(k))
        return self


class DescribeDBClusterAttributeResponseBody(TeaModel):
    def __init__(
        self,
        items: DescribeDBClusterAttributeResponseBodyItems = None,
        request_id: str = None,
    ):
        # The queried cluster.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Items') is not None:
            temp_model = DescribeDBClusterAttributeResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeDBClusterAttributeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBClusterAttributeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBClusterAttributeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBClusterHealthStatusRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeDBClusterHealthStatusResponseBodyCS(TeaModel):
    def __init__(
        self,
        active_count: int = None,
        expected_count: int = None,
        risk_count: int = None,
        status: str = None,
        unavailable_count: int = None,
    ):
        # The number of healthy access nodes.
        self.active_count = active_count
        # The total number of access nodes.
        self.expected_count = expected_count
        # The number of risky nodes.
        self.risk_count = risk_count
        # The health state of access nodes. Valid values:
        # 
        # *   **RISK**\
        # *   **NORMAL**\
        # *   **UNAVAILABLE**\
        self.status = status
        # The number of unavailable access nodes.
        self.unavailable_count = unavailable_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_count is not None:
            result['ActiveCount'] = self.active_count
        if self.expected_count is not None:
            result['ExpectedCount'] = self.expected_count
        if self.risk_count is not None:
            result['RiskCount'] = self.risk_count
        if self.status is not None:
            result['Status'] = self.status
        if self.unavailable_count is not None:
            result['UnavailableCount'] = self.unavailable_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ActiveCount') is not None:
            self.active_count = m.get('ActiveCount')
        if m.get('ExpectedCount') is not None:
            self.expected_count = m.get('ExpectedCount')
        if m.get('RiskCount') is not None:
            self.risk_count = m.get('RiskCount')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('UnavailableCount') is not None:
            self.unavailable_count = m.get('UnavailableCount')
        return self


class DescribeDBClusterHealthStatusResponseBodyExecutor(TeaModel):
    def __init__(
        self,
        active_count: int = None,
        expected_count: int = None,
        risk_count: int = None,
        status: str = None,
        unavailable_count: int = None,
    ):
        # The number of healthy access nodes.
        self.active_count = active_count
        # The total number of compute nodes.
        self.expected_count = expected_count
        # The number of risky nodes.
        self.risk_count = risk_count
        # The health state of compute node groups. Valid values:
        # 
        # *   **RISK**\
        # *   **NORMAL**\
        # *   **UNAVAILABLE**\
        self.status = status
        # The number of unavailable access nodes.
        self.unavailable_count = unavailable_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_count is not None:
            result['ActiveCount'] = self.active_count
        if self.expected_count is not None:
            result['ExpectedCount'] = self.expected_count
        if self.risk_count is not None:
            result['RiskCount'] = self.risk_count
        if self.status is not None:
            result['Status'] = self.status
        if self.unavailable_count is not None:
            result['UnavailableCount'] = self.unavailable_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ActiveCount') is not None:
            self.active_count = m.get('ActiveCount')
        if m.get('ExpectedCount') is not None:
            self.expected_count = m.get('ExpectedCount')
        if m.get('RiskCount') is not None:
            self.risk_count = m.get('RiskCount')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('UnavailableCount') is not None:
            self.unavailable_count = m.get('UnavailableCount')
        return self


class DescribeDBClusterHealthStatusResponseBodyWorker(TeaModel):
    def __init__(
        self,
        active_count: int = None,
        expected_count: int = None,
        risk_count: int = None,
        status: str = None,
        unavailable_count: int = None,
    ):
        # The number of healthy storage node groups.
        self.active_count = active_count
        # The total number of storage node groups.
        self.expected_count = expected_count
        # The number of risky storage node groups.
        self.risk_count = risk_count
        # The health state of storage node groups. Valid values:
        # 
        # *   **RISK**\
        # *   **NORMAL**\
        # *   **UNAVAILABLE**\
        self.status = status
        # The number of unavailable storage node groups.
        self.unavailable_count = unavailable_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_count is not None:
            result['ActiveCount'] = self.active_count
        if self.expected_count is not None:
            result['ExpectedCount'] = self.expected_count
        if self.risk_count is not None:
            result['RiskCount'] = self.risk_count
        if self.status is not None:
            result['Status'] = self.status
        if self.unavailable_count is not None:
            result['UnavailableCount'] = self.unavailable_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ActiveCount') is not None:
            self.active_count = m.get('ActiveCount')
        if m.get('ExpectedCount') is not None:
            self.expected_count = m.get('ExpectedCount')
        if m.get('RiskCount') is not None:
            self.risk_count = m.get('RiskCount')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('UnavailableCount') is not None:
            self.unavailable_count = m.get('UnavailableCount')
        return self


class DescribeDBClusterHealthStatusResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        cs: DescribeDBClusterHealthStatusResponseBodyCS = None,
        executor: DescribeDBClusterHealthStatusResponseBodyExecutor = None,
        instance_status: str = None,
        request_id: str = None,
        worker: DescribeDBClusterHealthStatusResponseBodyWorker = None,
    ):
        self.access_denied_detail = access_denied_detail
        # The access nodes of the queried cluster.
        self.cs = cs
        # The compute node groups of the queried cluster.
        self.executor = executor
        # The health state of the cluster. Valid values:
        # 
        # *   **RISK**\
        # *   **NORMAL**\
        # *   **UNAVAILABLE**\
        # 
        # >  When the states of the access nodes, compute node groups, and storage node groups of a cluster are all **NORMAL** and a connection to the cluster is established, the state of the cluster is **NORMAL**. When the state of the access nodes, compute node groups, or storage node groups of the cluster is **RISK**, the state of the cluster is **RISK**. When the state of the access nodes, compute node groups, or storage node groups of the cluster is **UNAVAILABLE**, the state of the cluster is **UNAVAILABLE**.
        self.instance_status = instance_status
        # The request ID.
        self.request_id = request_id
        # The storage node groups of the queried cluster.
        self.worker = worker

    def validate(self):
        if self.cs:
            self.cs.validate()
        if self.executor:
            self.executor.validate()
        if self.worker:
            self.worker.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.cs is not None:
            result['CS'] = self.cs.to_map()
        if self.executor is not None:
            result['Executor'] = self.executor.to_map()
        if self.instance_status is not None:
            result['InstanceStatus'] = self.instance_status
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.worker is not None:
            result['Worker'] = self.worker.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('CS') is not None:
            temp_model = DescribeDBClusterHealthStatusResponseBodyCS()
            self.cs = temp_model.from_map(m['CS'])
        if m.get('Executor') is not None:
            temp_model = DescribeDBClusterHealthStatusResponseBodyExecutor()
            self.executor = temp_model.from_map(m['Executor'])
        if m.get('InstanceStatus') is not None:
            self.instance_status = m.get('InstanceStatus')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Worker') is not None:
            temp_model = DescribeDBClusterHealthStatusResponseBodyWorker()
            self.worker = temp_model.from_map(m['Worker'])
        return self


class DescribeDBClusterHealthStatusResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBClusterHealthStatusResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBClusterHealthStatusResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBClusterPerformanceRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        key: str = None,
        region_id: str = None,
        resource_pools: str = None,
        start_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](~~~612397~~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        # 
        # > The end time must be later than the start time. The maximum time range that can be specified is two days.
        self.end_time = end_time
        # The key of the performance metric that you want to query. Separate multiple keys with commas (,). For more information about the performance metrics, see [Metric overview](https://help.aliyun.com/document_detail/2863211.html).
        self.key = key
        # The region ID of the cluster.
        # 
        # > You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The resource group ID.
        self.resource_pools = resource_pools
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.key is not None:
            result['Key'] = self.key
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_pools is not None:
            result['ResourcePools'] = self.resource_pools
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourcePools') is not None:
            self.resource_pools = m.get('ResourcePools')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeDBClusterPerformanceResponseBodyPerformancesSeries(TeaModel):
    def __init__(
        self,
        name: str = None,
        tags: str = None,
        translate_key: str = None,
        values: List[str] = None,
    ):
        # The name of the performance metric value. For more information about the performance metrics, see [Metric overview](https://help.aliyun.com/document_detail/2863211.html).
        self.name = name
        # The tags that are added to the cluster.
        self.tags = tags
        self.translate_key = translate_key
        # The values of the performance metric at different points in time.
        self.values = values

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.tags is not None:
            result['Tags'] = self.tags
        if self.translate_key is not None:
            result['TranslateKey'] = self.translate_key
        if self.values is not None:
            result['Values'] = self.values
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Tags') is not None:
            self.tags = m.get('Tags')
        if m.get('TranslateKey') is not None:
            self.translate_key = m.get('TranslateKey')
        if m.get('Values') is not None:
            self.values = m.get('Values')
        return self


class DescribeDBClusterPerformanceResponseBodyPerformances(TeaModel):
    def __init__(
        self,
        key: str = None,
        series: List[DescribeDBClusterPerformanceResponseBodyPerformancesSeries] = None,
        unit: str = None,
    ):
        # The name of the performance metric.
        self.key = key
        # The queried performance metric data.
        self.series = series
        # The unit of the performance metric.
        self.unit = unit

    def validate(self):
        if self.series:
            for k in self.series:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        result['Series'] = []
        if self.series is not None:
            for k in self.series:
                result['Series'].append(k.to_map() if k else None)
        if self.unit is not None:
            result['Unit'] = self.unit
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        self.series = []
        if m.get('Series') is not None:
            for k in m.get('Series'):
                temp_model = DescribeDBClusterPerformanceResponseBodyPerformancesSeries()
                self.series.append(temp_model.from_map(k))
        if m.get('Unit') is not None:
            self.unit = m.get('Unit')
        return self


class DescribeDBClusterPerformanceResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        performances: List[DescribeDBClusterPerformanceResponseBodyPerformances] = None,
        request_id: str = None,
        start_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        self.dbcluster_id = dbcluster_id
        # The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.
        self.end_time = end_time
        # The queried performance metrics.
        self.performances = performances
        # The request ID.
        self.request_id = request_id
        # The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.
        self.start_time = start_time

    def validate(self):
        if self.performances:
            for k in self.performances:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        result['Performances'] = []
        if self.performances is not None:
            for k in self.performances:
                result['Performances'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        self.performances = []
        if m.get('Performances') is not None:
            for k in m.get('Performances'):
                temp_model = DescribeDBClusterPerformanceResponseBodyPerformances()
                self.performances.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeDBClusterPerformanceResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBClusterPerformanceResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBClusterPerformanceResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBClusterSpaceSummaryRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeDBClusterSpaceSummaryResponseBodyDataColdData(TeaModel):
    def __init__(
        self,
        data_size: int = None,
        index_size: int = None,
        other_size: int = None,
        primary_key_index_size: int = None,
        total_size: int = None,
    ):
        # The data size of table records. Unit: bytes.
        self.data_size = data_size
        # The data size of regular indexes. Unit: bytes.
        self.index_size = index_size
        # The data size of other data. Unit: bytes.
        self.other_size = other_size
        # The data size of primary key indexes. Unit: bytes.
        self.primary_key_index_size = primary_key_index_size
        # The cold data size. Unit: bytes.
        # 
        # >  Formula: Cold data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.
        self.total_size = total_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data_size is not None:
            result['DataSize'] = self.data_size
        if self.index_size is not None:
            result['IndexSize'] = self.index_size
        if self.other_size is not None:
            result['OtherSize'] = self.other_size
        if self.primary_key_index_size is not None:
            result['PrimaryKeyIndexSize'] = self.primary_key_index_size
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DataSize') is not None:
            self.data_size = m.get('DataSize')
        if m.get('IndexSize') is not None:
            self.index_size = m.get('IndexSize')
        if m.get('OtherSize') is not None:
            self.other_size = m.get('OtherSize')
        if m.get('PrimaryKeyIndexSize') is not None:
            self.primary_key_index_size = m.get('PrimaryKeyIndexSize')
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        return self


class DescribeDBClusterSpaceSummaryResponseBodyDataDataGrowth(TeaModel):
    def __init__(
        self,
        day_growth: int = None,
        week_growth: int = None,
    ):
        # The data growth within the last day. Unit: bytes.
        # 
        # >  Formula: Data growth within the last day = Current data size - Data size one day ago.
        self.day_growth = day_growth
        # The daily data growth within the last seven days. Unit: bytes.
        # 
        # >  Formula: Daily data growth within the last seven days = (Current data size - Data size seven days ago)/7.
        self.week_growth = week_growth

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.day_growth is not None:
            result['DayGrowth'] = self.day_growth
        if self.week_growth is not None:
            result['WeekGrowth'] = self.week_growth
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DayGrowth') is not None:
            self.day_growth = m.get('DayGrowth')
        if m.get('WeekGrowth') is not None:
            self.week_growth = m.get('WeekGrowth')
        return self


class DescribeDBClusterSpaceSummaryResponseBodyDataHotData(TeaModel):
    def __init__(
        self,
        data_size: int = None,
        index_size: int = None,
        other_size: int = None,
        primary_key_index_size: int = None,
        total_size: int = None,
    ):
        # The data size of table records. Unit: bytes.
        self.data_size = data_size
        # The data size of regular indexes. Unit: bytes.
        self.index_size = index_size
        # The data size of other data. Unit: bytes.
        self.other_size = other_size
        # The data size of primary key indexes. Unit: bytes.
        self.primary_key_index_size = primary_key_index_size
        # The hot data size. Unit: bytes.
        # 
        # >  Formula: Hot data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.
        self.total_size = total_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data_size is not None:
            result['DataSize'] = self.data_size
        if self.index_size is not None:
            result['IndexSize'] = self.index_size
        if self.other_size is not None:
            result['OtherSize'] = self.other_size
        if self.primary_key_index_size is not None:
            result['PrimaryKeyIndexSize'] = self.primary_key_index_size
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DataSize') is not None:
            self.data_size = m.get('DataSize')
        if m.get('IndexSize') is not None:
            self.index_size = m.get('IndexSize')
        if m.get('OtherSize') is not None:
            self.other_size = m.get('OtherSize')
        if m.get('PrimaryKeyIndexSize') is not None:
            self.primary_key_index_size = m.get('PrimaryKeyIndexSize')
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        return self


class DescribeDBClusterSpaceSummaryResponseBodyData(TeaModel):
    def __init__(
        self,
        cold_data: DescribeDBClusterSpaceSummaryResponseBodyDataColdData = None,
        data_growth: DescribeDBClusterSpaceSummaryResponseBodyDataDataGrowth = None,
        hot_data: DescribeDBClusterSpaceSummaryResponseBodyDataHotData = None,
        total_size: str = None,
    ):
        # The cold data.
        self.cold_data = cold_data
        # The data growth.
        self.data_growth = data_growth
        # The hot data.
        self.hot_data = hot_data
        # The total data size. Unit: bytes.
        # 
        # >  Formula: Total data size = Hot data size+ Cold data size.
        self.total_size = total_size

    def validate(self):
        if self.cold_data:
            self.cold_data.validate()
        if self.data_growth:
            self.data_growth.validate()
        if self.hot_data:
            self.hot_data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cold_data is not None:
            result['ColdData'] = self.cold_data.to_map()
        if self.data_growth is not None:
            result['DataGrowth'] = self.data_growth.to_map()
        if self.hot_data is not None:
            result['HotData'] = self.hot_data.to_map()
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColdData') is not None:
            temp_model = DescribeDBClusterSpaceSummaryResponseBodyDataColdData()
            self.cold_data = temp_model.from_map(m['ColdData'])
        if m.get('DataGrowth') is not None:
            temp_model = DescribeDBClusterSpaceSummaryResponseBodyDataDataGrowth()
            self.data_growth = temp_model.from_map(m['DataGrowth'])
        if m.get('HotData') is not None:
            temp_model = DescribeDBClusterSpaceSummaryResponseBodyDataHotData()
            self.hot_data = temp_model.from_map(m['HotData'])
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        return self


class DescribeDBClusterSpaceSummaryResponseBody(TeaModel):
    def __init__(
        self,
        data: DescribeDBClusterSpaceSummaryResponseBodyData = None,
        request_id: str = None,
    ):
        # The queried storage overview information.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DescribeDBClusterSpaceSummaryResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeDBClusterSpaceSummaryResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBClusterSpaceSummaryResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBClusterSpaceSummaryResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBClusterStatusRequest(TeaModel):
    def __init__(
        self,
        region_id: str = None,
    ):
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeDBClusterStatusResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        status: List[str] = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The queried cluster states.
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeDBClusterStatusResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBClusterStatusResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBClusterStatusResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBClustersRequestTag(TeaModel):
    def __init__(
        self,
        key: str = None,
        value: str = None,
    ):
        # The tag key.
        self.key = key
        # The tag value.
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeDBClustersRequest(TeaModel):
    def __init__(
        self,
        dbcluster_description: str = None,
        dbcluster_ids: str = None,
        dbcluster_status: str = None,
        dbcluster_version: str = None,
        page_number: int = None,
        page_size: int = None,
        product_version: str = None,
        region_id: str = None,
        resource_group_id: str = None,
        tag: List[DescribeDBClustersRequestTag] = None,
    ):
        # The description of the cluster.
        # 
        # *   The description cannot start with `http://` or `https://`.
        # *   The description must be 2 to 256 characters in length
        self.dbcluster_description = dbcluster_description
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # If you do not specify this parameter, the information about all clusters that reside in the region is returned.
        self.dbcluster_ids = dbcluster_ids
        # The status of the cluster. Valid values:
        # 
        # *   **Preparing**\
        # *   **Creating**\
        # *   **Running**\
        # *   **Deleting**\
        # *   **Restoring**\
        # *   **ClassChanging**\
        # *   **NetAddressCreating**\
        # *   **NetAddressDeleting**\
        # *   **NetAddressModifying**\
        self.dbcluster_status = dbcluster_status
        # The version number corresponding to the edition of the cluster. Valid values:
        # 
        # *   **3.0**: Data Warehouse Edition.
        # *   **5.0** (default): includes Data Lakehouse Edition, Enterprise Edition, and Basic Edition.
        # *   **All**: all editions, including Data Warehouse Edition, Data Lakehouse Edition, Enterprise Edition, and Basic Edition.
        self.dbcluster_version = dbcluster_version
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The edition of the cluster. Valid values:
        # 
        # *   **EnterpriseVersion**: Enterprise Edition.
        # *   **BasicVersion**: Basic Edition.
        # 
        # >  If you leave this parameter empty, the information about clusters of all editions is returned.
        self.product_version = product_version
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The resource group ID. If you do not specify this parameter, the information about all resource groups in the cluster is returned.
        self.resource_group_id = resource_group_id
        # The tags that are added to the cluster.
        self.tag = tag

    def validate(self):
        if self.tag:
            for k in self.tag:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description
        if self.dbcluster_ids is not None:
            result['DBClusterIds'] = self.dbcluster_ids
        if self.dbcluster_status is not None:
            result['DBClusterStatus'] = self.dbcluster_status
        if self.dbcluster_version is not None:
            result['DBClusterVersion'] = self.dbcluster_version
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.product_version is not None:
            result['ProductVersion'] = self.product_version
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        result['Tag'] = []
        if self.tag is not None:
            for k in self.tag:
                result['Tag'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')
        if m.get('DBClusterIds') is not None:
            self.dbcluster_ids = m.get('DBClusterIds')
        if m.get('DBClusterStatus') is not None:
            self.dbcluster_status = m.get('DBClusterStatus')
        if m.get('DBClusterVersion') is not None:
            self.dbcluster_version = m.get('DBClusterVersion')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('ProductVersion') is not None:
            self.product_version = m.get('ProductVersion')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        self.tag = []
        if m.get('Tag') is not None:
            for k in m.get('Tag'):
                temp_model = DescribeDBClustersRequestTag()
                self.tag.append(temp_model.from_map(k))
        return self


class DescribeDBClustersResponseBodyItemsDBClusterTagsTag(TeaModel):
    def __init__(
        self,
        key: str = None,
        value: str = None,
    ):
        # The tag key.
        # 
        # >  You can call the [TagResources](https://help.aliyun.com/document_detail/179253.html) operation to add tags to a cluster.
        self.key = key
        # The tag value.
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeDBClustersResponseBodyItemsDBClusterTags(TeaModel):
    def __init__(
        self,
        tag: List[DescribeDBClustersResponseBodyItemsDBClusterTagsTag] = None,
    ):
        self.tag = tag

    def validate(self):
        if self.tag:
            for k in self.tag:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Tag'] = []
        if self.tag is not None:
            for k in self.tag:
                result['Tag'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.tag = []
        if m.get('Tag') is not None:
            for k in m.get('Tag'):
                temp_model = DescribeDBClustersResponseBodyItemsDBClusterTagsTag()
                self.tag.append(temp_model.from_map(k))
        return self


class DescribeDBClustersResponseBodyItemsDBClusterTaskInfoStepListStepList(TeaModel):
    def __init__(
        self,
        end_time: str = None,
        start_time: str = None,
        step_desc: str = None,
        step_name: str = None,
        step_progress: str = None,
        step_status: str = None,
    ):
        # The end time of the job step. The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. The time is displayed in UTC.
        self.end_time = end_time
        # The start time of the job step. The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. The time is displayed in UTC.
        self.start_time = start_time
        # The description of the job step.
        self.step_desc = step_desc
        # The name of the job step.
        self.step_name = step_name
        # The progress of the job step. Unit: %.
        self.step_progress = step_progress
        # The status of the job step. Valid values:
        # 
        # *   **NOT_RUN**\
        # *   **RUNNING**\
        # *   **SUCCEED**\
        self.step_status = step_status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.step_desc is not None:
            result['StepDesc'] = self.step_desc
        if self.step_name is not None:
            result['StepName'] = self.step_name
        if self.step_progress is not None:
            result['StepProgress'] = self.step_progress
        if self.step_status is not None:
            result['StepStatus'] = self.step_status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StepDesc') is not None:
            self.step_desc = m.get('StepDesc')
        if m.get('StepName') is not None:
            self.step_name = m.get('StepName')
        if m.get('StepProgress') is not None:
            self.step_progress = m.get('StepProgress')
        if m.get('StepStatus') is not None:
            self.step_status = m.get('StepStatus')
        return self


class DescribeDBClustersResponseBodyItemsDBClusterTaskInfoStepList(TeaModel):
    def __init__(
        self,
        step_list: List[DescribeDBClustersResponseBodyItemsDBClusterTaskInfoStepListStepList] = None,
    ):
        self.step_list = step_list

    def validate(self):
        if self.step_list:
            for k in self.step_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['StepList'] = []
        if self.step_list is not None:
            for k in self.step_list:
                result['StepList'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.step_list = []
        if m.get('StepList') is not None:
            for k in m.get('StepList'):
                temp_model = DescribeDBClustersResponseBodyItemsDBClusterTaskInfoStepListStepList()
                self.step_list.append(temp_model.from_map(k))
        return self


class DescribeDBClustersResponseBodyItemsDBClusterTaskInfo(TeaModel):
    def __init__(
        self,
        name: str = None,
        progress: str = None,
        status: str = None,
        step_list: DescribeDBClustersResponseBodyItemsDBClusterTaskInfoStepList = None,
    ):
        # The name of the job.
        self.name = name
        # The progress of the job. Unit: %.
        self.progress = progress
        # The status of the job. Valid values:
        # 
        # *   **NOT_RUN**\
        # *   **RUNNING**\
        # *   **SUCCEED**\
        self.status = status
        # The job steps.
        self.step_list = step_list

    def validate(self):
        if self.step_list:
            self.step_list.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.progress is not None:
            result['Progress'] = self.progress
        if self.status is not None:
            result['Status'] = self.status
        if self.step_list is not None:
            result['StepList'] = self.step_list.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Progress') is not None:
            self.progress = m.get('Progress')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('StepList') is not None:
            temp_model = DescribeDBClustersResponseBodyItemsDBClusterTaskInfoStepList()
            self.step_list = temp_model.from_map(m['StepList'])
        return self


class DescribeDBClustersResponseBodyItemsDBCluster(TeaModel):
    def __init__(
        self,
        category: str = None,
        commodity_code: str = None,
        compute_resource: str = None,
        connection_string: str = None,
        create_time: str = None,
        dbcluster_description: str = None,
        dbcluster_id: str = None,
        dbcluster_network_type: str = None,
        dbcluster_status: str = None,
        dbcluster_type: str = None,
        dbnode_class: str = None,
        dbnode_count: int = None,
        dbnode_storage: int = None,
        dbversion: str = None,
        disk_type: str = None,
        dts_job_id: str = None,
        elastic_ioresource: int = None,
        engine: str = None,
        executor_count: str = None,
        expire_time: str = None,
        expired: str = None,
        inner_ip: str = None,
        inner_port: str = None,
        lock_mode: str = None,
        lock_reason: str = None,
        mode: str = None,
        pay_type: str = None,
        port: str = None,
        product_form: str = None,
        product_version: str = None,
        rds_instance_id: str = None,
        region_id: str = None,
        reserved_acu: str = None,
        reserved_node_count: int = None,
        reserved_node_size: str = None,
        resource_group_id: str = None,
        storage_resource: str = None,
        tags: DescribeDBClustersResponseBodyItemsDBClusterTags = None,
        task_info: DescribeDBClustersResponseBodyItemsDBClusterTaskInfo = None,
        vpccloud_instance_id: str = None,
        vpcid: str = None,
        v_switch_id: str = None,
        zone_id: str = None,
    ):
        # The mode of the cluster. This parameter is returned only for Data Warehouse Edition clusters. Valid values:
        # 
        # *   **BASIC**: reserved mode for Basic Edition.
        # *   **CLUSTER**: reserved mode for Cluster Edition.
        # *   **MIXED_STORAGE**: elastic mode for Cluster Edition.
        # 
        # >  For more information about cluster editions, see [Editions](https://help.aliyun.com/document_detail/205001.html).
        self.category = category
        # The billing method of the cluster. Valid values:
        # 
        # *   **ads**: pay-as-you-go.
        # *   **ads_pre**: subscription.
        self.commodity_code = commodity_code
        # The specifications of reserved computing resources. Each ACU is approximately equal to 1 core and 4 GB memory. Computing resources are used to compute data. The increase in the computing resources can accelerate queries. You can scale computing resources based on your business requirements.
        self.compute_resource = compute_resource
        # The public endpoint that is used to connect to the cluster.
        self.connection_string = connection_string
        # The time when the cluster was created. The time follows the ISO 8601 standard in the *yyyy-mm-ddThh:mm:ssZ* format. The time is displayed in UTC.
        self.create_time = create_time
        # The description of the cluster.
        self.dbcluster_description = dbcluster_description
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The network type of the cluster. Only **VPC** is supported.
        self.dbcluster_network_type = dbcluster_network_type
        # The status of the cluster. Valid values:
        # 
        # *   **Preparing**\
        # *   **Creating**\
        # *   **Running**\
        # *   **Deleting**\
        # *   **Restoring**\
        # *   **ClassChanging**\
        # *   **NetAddressCreating**\
        # *   **NetAddressDeleting**\
        # *   **NetAddressModifying**\
        self.dbcluster_status = dbcluster_status
        # The type of the cluster. By default, **Common** is returned, which indicates a common cluster.
        self.dbcluster_type = dbcluster_type
        # The node specifications of the cluster. This parameter is returned only for Data Warehouse Edition clusters.
        self.dbnode_class = dbnode_class
        # The number of node groups.
        self.dbnode_count = dbnode_count
        # The storage capacity of the cluster. Unit: GB.
        self.dbnode_storage = dbnode_storage
        # The version number corresponding to the edition of the cluster. Only **5.0** is supported.
        self.dbversion = dbversion
        # The disk type of the cluster. Valid values:
        # 
        # *   **local_ssd**: local disk.
        # *   **cloud**: basic disk.
        # *   **cloud_ssd**: standard SSD.
        # *   **cloud_efficiency**: ultra disk.
        # *   **cloud_essd**: PL1 Enterprise SSD (ESSD).
        # *   **cloud_essd2**: PL2 ESSD.
        # *   **cloud_essd3**: PL3 ESSD.
        # 
        # >  For more information about ESSDs, see [ESSDs](https://help.aliyun.com/document_detail/122389.html).
        self.disk_type = disk_type
        # The ID of the Data Transmission Service (DTS) synchronization job This parameter is returned only for MySQL analytic instances.
        self.dts_job_id = dts_job_id
        # The number of elastic I/O units (EIUs). For more information, see the "[EIUs](https://help.aliyun.com/document_detail/189505.html)" section of the Scale out elastic I/O resources topic.
        # 
        # >  This parameter is returned only for clusters in elastic mode.
        self.elastic_ioresource = elastic_ioresource
        # The engine of the cluster. **AnalyticDB** is returned.
        self.engine = engine
        # The number of compute nodes that are used by the cluster in elastic mode.
        self.executor_count = executor_count
        # The time when the cluster expires. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        # 
        # > 
        # 
        # *   If the billing method of the cluster is subscription, the actual expiration time is returned.
        # 
        # *   If the billing method of the cluster is pay-as-you-go, null is returned.
        self.expire_time = expire_time
        # Indicates whether the subscription cluster has expired. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        # 
        # > 
        # 
        # *   If the cluster has expired, the system locks or releases the cluster within a period of time. We recommend that you renew the expired cluster. For more information, see [Renewal policy](https://help.aliyun.com/document_detail/135246.html).
        # 
        # *   This parameter is not returned for pay-as-you-go clusters.
        self.expired = expired
        # The internal IP address of the cluster.
        self.inner_ip = inner_ip
        # The internal port of the cluster.
        self.inner_port = inner_port
        # The lock status of the cluster. Valid values:
        # 
        # *   **Unlock**: The cluster is not locked.
        # *   **ManualLock**: The cluster is manually locked.
        # *   **LockByExpiration**: The cluster is automatically locked due to cluster expiration.
        self.lock_mode = lock_mode
        # The reason why the cluster is locked.
        # 
        # >  This parameter is returned only when the cluster was locked. **instance_expire** is returned.
        self.lock_reason = lock_reason
        # The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.
        self.mode = mode
        # The billing method of the cluster. Valid values:
        # 
        # *   **Postpaid**: pay-as-you-go.
        # *   **Prepaid**: subscription.
        self.pay_type = pay_type
        # The port number that is used to connect to the cluster.
        self.port = port
        # The service type of the cluster. Valid values:
        # 
        # *   **LegacyForm**\
        # *   **IntegrationForm**\
        self.product_form = product_form
        # The edition of the cluster. Valid values:
        # 
        # *   **BasicVersion**: Basic Edition.
        # *   **EnterpriseVersion**: Enterprise Edition.
        self.product_version = product_version
        # The ID of the ApsaraDB RDS instance from which data is synchronized to the cluster. This parameter is returned only for MySQL analytic instances.
        self.rds_instance_id = rds_instance_id
        # The region ID of the cluster.
        self.region_id = region_id
        # The remaining reserved computing resources that are available in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.
        self.reserved_acu = reserved_acu
        # The number of reserved resource nodes.
        self.reserved_node_count = reserved_node_count
        # The single-node specifications of reserved resources.
        self.reserved_node_size = reserved_node_size
        # The resource group ID.
        self.resource_group_id = resource_group_id
        # The specifications of reserved storage resources. Each AnalyticDB compute unit (ACU) is approximately equal to 1 core and 4 GB memory. Storage resources are used to read and write data. The increase in the storage resources can improve the read and write performance of the cluster.
        self.storage_resource = storage_resource
        # The tags that are added to the cluster.
        self.tags = tags
        # The information about the job.
        self.task_info = task_info
        # The VPC endpoint.
        self.vpccloud_instance_id = vpccloud_instance_id
        # The virtual private cloud (VPC) ID of the cluster.
        self.vpcid = vpcid
        # The vSwitch ID of the cluster.
        self.v_switch_id = v_switch_id
        # The zone ID of the cluster.
        self.zone_id = zone_id

    def validate(self):
        if self.tags:
            self.tags.validate()
        if self.task_info:
            self.task_info.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        if self.commodity_code is not None:
            result['CommodityCode'] = self.commodity_code
        if self.compute_resource is not None:
            result['ComputeResource'] = self.compute_resource
        if self.connection_string is not None:
            result['ConnectionString'] = self.connection_string
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.dbcluster_network_type is not None:
            result['DBClusterNetworkType'] = self.dbcluster_network_type
        if self.dbcluster_status is not None:
            result['DBClusterStatus'] = self.dbcluster_status
        if self.dbcluster_type is not None:
            result['DBClusterType'] = self.dbcluster_type
        if self.dbnode_class is not None:
            result['DBNodeClass'] = self.dbnode_class
        if self.dbnode_count is not None:
            result['DBNodeCount'] = self.dbnode_count
        if self.dbnode_storage is not None:
            result['DBNodeStorage'] = self.dbnode_storage
        if self.dbversion is not None:
            result['DBVersion'] = self.dbversion
        if self.disk_type is not None:
            result['DiskType'] = self.disk_type
        if self.dts_job_id is not None:
            result['DtsJobId'] = self.dts_job_id
        if self.elastic_ioresource is not None:
            result['ElasticIOResource'] = self.elastic_ioresource
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.executor_count is not None:
            result['ExecutorCount'] = self.executor_count
        if self.expire_time is not None:
            result['ExpireTime'] = self.expire_time
        if self.expired is not None:
            result['Expired'] = self.expired
        if self.inner_ip is not None:
            result['InnerIp'] = self.inner_ip
        if self.inner_port is not None:
            result['InnerPort'] = self.inner_port
        if self.lock_mode is not None:
            result['LockMode'] = self.lock_mode
        if self.lock_reason is not None:
            result['LockReason'] = self.lock_reason
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.pay_type is not None:
            result['PayType'] = self.pay_type
        if self.port is not None:
            result['Port'] = self.port
        if self.product_form is not None:
            result['ProductForm'] = self.product_form
        if self.product_version is not None:
            result['ProductVersion'] = self.product_version
        if self.rds_instance_id is not None:
            result['RdsInstanceId'] = self.rds_instance_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.reserved_acu is not None:
            result['ReservedACU'] = self.reserved_acu
        if self.reserved_node_count is not None:
            result['ReservedNodeCount'] = self.reserved_node_count
        if self.reserved_node_size is not None:
            result['ReservedNodeSize'] = self.reserved_node_size
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.storage_resource is not None:
            result['StorageResource'] = self.storage_resource
        if self.tags is not None:
            result['Tags'] = self.tags.to_map()
        if self.task_info is not None:
            result['TaskInfo'] = self.task_info.to_map()
        if self.vpccloud_instance_id is not None:
            result['VPCCloudInstanceId'] = self.vpccloud_instance_id
        if self.vpcid is not None:
            result['VPCId'] = self.vpcid
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('CommodityCode') is not None:
            self.commodity_code = m.get('CommodityCode')
        if m.get('ComputeResource') is not None:
            self.compute_resource = m.get('ComputeResource')
        if m.get('ConnectionString') is not None:
            self.connection_string = m.get('ConnectionString')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DBClusterNetworkType') is not None:
            self.dbcluster_network_type = m.get('DBClusterNetworkType')
        if m.get('DBClusterStatus') is not None:
            self.dbcluster_status = m.get('DBClusterStatus')
        if m.get('DBClusterType') is not None:
            self.dbcluster_type = m.get('DBClusterType')
        if m.get('DBNodeClass') is not None:
            self.dbnode_class = m.get('DBNodeClass')
        if m.get('DBNodeCount') is not None:
            self.dbnode_count = m.get('DBNodeCount')
        if m.get('DBNodeStorage') is not None:
            self.dbnode_storage = m.get('DBNodeStorage')
        if m.get('DBVersion') is not None:
            self.dbversion = m.get('DBVersion')
        if m.get('DiskType') is not None:
            self.disk_type = m.get('DiskType')
        if m.get('DtsJobId') is not None:
            self.dts_job_id = m.get('DtsJobId')
        if m.get('ElasticIOResource') is not None:
            self.elastic_ioresource = m.get('ElasticIOResource')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('ExecutorCount') is not None:
            self.executor_count = m.get('ExecutorCount')
        if m.get('ExpireTime') is not None:
            self.expire_time = m.get('ExpireTime')
        if m.get('Expired') is not None:
            self.expired = m.get('Expired')
        if m.get('InnerIp') is not None:
            self.inner_ip = m.get('InnerIp')
        if m.get('InnerPort') is not None:
            self.inner_port = m.get('InnerPort')
        if m.get('LockMode') is not None:
            self.lock_mode = m.get('LockMode')
        if m.get('LockReason') is not None:
            self.lock_reason = m.get('LockReason')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('PayType') is not None:
            self.pay_type = m.get('PayType')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ProductForm') is not None:
            self.product_form = m.get('ProductForm')
        if m.get('ProductVersion') is not None:
            self.product_version = m.get('ProductVersion')
        if m.get('RdsInstanceId') is not None:
            self.rds_instance_id = m.get('RdsInstanceId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ReservedACU') is not None:
            self.reserved_acu = m.get('ReservedACU')
        if m.get('ReservedNodeCount') is not None:
            self.reserved_node_count = m.get('ReservedNodeCount')
        if m.get('ReservedNodeSize') is not None:
            self.reserved_node_size = m.get('ReservedNodeSize')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('StorageResource') is not None:
            self.storage_resource = m.get('StorageResource')
        if m.get('Tags') is not None:
            temp_model = DescribeDBClustersResponseBodyItemsDBClusterTags()
            self.tags = temp_model.from_map(m['Tags'])
        if m.get('TaskInfo') is not None:
            temp_model = DescribeDBClustersResponseBodyItemsDBClusterTaskInfo()
            self.task_info = temp_model.from_map(m['TaskInfo'])
        if m.get('VPCCloudInstanceId') is not None:
            self.vpccloud_instance_id = m.get('VPCCloudInstanceId')
        if m.get('VPCId') is not None:
            self.vpcid = m.get('VPCId')
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class DescribeDBClustersResponseBodyItems(TeaModel):
    def __init__(
        self,
        dbcluster: List[DescribeDBClustersResponseBodyItemsDBCluster] = None,
    ):
        self.dbcluster = dbcluster

    def validate(self):
        if self.dbcluster:
            for k in self.dbcluster:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['DBCluster'] = []
        if self.dbcluster is not None:
            for k in self.dbcluster:
                result['DBCluster'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.dbcluster = []
        if m.get('DBCluster') is not None:
            for k in m.get('DBCluster'):
                temp_model = DescribeDBClustersResponseBodyItemsDBCluster()
                self.dbcluster.append(temp_model.from_map(k))
        return self


class DescribeDBClustersResponseBody(TeaModel):
    def __init__(
        self,
        items: DescribeDBClustersResponseBodyItems = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The queried clusters.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Items') is not None:
            temp_model = DescribeDBClustersResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeDBClustersResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBClustersResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBClustersResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDBResourceGroupRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        group_name: str = None,
        group_type: str = None,
        region_id: str = None,
        resource_owner_account: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        # 
        # > If you do not specify this parameter, the information about all resource groups in the cluster is returned.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # >  For more information about resource groups, see [Resource group overview](https://help.aliyun.com/document_detail/428610.html).
        self.group_type = group_type
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class DescribeDBResourceGroupResponseBodyGroupsInfoRayConfigWorkerGroups(TeaModel):
    def __init__(
        self,
        allocate_unit: str = None,
        group_name: str = None,
        max_worker_quantity: int = None,
        min_worker_quantity: int = None,
        worker_disk_capacity: str = None,
        worker_spec_name: str = None,
        worker_spec_type: str = None,
    ):
        self.allocate_unit = allocate_unit
        self.group_name = group_name
        self.max_worker_quantity = max_worker_quantity
        self.min_worker_quantity = min_worker_quantity
        self.worker_disk_capacity = worker_disk_capacity
        self.worker_spec_name = worker_spec_name
        self.worker_spec_type = worker_spec_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.allocate_unit is not None:
            result['AllocateUnit'] = self.allocate_unit
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.max_worker_quantity is not None:
            result['MaxWorkerQuantity'] = self.max_worker_quantity
        if self.min_worker_quantity is not None:
            result['MinWorkerQuantity'] = self.min_worker_quantity
        if self.worker_disk_capacity is not None:
            result['WorkerDiskCapacity'] = self.worker_disk_capacity
        if self.worker_spec_name is not None:
            result['WorkerSpecName'] = self.worker_spec_name
        if self.worker_spec_type is not None:
            result['WorkerSpecType'] = self.worker_spec_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AllocateUnit') is not None:
            self.allocate_unit = m.get('AllocateUnit')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('MaxWorkerQuantity') is not None:
            self.max_worker_quantity = m.get('MaxWorkerQuantity')
        if m.get('MinWorkerQuantity') is not None:
            self.min_worker_quantity = m.get('MinWorkerQuantity')
        if m.get('WorkerDiskCapacity') is not None:
            self.worker_disk_capacity = m.get('WorkerDiskCapacity')
        if m.get('WorkerSpecName') is not None:
            self.worker_spec_name = m.get('WorkerSpecName')
        if m.get('WorkerSpecType') is not None:
            self.worker_spec_type = m.get('WorkerSpecType')
        return self


class DescribeDBResourceGroupResponseBodyGroupsInfoRayConfig(TeaModel):
    def __init__(
        self,
        category: str = None,
        head_spec: str = None,
        ray_cluster_address: str = None,
        ray_dashboard_address: str = None,
        ray_grafana_address: str = None,
        worker_groups: List[DescribeDBResourceGroupResponseBodyGroupsInfoRayConfigWorkerGroups] = None,
    ):
        self.category = category
        self.head_spec = head_spec
        self.ray_cluster_address = ray_cluster_address
        self.ray_dashboard_address = ray_dashboard_address
        self.ray_grafana_address = ray_grafana_address
        self.worker_groups = worker_groups

    def validate(self):
        if self.worker_groups:
            for k in self.worker_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        if self.head_spec is not None:
            result['HeadSpec'] = self.head_spec
        if self.ray_cluster_address is not None:
            result['RayClusterAddress'] = self.ray_cluster_address
        if self.ray_dashboard_address is not None:
            result['RayDashboardAddress'] = self.ray_dashboard_address
        if self.ray_grafana_address is not None:
            result['RayGrafanaAddress'] = self.ray_grafana_address
        result['WorkerGroups'] = []
        if self.worker_groups is not None:
            for k in self.worker_groups:
                result['WorkerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('HeadSpec') is not None:
            self.head_spec = m.get('HeadSpec')
        if m.get('RayClusterAddress') is not None:
            self.ray_cluster_address = m.get('RayClusterAddress')
        if m.get('RayDashboardAddress') is not None:
            self.ray_dashboard_address = m.get('RayDashboardAddress')
        if m.get('RayGrafanaAddress') is not None:
            self.ray_grafana_address = m.get('RayGrafanaAddress')
        self.worker_groups = []
        if m.get('WorkerGroups') is not None:
            for k in m.get('WorkerGroups'):
                temp_model = DescribeDBResourceGroupResponseBodyGroupsInfoRayConfigWorkerGroups()
                self.worker_groups.append(temp_model.from_map(k))
        return self


class DescribeDBResourceGroupResponseBodyGroupsInfoRules(TeaModel):
    def __init__(
        self,
        group_name: str = None,
        query_time: str = None,
        target_group_name: str = None,
    ):
        # The name of the resource group.
        self.group_name = group_name
        # The execution duration of the query. Unit: milliseconds.
        self.query_time = query_time
        # The name of the destination resource group.
        self.target_group_name = target_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.query_time is not None:
            result['QueryTime'] = self.query_time
        if self.target_group_name is not None:
            result['TargetGroupName'] = self.target_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('QueryTime') is not None:
            self.query_time = m.get('QueryTime')
        if m.get('TargetGroupName') is not None:
            self.target_group_name = m.get('TargetGroupName')
        return self


class DescribeDBResourceGroupResponseBodyGroupsInfo(TeaModel):
    def __init__(
        self,
        auto_stop_interval: str = None,
        cluster_mode: str = None,
        cluster_size_resource: str = None,
        create_time: str = None,
        elastic_min_compute_resource: str = None,
        enable_spot: str = None,
        engine: str = None,
        engine_params: Dict[str, Any] = None,
        group_name: str = None,
        group_type: str = None,
        group_users: str = None,
        max_cluster_count: int = None,
        max_compute_resource: str = None,
        max_gpu_quantity: int = None,
        message: str = None,
        min_cluster_count: int = None,
        min_compute_resource: str = None,
        min_gpu_quantity: int = None,
        ray_config: DescribeDBResourceGroupResponseBodyGroupsInfoRayConfig = None,
        rules: List[DescribeDBResourceGroupResponseBodyGroupsInfoRules] = None,
        running_cluster_count: int = None,
        spec_name: str = None,
        status: str = None,
        target_resource_group_name: str = None,
        update_time: str = None,
    ):
        self.auto_stop_interval = auto_stop_interval
        # A reserved parameter.
        self.cluster_mode = cluster_mode
        # A reserved parameter.
        self.cluster_size_resource = cluster_size_resource
        # The time when the resource group was created. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        self.create_time = create_time
        # The minimum amount of elastic computing resources.
        self.elastic_min_compute_resource = elastic_min_compute_resource
        # Indicates whether the preemptible instance feature is enabled for the resource group. After the preemptible instance feature is enabled, you are charged for resources at a lower unit price but the resources are probably released. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        # 
        # The True value is returned only for job resource groups.
        self.enable_spot = enable_spot
        self.engine = engine
        self.engine_params = engine_params
        # The name of the resource group.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # >  For more information about resource groups, see [Resource groups](https://help.aliyun.com/document_detail/428610.html).
        self.group_type = group_type
        # The Resource Access Management (RAM) user that is associated with the resource group.
        self.group_users = group_users
        # A reserved parameter.
        self.max_cluster_count = max_cluster_count
        # The maximum amount of reserved computing resources.
        self.max_compute_resource = max_compute_resource
        self.max_gpu_quantity = max_gpu_quantity
        # This parameter is required.
        self.message = message
        # A reserved parameter.
        self.min_cluster_count = min_cluster_count
        # The minimum amount of reserved computing resources.
        self.min_compute_resource = min_compute_resource
        self.min_gpu_quantity = min_gpu_quantity
        self.ray_config = ray_config
        # The job resubmission rules.
        self.rules = rules
        # A reserved parameter.
        self.running_cluster_count = running_cluster_count
        self.spec_name = spec_name
        # The status of the resource group. Valid values:
        # 
        # *   **creating**: The resource group is being created.
        # *   **ok**: The resource group is created.
        # *   **pendingdelete**: The resource group is pending to be deleted.
        self.status = status
        self.target_resource_group_name = target_resource_group_name
        # The time when the resource group was updated. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        self.update_time = update_time

    def validate(self):
        if self.ray_config:
            self.ray_config.validate()
        if self.rules:
            for k in self.rules:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_stop_interval is not None:
            result['AutoStopInterval'] = self.auto_stop_interval
        if self.cluster_mode is not None:
            result['ClusterMode'] = self.cluster_mode
        if self.cluster_size_resource is not None:
            result['ClusterSizeResource'] = self.cluster_size_resource
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.elastic_min_compute_resource is not None:
            result['ElasticMinComputeResource'] = self.elastic_min_compute_resource
        if self.enable_spot is not None:
            result['EnableSpot'] = self.enable_spot
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.engine_params is not None:
            result['EngineParams'] = self.engine_params
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.group_users is not None:
            result['GroupUsers'] = self.group_users
        if self.max_cluster_count is not None:
            result['MaxClusterCount'] = self.max_cluster_count
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.max_gpu_quantity is not None:
            result['MaxGpuQuantity'] = self.max_gpu_quantity
        if self.message is not None:
            result['Message'] = self.message
        if self.min_cluster_count is not None:
            result['MinClusterCount'] = self.min_cluster_count
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        if self.min_gpu_quantity is not None:
            result['MinGpuQuantity'] = self.min_gpu_quantity
        if self.ray_config is not None:
            result['RayConfig'] = self.ray_config.to_map()
        result['Rules'] = []
        if self.rules is not None:
            for k in self.rules:
                result['Rules'].append(k.to_map() if k else None)
        if self.running_cluster_count is not None:
            result['RunningClusterCount'] = self.running_cluster_count
        if self.spec_name is not None:
            result['SpecName'] = self.spec_name
        if self.status is not None:
            result['Status'] = self.status
        if self.target_resource_group_name is not None:
            result['TargetResourceGroupName'] = self.target_resource_group_name
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoStopInterval') is not None:
            self.auto_stop_interval = m.get('AutoStopInterval')
        if m.get('ClusterMode') is not None:
            self.cluster_mode = m.get('ClusterMode')
        if m.get('ClusterSizeResource') is not None:
            self.cluster_size_resource = m.get('ClusterSizeResource')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('ElasticMinComputeResource') is not None:
            self.elastic_min_compute_resource = m.get('ElasticMinComputeResource')
        if m.get('EnableSpot') is not None:
            self.enable_spot = m.get('EnableSpot')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('EngineParams') is not None:
            self.engine_params = m.get('EngineParams')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('GroupUsers') is not None:
            self.group_users = m.get('GroupUsers')
        if m.get('MaxClusterCount') is not None:
            self.max_cluster_count = m.get('MaxClusterCount')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MaxGpuQuantity') is not None:
            self.max_gpu_quantity = m.get('MaxGpuQuantity')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('MinClusterCount') is not None:
            self.min_cluster_count = m.get('MinClusterCount')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        if m.get('MinGpuQuantity') is not None:
            self.min_gpu_quantity = m.get('MinGpuQuantity')
        if m.get('RayConfig') is not None:
            temp_model = DescribeDBResourceGroupResponseBodyGroupsInfoRayConfig()
            self.ray_config = temp_model.from_map(m['RayConfig'])
        self.rules = []
        if m.get('Rules') is not None:
            for k in m.get('Rules'):
                temp_model = DescribeDBResourceGroupResponseBodyGroupsInfoRules()
                self.rules.append(temp_model.from_map(k))
        if m.get('RunningClusterCount') is not None:
            self.running_cluster_count = m.get('RunningClusterCount')
        if m.get('SpecName') is not None:
            self.spec_name = m.get('SpecName')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TargetResourceGroupName') is not None:
            self.target_resource_group_name = m.get('TargetResourceGroupName')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class DescribeDBResourceGroupResponseBody(TeaModel):
    def __init__(
        self,
        groups_info: List[DescribeDBResourceGroupResponseBodyGroupsInfo] = None,
        request_id: str = None,
    ):
        # The queried resource groups.
        self.groups_info = groups_info
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.groups_info:
            for k in self.groups_info:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['GroupsInfo'] = []
        if self.groups_info is not None:
            for k in self.groups_info:
                result['GroupsInfo'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.groups_info = []
        if m.get('GroupsInfo') is not None:
            for k in m.get('GroupsInfo'):
                temp_model = DescribeDBResourceGroupResponseBodyGroupsInfo()
                self.groups_info.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeDBResourceGroupResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDBResourceGroupResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDBResourceGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDiagnosisDimensionsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        query_condition: str = None,
        region_id: str = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # > 
        # 
        # *   The end time must be later than the start time.
        # 
        # *   The maximum time range that can be specified is 24 hours.
        self.end_time = end_time
        # The language. Valid values:
        # 
        # *   **zh-CN** (default): simplified Chinese.
        # *   **en-US**: English.
        # *   **ja**: Japanese.
        self.lang = lang
        # The query condition for SQL statements, which can contain the `Type`, `Value`, `Min`, and `Max` fields. Specify the condition in the JSON format. `Type` specifies the query dimension. Valid values for Type: `maxCost`, `status`, and `cost`. `Value`, `Min`, or `Max` specifies the query range for the dimension. Valid values:
        # 
        # *   `{"Type":"maxCost","Value":"100"}`: queries the top 100 most time-consuming SQL statements. Set `Value` to 100.
        # *   `{"Type":"status","Value":"finished"}`: queries the executed SQL statements. You can set `Value` to `running` to query the SQL statements that are being executed. You can also set Value to `failed` to query the SQL statements that failed to be executed.
        # *   `{"Type":"cost","Min":"10","Max":"200"}`: queries the SQL statements whose execution duration is in the range of 10 to 200 milliseconds. You can also specify custom values for the Min and Max fields.
        self.query_condition = query_condition
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The beginning of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # >  You can query data only within the last 14 days.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.query_condition is not None:
            result['QueryCondition'] = self.query_condition
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('QueryCondition') is not None:
            self.query_condition = m.get('QueryCondition')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeDiagnosisDimensionsResponseBody(TeaModel):
    def __init__(
        self,
        client_ips: List[str] = None,
        databases: List[str] = None,
        request_id: str = None,
        resource_groups: List[str] = None,
        user_names: List[str] = None,
    ):
        # The queried source IP addresses.
        self.client_ips = client_ips
        # The queried database names.
        self.databases = databases
        # The request ID.
        self.request_id = request_id
        # The queried resource group names.
        self.resource_groups = resource_groups
        # The queried usernames.
        self.user_names = user_names

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_ips is not None:
            result['ClientIps'] = self.client_ips
        if self.databases is not None:
            result['Databases'] = self.databases
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.resource_groups is not None:
            result['ResourceGroups'] = self.resource_groups
        if self.user_names is not None:
            result['UserNames'] = self.user_names
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientIps') is not None:
            self.client_ips = m.get('ClientIps')
        if m.get('Databases') is not None:
            self.databases = m.get('Databases')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ResourceGroups') is not None:
            self.resource_groups = m.get('ResourceGroups')
        if m.get('UserNames') is not None:
            self.user_names = m.get('UserNames')
        return self


class DescribeDiagnosisDimensionsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDiagnosisDimensionsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDiagnosisDimensionsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDiagnosisRecordsRequest(TeaModel):
    def __init__(
        self,
        client_ip: str = None,
        dbcluster_id: str = None,
        database: str = None,
        end_time: str = None,
        keyword: str = None,
        lang: str = None,
        max_peak_memory: int = None,
        max_scan_size: int = None,
        min_peak_memory: int = None,
        min_scan_size: int = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        pattern_id: str = None,
        query_condition: str = None,
        region_id: str = None,
        resource_group: str = None,
        start_time: str = None,
        user_name: str = None,
    ):
        # The source IP address.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.client_ip = client_ip
        # The Enterprise Edition, Basic Edition, or Data Lakehouse Edition cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database on which the SQL statements are executed.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.database = database
        # The end of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # > 
        # 
        # *   The end time must be later than the start time.
        # 
        # *   The maximum time range that can be specified is 24 hours.
        self.end_time = end_time
        # The query keyword of the SQL statements.
        self.keyword = keyword
        # The language of file titles and error messages. Valid values:
        # 
        # *   **zh** (default): simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The maximum peak memory of the SQL statements. Unit: bytes.
        self.max_peak_memory = max_peak_memory
        # The maximum scan size of the SQL statements. Unit: bytes.
        self.max_scan_size = max_scan_size
        # The minimum peak memory of the SQL statements. Unit: bytes.
        self.min_peak_memory = min_peak_memory
        # The minimum scan size of the SQL statements. Unit: bytes.
        self.min_scan_size = min_scan_size
        # The order in which to sort the SQL statements by field, which contains the `Field` and `Type` fields. Specify the order in the JSON format. Example: `[{"Field":"StartTime", "Type": "desc"}]`. Fields:
        # 
        # *   `Field` specifies the field that is used to sort the SQL statements. Valid values:
        # 
        #     *   `StartTime`: the execution start time.
        #     *   `Status`: the execution status.
        #     *   `UserName`: the username.
        #     *   `Cost`: the execution duration.
        #     *   `PeakMemory`: the peak memory.
        #     *   `ScanSize`: the amount of data that is scanned.
        #     *   `Database`: the name of the database.
        #     *   `ClientIp`: the source IP address.
        #     *   `ResourceGroup`: the name of the resource group.
        #     *   `QueueTime`: the amount of time that is consumed for queuing.
        #     *   `OutputRows`: the number of output rows.
        #     *   `OutputDataSize`: the amount of output data.
        #     *   `ResourceCostRank`: the execution duration rank of operators that are used in the SQL statements. This value takes effect only when `QueryCondition` is set to `{"Type":"status","Value":"running"}`.
        # 
        # *   `Type` specifies the sorting order. Valid values (case-insensitive):
        # 
        #     *   `Desc`: descending order.
        #     *   `Asc`: ascending order.
        self.order = order
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The SQL pattern ID.
        self.pattern_id = pattern_id
        # The query condition for SQL statements, which can contain the `Type`, `Value`, `Min`, and `Max` fields. Specify the condition in the JSON format. `Type` specifies the query dimension. Valid values for Type: `maxCost`, `status`, and `cost`. `Value`, `Min`, or `Max` specifies the query range for the dimension. Valid values:
        # 
        # *   `{"Type":"maxCost","Value":"100"}`: queries the top 100 most time-consuming SQL statements. Set `Value` to 100.
        # *   `{"Type":"status","Value":"finished"}`: queries the executed SQL statements. You can set `Value` to `running` to query the SQL statements that are being executed. You can also set Value to `failed` to query the SQL statements that failed to be executed.
        # *   `{"Type":"cost","Min":"10","Max":"200"}`: queries the SQL statements whose execution duration is in the range of 10 to 200 milliseconds. You can also specify custom values for the Min and Max fields.
        self.query_condition = query_condition
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The resource group to which the SQL statements belong.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.resource_group = resource_group
        # The beginning of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # >  You can query data only within the last 14 days.
        self.start_time = start_time
        # The username that is used to execute the SQL statements. You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_ip is not None:
            result['ClientIp'] = self.client_ip
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database is not None:
            result['Database'] = self.database
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.max_peak_memory is not None:
            result['MaxPeakMemory'] = self.max_peak_memory
        if self.max_scan_size is not None:
            result['MaxScanSize'] = self.max_scan_size
        if self.min_peak_memory is not None:
            result['MinPeakMemory'] = self.min_peak_memory
        if self.min_scan_size is not None:
            result['MinScanSize'] = self.min_scan_size
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.pattern_id is not None:
            result['PatternId'] = self.pattern_id
        if self.query_condition is not None:
            result['QueryCondition'] = self.query_condition
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientIp') is not None:
            self.client_ip = m.get('ClientIp')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('MaxPeakMemory') is not None:
            self.max_peak_memory = m.get('MaxPeakMemory')
        if m.get('MaxScanSize') is not None:
            self.max_scan_size = m.get('MaxScanSize')
        if m.get('MinPeakMemory') is not None:
            self.min_peak_memory = m.get('MinPeakMemory')
        if m.get('MinScanSize') is not None:
            self.min_scan_size = m.get('MinScanSize')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('PatternId') is not None:
            self.pattern_id = m.get('PatternId')
        if m.get('QueryCondition') is not None:
            self.query_condition = m.get('QueryCondition')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeDiagnosisRecordsResponseBodyQuerysQueryProperties(TeaModel):
    def __init__(
        self,
        name: str = None,
        value: str = None,
    ):
        self.name = name
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeDiagnosisRecordsResponseBodyQuerys(TeaModel):
    def __init__(
        self,
        client_ip: str = None,
        cost: int = None,
        database: str = None,
        etl_write_rows: int = None,
        execution_time: int = None,
        output_data_size: int = None,
        output_rows: int = None,
        pattern_id: str = None,
        peak_memory: int = None,
        process_id: str = None,
        query_properties: List[DescribeDiagnosisRecordsResponseBodyQuerysQueryProperties] = None,
        queue_time: int = None,
        rc_host: str = None,
        resource_cost_rank: int = None,
        resource_group: str = None,
        sql: str = None,
        sqltruncated: bool = None,
        sqltruncated_threshold: int = None,
        scan_rows: int = None,
        scan_size: int = None,
        start_time: int = None,
        status: str = None,
        total_planning_time: int = None,
        total_stages: int = None,
        user_name: str = None,
    ):
        # The source IP address.
        self.client_ip = client_ip
        # The total execution duration. Unit: milliseconds.
        # 
        # >  This value is the cumulative value of the `QueuedTime`, `TotalPlanningTime`, and `ExecutionTime` parameters.
        self.cost = cost
        # The name of the database on which the SQL statement is executed.
        self.database = database
        # The number of rows written to the table by an extract-transform-load (ETL) job.
        self.etl_write_rows = etl_write_rows
        # The execution duration. Unit: milliseconds.
        self.execution_time = execution_time
        # The amount of returned data. Unit: bytes.
        self.output_data_size = output_data_size
        # The number of rows returned.
        self.output_rows = output_rows
        self.pattern_id = pattern_id
        # The peak memory. Unit: bytes.
        self.peak_memory = peak_memory
        # The query ID.
        self.process_id = process_id
        # The query properties.
        # 
        # >  For information about common properties, see [Config and hint configuration parameters](https://help.aliyun.com/document_detail/408955.html).
        self.query_properties = query_properties
        # The amount of time that is consumed for queuing. Unit: milliseconds.
        self.queue_time = queue_time
        # The IP address and port number of the AnalyticDB for MySQL frontend node on which the SQL statement is executed.
        self.rc_host = rc_host
        # The execution duration rank of operators that are used in the SQL statement.
        # 
        # >  This parameter is returned only for SQL statements whose `Status` parameter is `running`.
        self.resource_cost_rank = resource_cost_rank
        # The resource group to which the SQL statement belongs.
        self.resource_group = resource_group
        # The queried SQL statement.
        # 
        # >  For performance considerations, an SQL statement cannot exceed 5,120 characters in length. Otherwise, the SQL statement is truncated. You can call the [DownloadDiagnosisRecords](https://help.aliyun.com/document_detail/308212.html) operation to download the information about SQL statements that meet a query condition for an AnalyticDB for MySQL cluster, including the complete SQL statements.
        self.sql = sql
        # Indicates whether the SQL statement is truncated. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.sqltruncated = sqltruncated
        # The maximum length of the SQL statement. 5120 is returned. Unit: characters. SQL statements that exceed this limit are truncated.
        self.sqltruncated_threshold = sqltruncated_threshold
        # The number of rows scanned.
        self.scan_rows = scan_rows
        # The amount of scanned data. Unit: bytes.
        self.scan_size = scan_size
        # The execution start time of the SQL statement. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.start_time = start_time
        # The state of the SQL statement. Valid values:
        # 
        # *   **running**\
        # *   **finished**\
        # *   **failed**\
        self.status = status
        # The amount of time that is consumed to generate an execution plan. Unit: milliseconds.
        self.total_planning_time = total_planning_time
        # The total number of stages generated.
        self.total_stages = total_stages
        # The username that is used to execute the SQL statements.
        self.user_name = user_name

    def validate(self):
        if self.query_properties:
            for k in self.query_properties:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_ip is not None:
            result['ClientIp'] = self.client_ip
        if self.cost is not None:
            result['Cost'] = self.cost
        if self.database is not None:
            result['Database'] = self.database
        if self.etl_write_rows is not None:
            result['EtlWriteRows'] = self.etl_write_rows
        if self.execution_time is not None:
            result['ExecutionTime'] = self.execution_time
        if self.output_data_size is not None:
            result['OutputDataSize'] = self.output_data_size
        if self.output_rows is not None:
            result['OutputRows'] = self.output_rows
        if self.pattern_id is not None:
            result['PatternId'] = self.pattern_id
        if self.peak_memory is not None:
            result['PeakMemory'] = self.peak_memory
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        result['QueryProperties'] = []
        if self.query_properties is not None:
            for k in self.query_properties:
                result['QueryProperties'].append(k.to_map() if k else None)
        if self.queue_time is not None:
            result['QueueTime'] = self.queue_time
        if self.rc_host is not None:
            result['RcHost'] = self.rc_host
        if self.resource_cost_rank is not None:
            result['ResourceCostRank'] = self.resource_cost_rank
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.sqltruncated is not None:
            result['SQLTruncated'] = self.sqltruncated
        if self.sqltruncated_threshold is not None:
            result['SQLTruncatedThreshold'] = self.sqltruncated_threshold
        if self.scan_rows is not None:
            result['ScanRows'] = self.scan_rows
        if self.scan_size is not None:
            result['ScanSize'] = self.scan_size
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status is not None:
            result['Status'] = self.status
        if self.total_planning_time is not None:
            result['TotalPlanningTime'] = self.total_planning_time
        if self.total_stages is not None:
            result['TotalStages'] = self.total_stages
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientIp') is not None:
            self.client_ip = m.get('ClientIp')
        if m.get('Cost') is not None:
            self.cost = m.get('Cost')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('EtlWriteRows') is not None:
            self.etl_write_rows = m.get('EtlWriteRows')
        if m.get('ExecutionTime') is not None:
            self.execution_time = m.get('ExecutionTime')
        if m.get('OutputDataSize') is not None:
            self.output_data_size = m.get('OutputDataSize')
        if m.get('OutputRows') is not None:
            self.output_rows = m.get('OutputRows')
        if m.get('PatternId') is not None:
            self.pattern_id = m.get('PatternId')
        if m.get('PeakMemory') is not None:
            self.peak_memory = m.get('PeakMemory')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        self.query_properties = []
        if m.get('QueryProperties') is not None:
            for k in m.get('QueryProperties'):
                temp_model = DescribeDiagnosisRecordsResponseBodyQuerysQueryProperties()
                self.query_properties.append(temp_model.from_map(k))
        if m.get('QueueTime') is not None:
            self.queue_time = m.get('QueueTime')
        if m.get('RcHost') is not None:
            self.rc_host = m.get('RcHost')
        if m.get('ResourceCostRank') is not None:
            self.resource_cost_rank = m.get('ResourceCostRank')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('SQLTruncated') is not None:
            self.sqltruncated = m.get('SQLTruncated')
        if m.get('SQLTruncatedThreshold') is not None:
            self.sqltruncated_threshold = m.get('SQLTruncatedThreshold')
        if m.get('ScanRows') is not None:
            self.scan_rows = m.get('ScanRows')
        if m.get('ScanSize') is not None:
            self.scan_size = m.get('ScanSize')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TotalPlanningTime') is not None:
            self.total_planning_time = m.get('TotalPlanningTime')
        if m.get('TotalStages') is not None:
            self.total_stages = m.get('TotalStages')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeDiagnosisRecordsResponseBody(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        querys: List[DescribeDiagnosisRecordsResponseBodyQuerys] = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The queried SQL statements.
        self.querys = querys
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.querys:
            for k in self.querys:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        result['Querys'] = []
        if self.querys is not None:
            for k in self.querys:
                result['Querys'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        self.querys = []
        if m.get('Querys') is not None:
            for k in m.get('Querys'):
                temp_model = DescribeDiagnosisRecordsResponseBodyQuerys()
                self.querys.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeDiagnosisRecordsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDiagnosisRecordsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDiagnosisRecordsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDiagnosisSQLInfoRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lang: str = None,
        process_id: str = None,
        process_rc_host: str = None,
        process_start_time: int = None,
        process_state: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The language of file titles and error messages. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The query ID.
        # 
        # >  You can call the [DescribeDiagnosisRecords](https://help.aliyun.com/document_detail/308207.html) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL cluster, including the query ID.
        self.process_id = process_id
        # The IP address and port number of the AnalyticDB for MySQL frontend node on which the SQL statement is executed.
        # 
        # >  You can call the [DescribeDiagnosisRecords](https://help.aliyun.com/document_detail/308207.html) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster, including the IP address and port number of the frontend node.
        self.process_rc_host = process_rc_host
        # The execution start time of the SQL statement. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # >  You can call the [DescribeDiagnosisRecords](https://help.aliyun.com/document_detail/308207.html) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL cluster, including the execution start time of the SQL statement.
        self.process_start_time = process_start_time
        # The status of the SQL statement. Valid values:
        # 
        # *   **running**\
        # *   **finished**\
        # *   **failed**\
        # 
        # >  You can call the [DescribeDiagnosisRecords](https://help.aliyun.com/document_detail/308207.html) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL cluster, including the status of the SQL statement.
        self.process_state = process_state
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        if self.process_rc_host is not None:
            result['ProcessRcHost'] = self.process_rc_host
        if self.process_start_time is not None:
            result['ProcessStartTime'] = self.process_start_time
        if self.process_state is not None:
            result['ProcessState'] = self.process_state
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        if m.get('ProcessRcHost') is not None:
            self.process_rc_host = m.get('ProcessRcHost')
        if m.get('ProcessStartTime') is not None:
            self.process_start_time = m.get('ProcessStartTime')
        if m.get('ProcessState') is not None:
            self.process_state = m.get('ProcessState')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeDiagnosisSQLInfoResponseBodyStageInfos(TeaModel):
    def __init__(
        self,
        execution_type: str = None,
        input_data_size: int = None,
        input_rows: int = None,
        operator_cost: int = None,
        output_data_size: int = None,
        output_rows: int = None,
        peak_memory: int = None,
        progress: float = None,
        stage_id: str = None,
        state: str = None,
    ):
        self.execution_type = execution_type
        # The total amount of input data in the stage. Unit: bytes.
        self.input_data_size = input_data_size
        # The total number of input rows in the stage.
        self.input_rows = input_rows
        # The total amount of time consumed by all operators in the stage. Unit: milliseconds.
        self.operator_cost = operator_cost
        # The total amount of output data in the stage. Unit: bytes.
        self.output_data_size = output_data_size
        # The total number of output rows in the stage.
        self.output_rows = output_rows
        # The total peak memory of the stage. Unit: bytes.
        self.peak_memory = peak_memory
        # The execution progress of the stage.
        self.progress = progress
        # The stage ID.
        self.stage_id = stage_id
        # The state of the stage.
        self.state = state

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.execution_type is not None:
            result['ExecutionType'] = self.execution_type
        if self.input_data_size is not None:
            result['InputDataSize'] = self.input_data_size
        if self.input_rows is not None:
            result['InputRows'] = self.input_rows
        if self.operator_cost is not None:
            result['OperatorCost'] = self.operator_cost
        if self.output_data_size is not None:
            result['OutputDataSize'] = self.output_data_size
        if self.output_rows is not None:
            result['OutputRows'] = self.output_rows
        if self.peak_memory is not None:
            result['PeakMemory'] = self.peak_memory
        if self.progress is not None:
            result['Progress'] = self.progress
        if self.stage_id is not None:
            result['StageId'] = self.stage_id
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ExecutionType') is not None:
            self.execution_type = m.get('ExecutionType')
        if m.get('InputDataSize') is not None:
            self.input_data_size = m.get('InputDataSize')
        if m.get('InputRows') is not None:
            self.input_rows = m.get('InputRows')
        if m.get('OperatorCost') is not None:
            self.operator_cost = m.get('OperatorCost')
        if m.get('OutputDataSize') is not None:
            self.output_data_size = m.get('OutputDataSize')
        if m.get('OutputRows') is not None:
            self.output_rows = m.get('OutputRows')
        if m.get('PeakMemory') is not None:
            self.peak_memory = m.get('PeakMemory')
        if m.get('Progress') is not None:
            self.progress = m.get('Progress')
        if m.get('StageId') is not None:
            self.stage_id = m.get('StageId')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class DescribeDiagnosisSQLInfoResponseBody(TeaModel):
    def __init__(
        self,
        diagnosis_sqlinfo: str = None,
        request_id: str = None,
        stage_infos: List[DescribeDiagnosisSQLInfoResponseBodyStageInfos] = None,
    ):
        # The queried execution information, including the SQL statement, statistics, execution plan, and operator information.
        self.diagnosis_sqlinfo = diagnosis_sqlinfo
        # The request ID.
        self.request_id = request_id
        # The queried execution information by stage.
        self.stage_infos = stage_infos

    def validate(self):
        if self.stage_infos:
            for k in self.stage_infos:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.diagnosis_sqlinfo is not None:
            result['DiagnosisSQLInfo'] = self.diagnosis_sqlinfo
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['StageInfos'] = []
        if self.stage_infos is not None:
            for k in self.stage_infos:
                result['StageInfos'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DiagnosisSQLInfo') is not None:
            self.diagnosis_sqlinfo = m.get('DiagnosisSQLInfo')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.stage_infos = []
        if m.get('StageInfos') is not None:
            for k in m.get('StageInfos'):
                temp_model = DescribeDiagnosisSQLInfoResponseBodyStageInfos()
                self.stage_infos.append(temp_model.from_map(k))
        return self


class DescribeDiagnosisSQLInfoResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDiagnosisSQLInfoResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDiagnosisSQLInfoResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeDownloadRecordsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lang: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The language of the returned data. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeDownloadRecordsResponseBodyRecords(TeaModel):
    def __init__(
        self,
        download_id: int = None,
        exception_msg: str = None,
        file_name: str = None,
        status: str = None,
        url: str = None,
    ):
        # The download job ID.
        self.download_id = download_id
        # The error message returned if the download job failed.
        self.exception_msg = exception_msg
        # The name of the downloaded file.
        self.file_name = file_name
        # The status of the download job. Valid values:
        # 
        # *   **running**\
        # *   **finished**\
        # *   **failed**\
        self.status = status
        # The download URL of the file.
        self.url = url

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.download_id is not None:
            result['DownloadId'] = self.download_id
        if self.exception_msg is not None:
            result['ExceptionMsg'] = self.exception_msg
        if self.file_name is not None:
            result['FileName'] = self.file_name
        if self.status is not None:
            result['Status'] = self.status
        if self.url is not None:
            result['Url'] = self.url
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DownloadId') is not None:
            self.download_id = m.get('DownloadId')
        if m.get('ExceptionMsg') is not None:
            self.exception_msg = m.get('ExceptionMsg')
        if m.get('FileName') is not None:
            self.file_name = m.get('FileName')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('Url') is not None:
            self.url = m.get('Url')
        return self


class DescribeDownloadRecordsResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        records: List[DescribeDownloadRecordsResponseBodyRecords] = None,
        request_id: str = None,
    ):
        self.access_denied_detail = access_denied_detail
        # The queried download tasks.
        self.records = records
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.records:
            for k in self.records:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        result['Records'] = []
        if self.records is not None:
            for k in self.records:
                result['Records'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        self.records = []
        if m.get('Records') is not None:
            for k in m.get('Records'):
                temp_model = DescribeDownloadRecordsResponseBodyRecords()
                self.records.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeDownloadRecordsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeDownloadRecordsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeDownloadRecordsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeElasticPlanAttributeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # >  You can call the [DescribeElasticPlans](https://help.aliyun.com/document_detail/601334.html) operation to query the names of scaling plans.
        # 
        # This parameter is required.
        self.elastic_plan_name = elastic_plan_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        return self


class DescribeElasticPlanAttributeResponseBodyElasticPlan(TeaModel):
    def __init__(
        self,
        auto_scale: bool = None,
        cron_expression: str = None,
        elastic_plan_name: str = None,
        enabled: bool = None,
        end_time: str = None,
        resource_group_name: str = None,
        start_time: str = None,
        target_size: str = None,
        type: str = None,
    ):
        # Indicates whether **Default Proportional Scaling for EIUs** is enabled. Valid values: true: Default Proportional Scaling for EIUs is enabled. If you set this parameter to true, storage resources are scaled along with computing resources. false: Default Proportional Scaling for EIUs is not enabled.
        # 
        # >  You can enable Default Proportional Scaling for EIUs for only a single scaling plan of a cluster. After you enable a scaling plan of the Default Proportional Scaling for EIUs type, you cannot enable scaling plans of other types.
        self.auto_scale = auto_scale
        # A CORN expression that indicates the scaling cycle and time for the scaling plan.
        self.cron_expression = cron_expression
        # The name of the scaling plan.
        self.elastic_plan_name = elastic_plan_name
        # Indicates whether the scaling plan is enabled.
        self.enabled = enabled
        # The end time of the scaling plan.
        # 
        # >  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.
        self.end_time = end_time
        # The name of the resource group used by the scaling plan.
        self.resource_group_name = resource_group_name
        # The start time of the scaling plan.
        # 
        # >  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.
        self.start_time = start_time
        # The amount of elastic resources after scaling.
        self.target_size = target_size
        # The type of the scaling plan.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_scale is not None:
            result['AutoScale'] = self.auto_scale
        if self.cron_expression is not None:
            result['CronExpression'] = self.cron_expression
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.enabled is not None:
            result['Enabled'] = self.enabled
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.target_size is not None:
            result['TargetSize'] = self.target_size
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoScale') is not None:
            self.auto_scale = m.get('AutoScale')
        if m.get('CronExpression') is not None:
            self.cron_expression = m.get('CronExpression')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('Enabled') is not None:
            self.enabled = m.get('Enabled')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('TargetSize') is not None:
            self.target_size = m.get('TargetSize')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeElasticPlanAttributeResponseBody(TeaModel):
    def __init__(
        self,
        elastic_plan: DescribeElasticPlanAttributeResponseBodyElasticPlan = None,
        request_id: str = None,
    ):
        # The queried scaling plan.
        self.elastic_plan = elastic_plan
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.elastic_plan:
            self.elastic_plan.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.elastic_plan is not None:
            result['ElasticPlan'] = self.elastic_plan.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ElasticPlan') is not None:
            temp_model = DescribeElasticPlanAttributeResponseBodyElasticPlan()
            self.elastic_plan = temp_model.from_map(m['ElasticPlan'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeElasticPlanAttributeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeElasticPlanAttributeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeElasticPlanAttributeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeElasticPlanJobsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
        page_number: int = None,
        page_size: int = None,
        resource_group_name: str = None,
        start_time: str = None,
        status: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # > 
        # 
        # *   If you do not specify this parameter, all scaling plans of the cluster are queried.
        # 
        # *   You can call the [DescribeElasticPlans](https://help.aliyun.com/document_detail/601334.html) operation to query the names of scaling plans.
        self.elastic_plan_name = elastic_plan_name
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        # 
        # This parameter is required.
        self.page_size = page_size
        # The name of the resource group.
        # 
        # > 
        # 
        # *   If you do not specify this parameter, the scaling plans of all resource groups are queried, including the interactive resource group and elastic I/O unit (EIU) types.
        # 
        # *   You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the resource group name for a cluster.
        self.resource_group_name = resource_group_name
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        self.start_time = start_time
        # The state of the scaling plan job. Valid values:
        # 
        # *   RUNNING
        # *   SUCCESSFUL
        # *   FAILED
        # 
        # >  If you do not specify this parameter, the scaling plans in all states are queried.
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeElasticPlanJobsResponseBodyJobs(TeaModel):
    def __init__(
        self,
        elastic_acu: str = None,
        elastic_plan_name: str = None,
        end_time: str = None,
        instance_size: int = None,
        reserve_acu: str = None,
        resource_group_name: str = None,
        start_time: str = None,
        status: str = None,
        target_size: str = None,
        total_acu: str = None,
        type: str = None,
    ):
        # The amount of elastic resources.
        # 
        # > 
        # 
        # *   If Type is set to EXECUTOR, ElasticAcu indicates the amount of elastic resources in the current resource group.
        # 
        # *   If Type is set to WORKER, ElasticAcu indicates the total amount of elastic storage resources in the current cluster.
        self.elastic_acu = elastic_acu
        # The name of the scaling plan.
        self.elastic_plan_name = elastic_plan_name
        # The end time of the scaling plan job.
        # 
        # >  The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ss format. The time is displayed in UTC.
        self.end_time = end_time
        # The number of compute nodes or storage replica sets.
        # 
        # > 
        # 
        # *   If Type is set to EXECUTOR, InstanceSize indicates the number of compute nodes in the cluster.
        # 
        # *   If Type is set to EXECUTOR, InstanceSize indicates the number of storage replica sets in the cluster.
        self.instance_size = instance_size
        # The amount of reserved resources.
        # 
        # > 
        # 
        # *   If Type is set to EXECUTOR, ReserveAcu indicates the amount of reserved resources in the current resource group.
        # 
        # *   If Type is set to WORKER, ReserveAcu indicates the total amount of reserved storage resources in the current cluster.
        self.reserve_acu = reserve_acu
        # The name of the resource group.
        self.resource_group_name = resource_group_name
        # The start time of the scaling plan job.
        # 
        # >  The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ss format. The time is displayed in UTC.
        self.start_time = start_time
        # The state of the scaling plan job. Valid values:
        # 
        # *   RUNNING
        # *   SUCCESSFUL
        # *   FAILED
        self.status = status
        # The desired specifications of elastic resources after scaling.
        self.target_size = target_size
        # The total amount of resources.
        # 
        # > 
        # 
        # *   If Type is set to EXECUTOR, TotalAcu indicates the total amount of computing resources in the current resource group.
        # 
        # *   If Type is set to WORKER, TotalAcu indicates the total amount of storage resources in the cluster.
        self.total_acu = total_acu
        # The type of the scaling plan job. Valid values:
        # 
        # *   EXECUTOR: the interactive resource group type, which indicates the computing resource type.
        # *   WORKER: the EIU type.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.elastic_acu is not None:
            result['ElasticAcu'] = self.elastic_acu
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.instance_size is not None:
            result['InstanceSize'] = self.instance_size
        if self.reserve_acu is not None:
            result['ReserveAcu'] = self.reserve_acu
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status is not None:
            result['Status'] = self.status
        if self.target_size is not None:
            result['TargetSize'] = self.target_size
        if self.total_acu is not None:
            result['TotalAcu'] = self.total_acu
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ElasticAcu') is not None:
            self.elastic_acu = m.get('ElasticAcu')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('InstanceSize') is not None:
            self.instance_size = m.get('InstanceSize')
        if m.get('ReserveAcu') is not None:
            self.reserve_acu = m.get('ReserveAcu')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TargetSize') is not None:
            self.target_size = m.get('TargetSize')
        if m.get('TotalAcu') is not None:
            self.total_acu = m.get('TotalAcu')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeElasticPlanJobsResponseBody(TeaModel):
    def __init__(
        self,
        jobs: List[DescribeElasticPlanJobsResponseBodyJobs] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The queried scaling plan jobs.
        self.jobs = jobs
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of scaling plan jobs.
        self.total_count = total_count

    def validate(self):
        if self.jobs:
            for k in self.jobs:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Jobs'] = []
        if self.jobs is not None:
            for k in self.jobs:
                result['Jobs'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.jobs = []
        if m.get('Jobs') is not None:
            for k in m.get('Jobs'):
                temp_model = DescribeElasticPlanJobsResponseBodyJobs()
                self.jobs.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeElasticPlanJobsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeElasticPlanJobsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeElasticPlanJobsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeElasticPlanSpecificationsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        resource_group_name: str = None,
        type: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        # 
        # > 
        # 
        # *   This parameter must be specified only when you query the resource specifications that are supported by an interactive resource group.
        # 
        # *   You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the name of a resource group within a cluster.
        self.resource_group_name = resource_group_name
        # The type of the scaling plan. Valid values:
        # 
        # *   EXECUTOR: the interactive resource group type, which specifies the computing resource type.
        # *   WORKER: the elastic I/O unit (EIU) type.
        # 
        # This parameter is required.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeElasticPlanSpecificationsResponseBody(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        specifications: List[str] = None,
        total_count: int = None,
    ):
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The queried resource specifications.
        self.specifications = specifications
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.specifications is not None:
            result['Specifications'] = self.specifications
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Specifications') is not None:
            self.specifications = m.get('Specifications')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeElasticPlanSpecificationsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeElasticPlanSpecificationsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeElasticPlanSpecificationsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeElasticPlansRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
        enabled: bool = None,
        page_number: int = None,
        page_size: int = None,
        resource_group_name: str = None,
        type: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # > If you do not specify this parameter, all scaling plans are queried.
        self.elastic_plan_name = elastic_plan_name
        # Specifies whether to query the scaling plans that are immediately enabled after the plans are created. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.enabled = enabled
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        # 
        # This parameter is required.
        self.page_size = page_size
        # The name of the resource group.
        # 
        # > *   If you do not specify this parameter, the scaling plans of all resource groups are queried, covering the interactive resource group type and the elastic I/O unit (EIU) type.
        # >*   You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the name of a resource group within a cluster.
        self.resource_group_name = resource_group_name
        # The type of the scaling plan. Valid values:
        # 
        # *   **EXECUTOR**: the interactive resource group type, which specifies the computing resource type.
        # *   **WORKER**: the EIU type.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.enabled is not None:
            result['Enabled'] = self.enabled
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('Enabled') is not None:
            self.enabled = m.get('Enabled')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeElasticPlansResponseBodyElasticPlans(TeaModel):
    def __init__(
        self,
        auto_scale: bool = None,
        elastic_plan_name: str = None,
        enabled: bool = None,
        next_schedule_time: str = None,
        resource_group_name: str = None,
        target_size: str = None,
        type: str = None,
    ):
        # Indicates whether **Proportional Default Scaling for EIUs** is enabled. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.auto_scale = auto_scale
        # The name of the scaling plan.
        self.elastic_plan_name = elastic_plan_name
        # Indicates whether the scaling plan is immediately enabled after the plan is created. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.enabled = enabled
        # The time when the next scheduling is performed.
        # 
        # > The time is in the yyyy-MM-ddTHH:mm:ssZ format.
        self.next_schedule_time = next_schedule_time
        # The name of the resource group.
        # 
        # > You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the name of a resource group within a cluster.
        self.resource_group_name = resource_group_name
        # The amount of elastic resources after scaling.
        self.target_size = target_size
        # The type of the scaling plan. Valid values:
        # 
        # *   **EXECUTOR**: the interactive resource group type, which specifies the computing resource type.
        # *   **WORKER**: the EIU type.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_scale is not None:
            result['AutoScale'] = self.auto_scale
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.enabled is not None:
            result['Enabled'] = self.enabled
        if self.next_schedule_time is not None:
            result['NextScheduleTime'] = self.next_schedule_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.target_size is not None:
            result['TargetSize'] = self.target_size
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoScale') is not None:
            self.auto_scale = m.get('AutoScale')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('Enabled') is not None:
            self.enabled = m.get('Enabled')
        if m.get('NextScheduleTime') is not None:
            self.next_schedule_time = m.get('NextScheduleTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('TargetSize') is not None:
            self.target_size = m.get('TargetSize')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeElasticPlansResponseBody(TeaModel):
    def __init__(
        self,
        elastic_plans: List[DescribeElasticPlansResponseBodyElasticPlans] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The queried scaling plans.
        self.elastic_plans = elastic_plans
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.elastic_plans:
            for k in self.elastic_plans:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ElasticPlans'] = []
        if self.elastic_plans is not None:
            for k in self.elastic_plans:
                result['ElasticPlans'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.elastic_plans = []
        if m.get('ElasticPlans') is not None:
            for k in m.get('ElasticPlans'):
                temp_model = DescribeElasticPlansResponseBodyElasticPlans()
                self.elastic_plans.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeElasticPlansResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeElasticPlansResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeElasticPlansResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeEnabledPrivilegesRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The name of the database account.
        # 
        # >  You can call the [DescribeAccounts](https://help.aliyun.com/document_detail/612430.html) operation to query the information about database accounts for a cluster, including the account name.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeEnabledPrivilegesResponseBodyDataPrivileges(TeaModel):
    def __init__(
        self,
        description: str = None,
        key: str = None,
    ):
        # The description of the permission.
        self.description = description
        # The name of the permission.
        self.key = key

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.description is not None:
            result['Description'] = self.description
        if self.key is not None:
            result['Key'] = self.key
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        return self


class DescribeEnabledPrivilegesResponseBodyData(TeaModel):
    def __init__(
        self,
        description: str = None,
        privileges: List[DescribeEnabledPrivilegesResponseBodyDataPrivileges] = None,
        scope: str = None,
    ):
        # The description of the permission level.
        # 
        # This parameter is required.
        self.description = description
        # The queried permissions.
        # 
        # This parameter is required.
        self.privileges = privileges
        # The permission level.
        # 
        # This parameter is required.
        self.scope = scope

    def validate(self):
        if self.privileges:
            for k in self.privileges:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.description is not None:
            result['Description'] = self.description
        result['Privileges'] = []
        if self.privileges is not None:
            for k in self.privileges:
                result['Privileges'].append(k.to_map() if k else None)
        if self.scope is not None:
            result['Scope'] = self.scope
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Description') is not None:
            self.description = m.get('Description')
        self.privileges = []
        if m.get('Privileges') is not None:
            for k in m.get('Privileges'):
                temp_model = DescribeEnabledPrivilegesResponseBodyDataPrivileges()
                self.privileges.append(temp_model.from_map(k))
        if m.get('Scope') is not None:
            self.scope = m.get('Scope')
        return self


class DescribeEnabledPrivilegesResponseBody(TeaModel):
    def __init__(
        self,
        data: List[DescribeEnabledPrivilegesResponseBodyData] = None,
        request_id: str = None,
    ):
        # The queried permission level and permissions.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            for k in self.data:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Data'] = []
        if self.data is not None:
            for k in self.data:
                result['Data'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.data = []
        if m.get('Data') is not None:
            for k in m.get('Data'):
                temp_model = DescribeEnabledPrivilegesResponseBodyData()
                self.data.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeEnabledPrivilegesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeEnabledPrivilegesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeEnabledPrivilegesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeEssdCacheConfigRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DescribeEssdCacheConfigResponseBodyData(TeaModel):
    def __init__(
        self,
        enable_essd_cache: bool = None,
        essd_cache_size: int = None,
    ):
        # Specifies whether to enable the disk cache feature.
        # 
        # Valid values:
        # 
        # *   true
        # *   false
        self.enable_essd_cache = enable_essd_cache
        # The disk cache size. Unit: GB.
        self.essd_cache_size = essd_cache_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.enable_essd_cache is not None:
            result['EnableEssdCache'] = self.enable_essd_cache
        if self.essd_cache_size is not None:
            result['EssdCacheSize'] = self.essd_cache_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EnableEssdCache') is not None:
            self.enable_essd_cache = m.get('EnableEssdCache')
        if m.get('EssdCacheSize') is not None:
            self.essd_cache_size = m.get('EssdCacheSize')
        return self


class DescribeEssdCacheConfigResponseBody(TeaModel):
    def __init__(
        self,
        data: DescribeEssdCacheConfigResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = DescribeEssdCacheConfigResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeEssdCacheConfigResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeEssdCacheConfigResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeEssdCacheConfigResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeExcessivePrimaryKeysRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        order: str = None,
        owner_account: str = None,
        owner_id: int = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        self.end_time = end_time
        # The language of file titles and error messages. Valid values:
        # 
        # *   **zh (default)**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order in which table fields are sorted. Specify the value in the JSON format.
        # 
        # Example:
        # 
        #     [
        # 
        #         {
        # 
        #             "Field":"Name",
        # 
        #             "Type":"Asc"
        # 
        #         }
        # 
        #     ]
        # 
        # In the preceding code, Field specifies the field that is used to sort the table data. Set the value to Name. Type specifies the sorting order. Valid values: Desc and Asc.
        # 
        # Field and Type are case-insensitive.
        self.order = order
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The page number.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeExcessivePrimaryKeysResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        status: str = None,
    ):
        # The detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The severity level of the detection result.
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeExcessivePrimaryKeysResponseBodyTables(TeaModel):
    def __init__(
        self,
        column_count: int = None,
        primary_key_columns: str = None,
        primary_key_count: int = None,
        primary_key_index_size: int = None,
        schema_name: str = None,
        space_ratio: float = None,
        table_name: str = None,
        total_size: int = None,
    ):
        # The total number of columns.
        self.column_count = column_count
        # The queried primary key fields.
        self.primary_key_columns = primary_key_columns
        # The number of primary key fields.
        self.primary_key_count = primary_key_count
        # The data size of primary key indexes. Unit: bytes.
        self.primary_key_index_size = primary_key_index_size
        # The name of the database.
        self.schema_name = schema_name
        # The percentage of the table size. Unit: %.
        # 
        # >  Formula: Table storage percentage = Total data size of a table/Total data size of the cluster  100%.
        self.space_ratio = space_ratio
        # The name of the table
        self.table_name = table_name
        # The cold data size. Unit: bytes.
        # 
        # >  Formula: Cold data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.
        self.total_size = total_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column_count is not None:
            result['ColumnCount'] = self.column_count
        if self.primary_key_columns is not None:
            result['PrimaryKeyColumns'] = self.primary_key_columns
        if self.primary_key_count is not None:
            result['PrimaryKeyCount'] = self.primary_key_count
        if self.primary_key_index_size is not None:
            result['PrimaryKeyIndexSize'] = self.primary_key_index_size
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.space_ratio is not None:
            result['SpaceRatio'] = self.space_ratio
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColumnCount') is not None:
            self.column_count = m.get('ColumnCount')
        if m.get('PrimaryKeyColumns') is not None:
            self.primary_key_columns = m.get('PrimaryKeyColumns')
        if m.get('PrimaryKeyCount') is not None:
            self.primary_key_count = m.get('PrimaryKeyCount')
        if m.get('PrimaryKeyIndexSize') is not None:
            self.primary_key_index_size = m.get('PrimaryKeyIndexSize')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('SpaceRatio') is not None:
            self.space_ratio = m.get('SpaceRatio')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        return self


class DescribeExcessivePrimaryKeysResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        dbcluster_id: str = None,
        detection_items: List[DescribeExcessivePrimaryKeysResponseBodyDetectionItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        tables: List[DescribeExcessivePrimaryKeysResponseBodyTables] = None,
        total_count: str = None,
    ):
        # The queried information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The page number.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The queried tables that have excessive primary key fields.
        self.tables = tables
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()
        if self.tables:
            for k in self.tables:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['Tables'] = []
        if self.tables is not None:
            for k in self.tables:
                result['Tables'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeExcessivePrimaryKeysResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.tables = []
        if m.get('Tables') is not None:
            for k in m.get('Tables'):
                temp_model = DescribeExcessivePrimaryKeysResponseBodyTables()
                self.tables.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeExcessivePrimaryKeysResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeExcessivePrimaryKeysResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeExcessivePrimaryKeysResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeExecutorDetectionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.end_time = end_time
        # The language. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        self.lang = lang
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorAggSearchResults(TeaModel):
    def __init__(
        self,
        avg_value: float = None,
        max_value: int = None,
        operator_count: int = None,
        operator_name: str = None,
        total_value: int = None,
    ):
        # The average value of the operator metric.
        self.avg_value = avg_value
        # The maximum value of the operator metric.
        self.max_value = max_value
        # The number of occurrences of the operator.
        self.operator_count = operator_count
        # The name of the operator.
        self.operator_name = operator_name
        # The cumulative value of the operator metric.
        self.total_value = total_value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.avg_value is not None:
            result['AvgValue'] = self.avg_value
        if self.max_value is not None:
            result['MaxValue'] = self.max_value
        if self.operator_count is not None:
            result['OperatorCount'] = self.operator_count
        if self.operator_name is not None:
            result['OperatorName'] = self.operator_name
        if self.total_value is not None:
            result['TotalValue'] = self.total_value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AvgValue') is not None:
            self.avg_value = m.get('AvgValue')
        if m.get('MaxValue') is not None:
            self.max_value = m.get('MaxValue')
        if m.get('OperatorCount') is not None:
            self.operator_count = m.get('OperatorCount')
        if m.get('OperatorName') is not None:
            self.operator_name = m.get('OperatorName')
        if m.get('TotalValue') is not None:
            self.total_value = m.get('TotalValue')
        return self


class DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorAgg(TeaModel):
    def __init__(
        self,
        metric_name: str = None,
        search_results: List[DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorAggSearchResults] = None,
    ):
        # The name of the detection metric.
        self.metric_name = metric_name
        # The detection result items of operator metric aggregation.
        self.search_results = search_results

    def validate(self):
        if self.search_results:
            for k in self.search_results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        result['SearchResults'] = []
        if self.search_results is not None:
            for k in self.search_results:
                result['SearchResults'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        self.search_results = []
        if m.get('SearchResults') is not None:
            for k in m.get('SearchResults'):
                temp_model = DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorAggSearchResults()
                self.search_results.append(temp_model.from_map(k))
        return self


class DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorDetailsSearchResults(TeaModel):
    def __init__(
        self,
        input_rows: int = None,
        input_size: int = None,
        operator_cost: float = None,
        operator_info: str = None,
        operator_name: str = None,
        output_rows: int = None,
        output_size: int = None,
        peak_memory: int = None,
        process_id: str = None,
        stage_id: str = None,
    ):
        # The number of rows input by the operator.
        self.input_rows = input_rows
        # The amount of data input by the operator. Unit: bytes.
        self.input_size = input_size
        # The total CPU time consumed by all operators in the stage, which is equivalent to the total CPU time of the stage. You can use this parameter to determine which parts of the stage consume a large amount of computing resources. Unit: milliseconds.
        self.operator_cost = operator_cost
        # The property information about the operator.
        self.operator_info = operator_info
        # The name of the operator.
        self.operator_name = operator_name
        # The number of rows output by the operator.
        self.output_rows = output_rows
        # The amount of data output by the operator. Unit: bytes.
        self.output_size = output_size
        # The peak memory. Unit: bytes.
        self.peak_memory = peak_memory
        # The query ID.
        self.process_id = process_id
        # The stage ID.
        self.stage_id = stage_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.input_rows is not None:
            result['InputRows'] = self.input_rows
        if self.input_size is not None:
            result['InputSize'] = self.input_size
        if self.operator_cost is not None:
            result['OperatorCost'] = self.operator_cost
        if self.operator_info is not None:
            result['OperatorInfo'] = self.operator_info
        if self.operator_name is not None:
            result['OperatorName'] = self.operator_name
        if self.output_rows is not None:
            result['OutputRows'] = self.output_rows
        if self.output_size is not None:
            result['OutputSize'] = self.output_size
        if self.peak_memory is not None:
            result['PeakMemory'] = self.peak_memory
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        if self.stage_id is not None:
            result['StageId'] = self.stage_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('InputRows') is not None:
            self.input_rows = m.get('InputRows')
        if m.get('InputSize') is not None:
            self.input_size = m.get('InputSize')
        if m.get('OperatorCost') is not None:
            self.operator_cost = m.get('OperatorCost')
        if m.get('OperatorInfo') is not None:
            self.operator_info = m.get('OperatorInfo')
        if m.get('OperatorName') is not None:
            self.operator_name = m.get('OperatorName')
        if m.get('OutputRows') is not None:
            self.output_rows = m.get('OutputRows')
        if m.get('OutputSize') is not None:
            self.output_size = m.get('OutputSize')
        if m.get('PeakMemory') is not None:
            self.peak_memory = m.get('PeakMemory')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        if m.get('StageId') is not None:
            self.stage_id = m.get('StageId')
        return self


class DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorDetails(TeaModel):
    def __init__(
        self,
        metric_name: str = None,
        search_results: List[DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorDetailsSearchResults] = None,
    ):
        # The name of the detection metric.
        self.metric_name = metric_name
        # The detection result items of abnormal operators.
        self.search_results = search_results

    def validate(self):
        if self.search_results:
            for k in self.search_results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        result['SearchResults'] = []
        if self.search_results is not None:
            for k in self.search_results:
                result['SearchResults'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        self.search_results = []
        if m.get('SearchResults') is not None:
            for k in m.get('SearchResults'):
                temp_model = DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorDetailsSearchResults()
                self.search_results.append(temp_model.from_map(k))
        return self


class DescribeExecutorDetectionResponseBodyDetectionItemsResults(TeaModel):
    def __init__(
        self,
        operator_agg: List[DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorAgg] = None,
        operator_details: List[DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorDetails] = None,
    ):
        # The detection result items of operator metric aggregation.
        self.operator_agg = operator_agg
        # The detection result items of abnormal operators.
        self.operator_details = operator_details

    def validate(self):
        if self.operator_agg:
            for k in self.operator_agg:
                if k:
                    k.validate()
        if self.operator_details:
            for k in self.operator_details:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['OperatorAgg'] = []
        if self.operator_agg is not None:
            for k in self.operator_agg:
                result['OperatorAgg'].append(k.to_map() if k else None)
        result['OperatorDetails'] = []
        if self.operator_details is not None:
            for k in self.operator_details:
                result['OperatorDetails'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.operator_agg = []
        if m.get('OperatorAgg') is not None:
            for k in m.get('OperatorAgg'):
                temp_model = DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorAgg()
                self.operator_agg.append(temp_model.from_map(k))
        self.operator_details = []
        if m.get('OperatorDetails') is not None:
            for k in m.get('OperatorDetails'):
                temp_model = DescribeExecutorDetectionResponseBodyDetectionItemsResultsOperatorDetails()
                self.operator_details.append(temp_model.from_map(k))
        return self


class DescribeExecutorDetectionResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        results: DescribeExecutorDetectionResponseBodyDetectionItemsResults = None,
        status: str = None,
    ):
        # The information about the detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The detection result items.
        self.results = results
        # The severity level of the detection result. Valid values:
        # 
        # *   NORMAL
        # *   WARNING
        # *   CRITICAL
        self.status = status

    def validate(self):
        if self.results:
            self.results.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.results is not None:
            result['Results'] = self.results.to_map()
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Results') is not None:
            temp_model = DescribeExecutorDetectionResponseBodyDetectionItemsResults()
            self.results = temp_model.from_map(m['Results'])
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeExecutorDetectionResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        detection_items: List[DescribeExecutorDetectionResponseBodyDetectionItems] = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Warehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeExecutorDetectionResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeExecutorDetectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeExecutorDetectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeExecutorDetectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeInclinedNodesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lang: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The language of file titles and error messages. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeInclinedNodesResponseBodyItems(TeaModel):
    def __init__(
        self,
        disk_usage_ratio: str = None,
        node: str = None,
    ):
        # The disk usage of the storage node.
        self.disk_usage_ratio = disk_usage_ratio
        # The number of the storage node.
        self.node = node

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disk_usage_ratio is not None:
            result['DiskUsageRatio'] = self.disk_usage_ratio
        if self.node is not None:
            result['Node'] = self.node
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DiskUsageRatio') is not None:
            self.disk_usage_ratio = m.get('DiskUsageRatio')
        if m.get('Node') is not None:
            self.node = m.get('Node')
        return self


class DescribeInclinedNodesResponseBody(TeaModel):
    def __init__(
        self,
        items: List[DescribeInclinedNodesResponseBodyItems] = None,
        request_id: str = None,
    ):
        # The queried storage nodes.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeInclinedNodesResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeInclinedNodesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeInclinedNodesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeInclinedNodesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeInclinedTablesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lang: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        table_type: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The language. Valid values:
        # 
        # *   **zh (default)**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order by which to sort query results. Specify the parameter value in the JSON format.
        # 
        # Example:
        # 
        #     [
        # 
        #         {
        # 
        #             "Field":"Name",
        # 
        #             "Type":"Asc"
        # 
        #         }
        # 
        #     ]
        # 
        # Field specifies the field by which to sort the query results. Set the value to Name. Type specifies the sorting order. Valid values: Desc and Asc.
        # 
        # Field and Type are case-insensitive.
        self.order = order
        # The page number. Pages start from page 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        self.region_id = region_id
        # The type of the table. Valid values:
        # 
        # *   **FactTable**: the partitioned table.
        # *   **DimensionTable**: the dimension table.
        self.table_type = table_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.table_type is not None:
            result['TableType'] = self.table_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('TableType') is not None:
            self.table_type = m.get('TableType')
        return self


class DescribeInclinedTablesResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        status: str = None,
    ):
        # The message of the detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The severity level of the detection result.
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeInclinedTablesResponseBodyItemsTable(TeaModel):
    def __init__(
        self,
        is_incline: bool = None,
        name: str = None,
        row_count: int = None,
        schema: str = None,
        size: int = None,
        space_ratio: float = None,
        total_size: int = None,
        type: str = None,
    ):
        # Indicates whether data is skewed in the table.
        self.is_incline = is_incline
        # The name of the table.
        self.name = name
        # The number of rows in the table.
        self.row_count = row_count
        # The name of the database.
        self.schema = schema
        # The number of rows in the table.
        self.size = size
        # The percentage of the table size. Unit: %.
        # 
        # >  Formula: Table storage percentage = Total data size of a table/Total data size of the cluster  100%.
        self.space_ratio = space_ratio
        # The total data size of the table. Unit: bytes.
        # 
        # >  The following formulas can be used to calculate the total data size:
        # 
        # *   Formula 1: Total data size = Hot data size + Cold data size.
        # *   Formula 2: Total data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.
        self.total_size = total_size
        # The detection type of the table.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.is_incline is not None:
            result['IsIncline'] = self.is_incline
        if self.name is not None:
            result['Name'] = self.name
        if self.row_count is not None:
            result['RowCount'] = self.row_count
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.size is not None:
            result['Size'] = self.size
        if self.space_ratio is not None:
            result['SpaceRatio'] = self.space_ratio
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('IsIncline') is not None:
            self.is_incline = m.get('IsIncline')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('RowCount') is not None:
            self.row_count = m.get('RowCount')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        if m.get('SpaceRatio') is not None:
            self.space_ratio = m.get('SpaceRatio')
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeInclinedTablesResponseBodyItems(TeaModel):
    def __init__(
        self,
        table: List[DescribeInclinedTablesResponseBodyItemsTable] = None,
    ):
        # The queried table.
        self.table = table

    def validate(self):
        if self.table:
            for k in self.table:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Table'] = []
        if self.table is not None:
            for k in self.table:
                result['Table'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.table = []
        if m.get('Table') is not None:
            for k in m.get('Table'):
                temp_model = DescribeInclinedTablesResponseBodyItemsTable()
                self.table.append(temp_model.from_map(k))
        return self


class DescribeInclinedTablesResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        detection_items: List[DescribeInclinedTablesResponseBodyDetectionItems] = None,
        items: DescribeInclinedTablesResponseBodyItems = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The details about the access denial. This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The queried tables.
        self.items = items
        # The page number. Pages start from page 1.
        self.page_number = page_number
        # The total number of pages.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeInclinedTablesResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('Items') is not None:
            temp_model = DescribeInclinedTablesResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeInclinedTablesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeInclinedTablesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeInclinedTablesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeJobResourceUsageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        start_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC. The end time must be later than the start time.
        # 
        # This parameter is required.
        self.end_time = end_time
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeJobResourceUsageResponseBodyDataJobAcuUsageAcuUsageDetail(TeaModel):
    def __init__(
        self,
        elastic_acu_number: float = None,
        reserved_acu_number: float = None,
        spot_acu_number: float = None,
        spot_acu_percentage: float = None,
        total_acu_number: float = None,
    ):
        # The number of ACUs for the elastic resources.
        self.elastic_acu_number = elastic_acu_number
        # The number of ACUs for the reserved resources.
        self.reserved_acu_number = reserved_acu_number
        # The number of spot ACUs.
        self.spot_acu_number = spot_acu_number
        # The percent of spot ACUs.
        self.spot_acu_percentage = spot_acu_percentage
        # The total number of ACUs.
        self.total_acu_number = total_acu_number

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.elastic_acu_number is not None:
            result['ElasticAcuNumber'] = self.elastic_acu_number
        if self.reserved_acu_number is not None:
            result['ReservedAcuNumber'] = self.reserved_acu_number
        if self.spot_acu_number is not None:
            result['SpotAcuNumber'] = self.spot_acu_number
        if self.spot_acu_percentage is not None:
            result['SpotAcuPercentage'] = self.spot_acu_percentage
        if self.total_acu_number is not None:
            result['TotalAcuNumber'] = self.total_acu_number
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ElasticAcuNumber') is not None:
            self.elastic_acu_number = m.get('ElasticAcuNumber')
        if m.get('ReservedAcuNumber') is not None:
            self.reserved_acu_number = m.get('ReservedAcuNumber')
        if m.get('SpotAcuNumber') is not None:
            self.spot_acu_number = m.get('SpotAcuNumber')
        if m.get('SpotAcuPercentage') is not None:
            self.spot_acu_percentage = m.get('SpotAcuPercentage')
        if m.get('TotalAcuNumber') is not None:
            self.total_acu_number = m.get('TotalAcuNumber')
        return self


class DescribeJobResourceUsageResponseBodyDataJobAcuUsage(TeaModel):
    def __init__(
        self,
        acu_usage_detail: DescribeJobResourceUsageResponseBodyDataJobAcuUsageAcuUsageDetail = None,
        job_end_time: str = None,
        job_id: str = None,
        job_start_time: str = None,
        resource_group_name: str = None,
    ):
        # The ACU usage.
        self.acu_usage_detail = acu_usage_detail
        # The end time of the job. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.job_end_time = job_end_time
        # The job ID.
        self.job_id = job_id
        # The start time of the job. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.job_start_time = job_start_time
        # The name of the job resource group.
        self.resource_group_name = resource_group_name

    def validate(self):
        if self.acu_usage_detail:
            self.acu_usage_detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.acu_usage_detail is not None:
            result['AcuUsageDetail'] = self.acu_usage_detail.to_map()
        if self.job_end_time is not None:
            result['JobEndTime'] = self.job_end_time
        if self.job_id is not None:
            result['JobId'] = self.job_id
        if self.job_start_time is not None:
            result['JobStartTime'] = self.job_start_time
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AcuUsageDetail') is not None:
            temp_model = DescribeJobResourceUsageResponseBodyDataJobAcuUsageAcuUsageDetail()
            self.acu_usage_detail = temp_model.from_map(m['AcuUsageDetail'])
        if m.get('JobEndTime') is not None:
            self.job_end_time = m.get('JobEndTime')
        if m.get('JobId') is not None:
            self.job_id = m.get('JobId')
        if m.get('JobStartTime') is not None:
            self.job_start_time = m.get('JobStartTime')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class DescribeJobResourceUsageResponseBodyData(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        job_acu_usage: List[DescribeJobResourceUsageResponseBodyDataJobAcuUsage] = None,
        start_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The end time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.end_time = end_time
        # The AnalyticDB compute unit (ACU) usage of the job resource group.
        self.job_acu_usage = job_acu_usage
        # The start time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.start_time = start_time

    def validate(self):
        if self.job_acu_usage:
            for k in self.job_acu_usage:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        result['JobAcuUsage'] = []
        if self.job_acu_usage is not None:
            for k in self.job_acu_usage:
                result['JobAcuUsage'].append(k.to_map() if k else None)
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        self.job_acu_usage = []
        if m.get('JobAcuUsage') is not None:
            for k in m.get('JobAcuUsage'):
                temp_model = DescribeJobResourceUsageResponseBodyDataJobAcuUsage()
                self.job_acu_usage.append(temp_model.from_map(k))
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeJobResourceUsageResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: DescribeJobResourceUsageResponseBodyData = None,
        request_id: str = None,
    ):
        # The HTTP status code.
        self.code = code
        # The queried resource usage.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = DescribeJobResourceUsageResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeJobResourceUsageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeJobResourceUsageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeJobResourceUsageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeKernelVersionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # > 
        # 
        # *   You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/98094.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeKernelVersionResponseBodyAvailableKernelVersions(TeaModel):
    def __init__(
        self,
        expire_date: str = None,
        kernel_version: str = None,
        release_date: str = None,
    ):
        # The maintenance expiration time of the version. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. After the time arrives, the system no longer maintains the version. If any issues occur, update the minor version of the cluster to a later version.
        self.expire_date = expire_date
        # The minor version. Example: **3.1.9**.
        self.kernel_version = kernel_version
        # The time when the minor version was released. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.release_date = release_date

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.expire_date is not None:
            result['ExpireDate'] = self.expire_date
        if self.kernel_version is not None:
            result['KernelVersion'] = self.kernel_version
        if self.release_date is not None:
            result['ReleaseDate'] = self.release_date
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ExpireDate') is not None:
            self.expire_date = m.get('ExpireDate')
        if m.get('KernelVersion') is not None:
            self.kernel_version = m.get('KernelVersion')
        if m.get('ReleaseDate') is not None:
            self.release_date = m.get('ReleaseDate')
        return self


class DescribeKernelVersionResponseBody(TeaModel):
    def __init__(
        self,
        available_kernel_versions: List[DescribeKernelVersionResponseBodyAvailableKernelVersions] = None,
        expire_date: str = None,
        kernel_version: str = None,
        request_id: str = None,
    ):
        # The minor versions to which you can update the current minor version of the cluster.
        self.available_kernel_versions = available_kernel_versions
        # The maintenance expiration time of the version. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. After the time arrives, the system no longer maintains the version. If any issues occur, update the minor version of the cluster to a later version.
        self.expire_date = expire_date
        # The minor version of the cluster. Example: **3.1.8**.
        self.kernel_version = kernel_version
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.available_kernel_versions:
            for k in self.available_kernel_versions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AvailableKernelVersions'] = []
        if self.available_kernel_versions is not None:
            for k in self.available_kernel_versions:
                result['AvailableKernelVersions'].append(k.to_map() if k else None)
        if self.expire_date is not None:
            result['ExpireDate'] = self.expire_date
        if self.kernel_version is not None:
            result['KernelVersion'] = self.kernel_version
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.available_kernel_versions = []
        if m.get('AvailableKernelVersions') is not None:
            for k in m.get('AvailableKernelVersions'):
                temp_model = DescribeKernelVersionResponseBodyAvailableKernelVersions()
                self.available_kernel_versions.append(temp_model.from_map(k))
        if m.get('ExpireDate') is not None:
            self.expire_date = m.get('ExpireDate')
        if m.get('KernelVersion') is not None:
            self.kernel_version = m.get('KernelVersion')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeKernelVersionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeKernelVersionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeKernelVersionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeLLMAnswerRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        query: str = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # >  Enterprise Edition, Basic Edition, and Data Lakehouse Edition: You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The question proposed by a user.
        # 
        # This parameter is required.
        self.query = query
        # The region ID
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.query is not None:
            result['Query'] = self.query
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Query') is not None:
            self.query = m.get('Query')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeLLMAnswerResponseBody(TeaModel):
    def __init__(
        self,
        content: str = None,
        request_id: str = None,
        session_id: str = None,
    ):
        # The answer by the intelligent assistant to the question.
        self.content = content
        # The request ID.
        self.request_id = request_id
        # The session ID.
        self.session_id = session_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        return self


class DescribeLLMAnswerResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeLLMAnswerResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeLLMAnswerResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeLLMSimilarQuestionsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        query: str = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The question proposed by a user.
        # 
        # This parameter is required.
        self.query = query
        # The region ID
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.query is not None:
            result['Query'] = self.query
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Query') is not None:
            self.query = m.get('Query')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeLLMSimilarQuestionsResponseBodyItems(TeaModel):
    def __init__(
        self,
        answer: str = None,
        id: str = None,
        score: float = None,
        source: str = None,
        summary: str = None,
        title: str = None,
        url: str = None,
    ):
        # The answer to the similar question.
        self.answer = answer
        # The ID of the similar question.
        self.id = id
        # The similarity of the similar question.
        self.score = score
        # The source of the similar question.
        self.source = source
        # The summary of the similar question.
        self.summary = summary
        # The content of the similar question.
        self.title = title
        # The URL of the answer to the similar question.
        self.url = url

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.answer is not None:
            result['Answer'] = self.answer
        if self.id is not None:
            result['Id'] = self.id
        if self.score is not None:
            result['Score'] = self.score
        if self.source is not None:
            result['Source'] = self.source
        if self.summary is not None:
            result['Summary'] = self.summary
        if self.title is not None:
            result['Title'] = self.title
        if self.url is not None:
            result['Url'] = self.url
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Answer') is not None:
            self.answer = m.get('Answer')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('Score') is not None:
            self.score = m.get('Score')
        if m.get('Source') is not None:
            self.source = m.get('Source')
        if m.get('Summary') is not None:
            self.summary = m.get('Summary')
        if m.get('Title') is not None:
            self.title = m.get('Title')
        if m.get('Url') is not None:
            self.url = m.get('Url')
        return self


class DescribeLLMSimilarQuestionsResponseBody(TeaModel):
    def __init__(
        self,
        items: List[DescribeLLMSimilarQuestionsResponseBodyItems] = None,
        request_id: str = None,
        session_id: str = None,
    ):
        # The queried similar questions.
        self.items = items
        # The request ID.
        self.request_id = request_id
        # The session ID.
        self.session_id = session_id

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeLLMSimilarQuestionsResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        return self


class DescribeLLMSimilarQuestionsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeLLMSimilarQuestionsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeLLMSimilarQuestionsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeLakeCacheSizeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DescribeLakeCacheSizeResponseBodyData(TeaModel):
    def __init__(
        self,
        capacity: int = None,
        dbcluster_id: str = None,
        data_size: int = None,
        enable_lake_cache: bool = None,
        instances: List[str] = None,
    ):
        # The size of the lake cache space. Unit: GB.
        self.capacity = capacity
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The size of the data that occupies the lake cache space. Unit: GB.
        self.data_size = data_size
        # Indicates whether the lake cache feature is enabled.
        self.enable_lake_cache = enable_lake_cache
        # The clusters that share the lake cache space.
        self.instances = instances

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capacity is not None:
            result['Capacity'] = self.capacity
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.data_size is not None:
            result['DataSize'] = self.data_size
        if self.enable_lake_cache is not None:
            result['EnableLakeCache'] = self.enable_lake_cache
        if self.instances is not None:
            result['Instances'] = self.instances
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Capacity') is not None:
            self.capacity = m.get('Capacity')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DataSize') is not None:
            self.data_size = m.get('DataSize')
        if m.get('EnableLakeCache') is not None:
            self.enable_lake_cache = m.get('EnableLakeCache')
        if m.get('Instances') is not None:
            self.instances = m.get('Instances')
        return self


class DescribeLakeCacheSizeResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: DescribeLakeCacheSizeResponseBodyData = None,
        request_id: str = None,
    ):
        # The status code. The value 200 indicates that the request is successful.
        self.code = code
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = DescribeLakeCacheSizeResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeLakeCacheSizeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeLakeCacheSizeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeLakeCacheSizeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeOperatorPermissionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeOperatorPermissionResponseBody(TeaModel):
    def __init__(
        self,
        created_time: str = None,
        dbcluster_id: str = None,
        expired_time: str = None,
        privileges: str = None,
        request_id: str = None,
    ):
        # The time when the permissions take effect.
        self.created_time = created_time
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The time when the permissions expire.
        self.expired_time = expired_time
        # The queried permissions.
        self.privileges = privileges
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.created_time is not None:
            result['CreatedTime'] = self.created_time
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.expired_time is not None:
            result['ExpiredTime'] = self.expired_time
        if self.privileges is not None:
            result['Privileges'] = self.privileges
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreatedTime') is not None:
            self.created_time = m.get('CreatedTime')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ExpiredTime') is not None:
            self.expired_time = m.get('ExpiredTime')
        if m.get('Privileges') is not None:
            self.privileges = m.get('Privileges')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeOperatorPermissionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeOperatorPermissionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeOperatorPermissionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeOversizeNonPartitionTableInfosRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        order: str = None,
        owner_account: str = None,
        owner_id: int = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        # 
        # >  The end time must be later than the start time. The specified time range must be less than seven days.
        self.end_time = end_time
        # The language of file titles and error messages. Valid values:
        # 
        # *   **zh (default)**: simplified Chinese.
        # *   **en**: English
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order by which to sort query results. Specify the parameter value in the JSON format.
        # 
        # Example:
        # 
        #     [
        # 
        #         {
        # 
        #             "Field":"Name",
        # 
        #             "Type":"Asc"
        # 
        #         }
        # 
        #     ]
        # 
        # Field specifies the field by which to sort the query results. Set the value to Name. Type specifies the sorting order. Valid values: Desc and Asc.
        # 
        # Field and Type are case-insensitive.
        self.order = order
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   30
        # *   50
        # *   100
        # 
        # Default value: 30.
        self.page_size = page_size
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        # 
        # >
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeOversizeNonPartitionTableInfosResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        status: str = None,
    ):
        # The information about the detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The severity level of the detection result.
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeOversizeNonPartitionTableInfosResponseBodyTables(TeaModel):
    def __init__(
        self,
        data_size: int = None,
        index_size: int = None,
        local_data_size: int = None,
        primary_key_size: int = None,
        remote_data_size: int = None,
        row_count: int = None,
        schema_name: str = None,
        space_ratio: float = None,
        table_name: str = None,
    ):
        # The data size of the table. Unit: bytes.
        self.data_size = data_size
        # The data size of regular indexes. Unit: bytes.
        self.index_size = index_size
        # The size of hot data. Unit: bytes.
        self.local_data_size = local_data_size
        # The data size of the primary key index. Unit: bytes.
        self.primary_key_size = primary_key_size
        # The size of cold data. Unit: bytes.
        self.remote_data_size = remote_data_size
        # The number of rows in the table.
        self.row_count = row_count
        # The name of the database.
        self.schema_name = schema_name
        # The percentage of the table size. Unit: %.
        # 
        # >  Formula: Table storage percentage = Total data size of a table/Total data size of the cluster  100%.
        self.space_ratio = space_ratio
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data_size is not None:
            result['DataSize'] = self.data_size
        if self.index_size is not None:
            result['IndexSize'] = self.index_size
        if self.local_data_size is not None:
            result['LocalDataSize'] = self.local_data_size
        if self.primary_key_size is not None:
            result['PrimaryKeySize'] = self.primary_key_size
        if self.remote_data_size is not None:
            result['RemoteDataSize'] = self.remote_data_size
        if self.row_count is not None:
            result['RowCount'] = self.row_count
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.space_ratio is not None:
            result['SpaceRatio'] = self.space_ratio
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DataSize') is not None:
            self.data_size = m.get('DataSize')
        if m.get('IndexSize') is not None:
            self.index_size = m.get('IndexSize')
        if m.get('LocalDataSize') is not None:
            self.local_data_size = m.get('LocalDataSize')
        if m.get('PrimaryKeySize') is not None:
            self.primary_key_size = m.get('PrimaryKeySize')
        if m.get('RemoteDataSize') is not None:
            self.remote_data_size = m.get('RemoteDataSize')
        if m.get('RowCount') is not None:
            self.row_count = m.get('RowCount')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('SpaceRatio') is not None:
            self.space_ratio = m.get('SpaceRatio')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeOversizeNonPartitionTableInfosResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        detection_items: List[DescribeOversizeNonPartitionTableInfosResponseBodyDetectionItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        tables: List[DescribeOversizeNonPartitionTableInfosResponseBodyTables] = None,
        total_count: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The page number.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The queried oversized non-partitioned tables.
        self.tables = tables
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()
        if self.tables:
            for k in self.tables:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['Tables'] = []
        if self.tables is not None:
            for k in self.tables:
                result['Tables'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeOversizeNonPartitionTableInfosResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.tables = []
        if m.get('Tables') is not None:
            for k in m.get('Tables'):
                temp_model = DescribeOversizeNonPartitionTableInfosResponseBodyTables()
                self.tables.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeOversizeNonPartitionTableInfosResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeOversizeNonPartitionTableInfosResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeOversizeNonPartitionTableInfosResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribePatternPerformanceRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        pattern_id: str = None,
        region_id: str = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        # 
        # > The end time must be later than the start time.
        self.end_time = end_time
        # The SQL pattern ID.
        # 
        # >  You can call the [DescribeSQLPatterns](https://help.aliyun.com/document_detail/321868.html) operation to query the information about all SQL patterns in an AnalyticDB for MySQL cluster within a period of time, including SQL pattern IDs.
        self.pattern_id = pattern_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        # 
        # > 
        # 
        # *   If the current date is August 22, 2022 (UTC+8), you can query the data of August 9, 2022 (2022-08-08T16:00:00Z) to the earliest extent. If you want to query the data that is earlier than August 9, 2022 (2022-08-08T16:00:00Z), null is returned.
        # 
        # *   The maximum time range that can be specified is 24 hours.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.pattern_id is not None:
            result['PatternId'] = self.pattern_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('PatternId') is not None:
            self.pattern_id = m.get('PatternId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribePatternPerformanceResponseBodyPerformancesSeries(TeaModel):
    def __init__(
        self,
        name: str = None,
        values: List[str] = None,
    ):
        # The name of the performance metric value. Valid values:
        # 
        # *   If the value of `Key` is `AnalyticDB_PatternQueryCount`, `pattern_query_count` is returned, which indicates the number of executions of the SQL statements in association with the SQL pattern.
        # 
        # *   If the value of `Key` is `AnalyticDB_PatternQueryTime`, the following values are returned:
        # 
        #     *   `average_query_time`, which indicates the average total amount of time consumed by the SQL statements in association with the SQL pattern.
        #     *   `max_query_time`, which indicates the maximum total amount of time consumed by the SQL statements in association with the SQL pattern.
        # 
        # *   If the value of `Key` is `AnalyticDB_PatternExecutionTime`, the following values are returned:
        # 
        #     *   `average_execution_time`, which indicates the average execution duration of the SQL statements in association with the SQL pattern.
        #     *   `max_execution_time`, which indicates the maximum execution duration of the SQL statements in association with the SQL pattern.
        # 
        # *   If the value of `Key` is `AnalyticDB_PatternPeakMemory`, the following values are returned:
        # 
        #     *   `average_peak_memory`, which indicates the average peak memory usage of the SQL statements in association with the SQL pattern.
        #     *   `max_peak_memory`, which indicates the maximum peak memory usage of the SQL statements in association with the SQL pattern.
        # 
        # *   If the value of `Key` is `AnalyticDB_PatternScanSize`, the following values are returned:
        # 
        #     *   `average_scan_size`, which indicates the average amount of data scanned by the SQL statements in association with the SQL pattern.
        #     *   `max_scan_size`, which indicates the maximum amount of data scanned by the SQL statements in association with the SQL pattern.
        self.name = name
        # The values of the performance metric.
        self.values = values

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.values is not None:
            result['Values'] = self.values
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Values') is not None:
            self.values = m.get('Values')
        return self


class DescribePatternPerformanceResponseBodyPerformances(TeaModel):
    def __init__(
        self,
        key: str = None,
        series: List[DescribePatternPerformanceResponseBodyPerformancesSeries] = None,
        unit: str = None,
    ):
        # The queried performance metric. Valid values:
        # 
        # *   **AnalyticDB_PatternQueryCount**: the total number of queries executed in association with the SQL pattern.
        # *   **AnalyticDB_PatternQueryTime**: the total amount of time consumed by the queries executed in association with the SQL pattern.
        # *   **AnalyticDB_PatternExecutionTime**: the execution duration of the queries executed in association with the SQL pattern.
        # *   **AnalyticDB_PatternPeakMemory**: the peak memory usage of the queries executed in association with the SQL pattern.
        # *   **AnalyticDB_PatternScanSize**: the amount of data scanned in the queries executed in association with the SQL pattern.
        self.key = key
        # The values of the performance metrics.
        self.series = series
        # The unit of the performance metric. Valid values:
        # 
        # *   If the performance metric is related to the query time (the value of `Key` is `AnalyticDB_PatternQueryTime` or `AnalyticDB_PatternExecutionTime`), **ms** is returned.
        # *   If the performance metric is related to the peak memory usage (the value of `Key` is `AnalyticDB_PatternPeakMemory`), **MB** is returned.
        # *   If the performance metric is related to the amount of data scanned (the value of `Key` is `AnalyticDB_PatternScanSize`), **MB** is returned.
        # *   If the performance metric is related to the number of queries (the value of `Key` is `AnalyticDB_PatternQueryCount`), null is returned.
        self.unit = unit

    def validate(self):
        if self.series:
            for k in self.series:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        result['Series'] = []
        if self.series is not None:
            for k in self.series:
                result['Series'].append(k.to_map() if k else None)
        if self.unit is not None:
            result['Unit'] = self.unit
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        self.series = []
        if m.get('Series') is not None:
            for k in m.get('Series'):
                temp_model = DescribePatternPerformanceResponseBodyPerformancesSeries()
                self.series.append(temp_model.from_map(k))
        if m.get('Unit') is not None:
            self.unit = m.get('Unit')
        return self


class DescribePatternPerformanceResponseBody(TeaModel):
    def __init__(
        self,
        access_ip: str = None,
        end_time: str = None,
        failed_count: int = None,
        performances: List[DescribePatternPerformanceResponseBodyPerformances] = None,
        query_count: int = None,
        request_id: str = None,
        sqlpattern: str = None,
        start_time: str = None,
        tables: str = None,
        user: str = None,
    ):
        self.access_ip = access_ip
        # The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.
        self.end_time = end_time
        self.failed_count = failed_count
        # The queried performance metrics.
        self.performances = performances
        self.query_count = query_count
        # The request ID.
        self.request_id = request_id
        self.sqlpattern = sqlpattern
        # The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.
        self.start_time = start_time
        self.tables = tables
        self.user = user

    def validate(self):
        if self.performances:
            for k in self.performances:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_ip is not None:
            result['AccessIp'] = self.access_ip
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.failed_count is not None:
            result['FailedCount'] = self.failed_count
        result['Performances'] = []
        if self.performances is not None:
            for k in self.performances:
                result['Performances'].append(k.to_map() if k else None)
        if self.query_count is not None:
            result['QueryCount'] = self.query_count
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.sqlpattern is not None:
            result['SQLPattern'] = self.sqlpattern
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.tables is not None:
            result['Tables'] = self.tables
        if self.user is not None:
            result['User'] = self.user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessIp') is not None:
            self.access_ip = m.get('AccessIp')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('FailedCount') is not None:
            self.failed_count = m.get('FailedCount')
        self.performances = []
        if m.get('Performances') is not None:
            for k in m.get('Performances'):
                temp_model = DescribePatternPerformanceResponseBodyPerformances()
                self.performances.append(temp_model.from_map(k))
        if m.get('QueryCount') is not None:
            self.query_count = m.get('QueryCount')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SQLPattern') is not None:
            self.sqlpattern = m.get('SQLPattern')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Tables') is not None:
            self.tables = m.get('Tables')
        if m.get('User') is not None:
            self.user = m.get('User')
        return self


class DescribePatternPerformanceResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribePatternPerformanceResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribePatternPerformanceResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribePerformanceViewAttributeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        view_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The name of the view.
        # 
        # This parameter is required.
        self.view_name = view_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class DescribePerformanceViewAttributeResponseBodyViewDetailCategoriesKeys(TeaModel):
    def __init__(
        self,
        enable_auto_mc: bool = None,
        engine: List[str] = None,
        group_type: List[str] = None,
        key_name: str = None,
        selected: bool = None,
    ):
        # Indicates whether the multi-cluster feature is enabled. Valid values:
        # 
        # - true
        # 
        # - false
        self.enable_auto_mc = enable_auto_mc
        # The database engine of the cluster. Valid values:
        # 
        # *  AnalyticDB
        self.engine = engine
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # >  For more information about resource groups, see [Resource group overview](https://help.aliyun.com/document_detail/428610.html).
        self.group_type = group_type
        # The name of the metric.
        self.key_name = key_name
        # Specifies whether to select the metric. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.selected = selected

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.enable_auto_mc is not None:
            result['EnableAutoMc'] = self.enable_auto_mc
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.key_name is not None:
            result['KeyName'] = self.key_name
        if self.selected is not None:
            result['Selected'] = self.selected
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('EnableAutoMc') is not None:
            self.enable_auto_mc = m.get('EnableAutoMc')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('KeyName') is not None:
            self.key_name = m.get('KeyName')
        if m.get('Selected') is not None:
            self.selected = m.get('Selected')
        return self


class DescribePerformanceViewAttributeResponseBodyViewDetailCategories(TeaModel):
    def __init__(
        self,
        category: str = None,
        keys: List[DescribePerformanceViewAttributeResponseBodyViewDetailCategoriesKeys] = None,
    ):
        # The name of the metric category. Valid values:
        # 
        # *   **Node**\
        # *   **DiskData**\
        # *   **WorkLoad**\
        # *   **ResourceGroup**\
        self.category = category
        # The metrics.
        self.keys = keys

    def validate(self):
        if self.keys:
            for k in self.keys:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        result['Keys'] = []
        if self.keys is not None:
            for k in self.keys:
                result['Keys'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        self.keys = []
        if m.get('Keys') is not None:
            for k in m.get('Keys'):
                temp_model = DescribePerformanceViewAttributeResponseBodyViewDetailCategoriesKeys()
                self.keys.append(temp_model.from_map(k))
        return self


class DescribePerformanceViewAttributeResponseBodyViewDetail(TeaModel):
    def __init__(
        self,
        categories: List[DescribePerformanceViewAttributeResponseBodyViewDetailCategories] = None,
        chart_linked: bool = None,
        charts_per_line: int = None,
    ):
        # The metric category.
        self.categories = categories
        # Specifies whether to enable the filter interaction feature. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.chart_linked = chart_linked
        # The number of charts to display in each row.
        self.charts_per_line = charts_per_line

    def validate(self):
        if self.categories:
            for k in self.categories:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Categories'] = []
        if self.categories is not None:
            for k in self.categories:
                result['Categories'].append(k.to_map() if k else None)
        if self.chart_linked is not None:
            result['ChartLinked'] = self.chart_linked
        if self.charts_per_line is not None:
            result['ChartsPerLine'] = self.charts_per_line
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.categories = []
        if m.get('Categories') is not None:
            for k in m.get('Categories'):
                temp_model = DescribePerformanceViewAttributeResponseBodyViewDetailCategories()
                self.categories.append(temp_model.from_map(k))
        if m.get('ChartLinked') is not None:
            self.chart_linked = m.get('ChartLinked')
        if m.get('ChartsPerLine') is not None:
            self.charts_per_line = m.get('ChartsPerLine')
        return self


class DescribePerformanceViewAttributeResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        create_from_view_type: str = None,
        dbcluster_id: str = None,
        fill_origin_view_keys: bool = None,
        request_id: str = None,
        view_detail: DescribePerformanceViewAttributeResponseBodyViewDetail = None,
        view_name: str = None,
    ):
        # The details about the access denial.
        # 
        # >  This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The type of the view.
        self.create_from_view_type = create_from_view_type
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to populate the names of the metrics in the original monitoring view when you view the monitoring view. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.fill_origin_view_keys = fill_origin_view_keys
        # The request ID.
        self.request_id = request_id
        # The information about the monitoring view.
        self.view_detail = view_detail
        # The name of the view.
        self.view_name = view_name

    def validate(self):
        if self.view_detail:
            self.view_detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.create_from_view_type is not None:
            result['CreateFromViewType'] = self.create_from_view_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.fill_origin_view_keys is not None:
            result['FillOriginViewKeys'] = self.fill_origin_view_keys
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.view_detail is not None:
            result['ViewDetail'] = self.view_detail.to_map()
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('CreateFromViewType') is not None:
            self.create_from_view_type = m.get('CreateFromViewType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FillOriginViewKeys') is not None:
            self.fill_origin_view_keys = m.get('FillOriginViewKeys')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ViewDetail') is not None:
            temp_model = DescribePerformanceViewAttributeResponseBodyViewDetail()
            self.view_detail = temp_model.from_map(m['ViewDetail'])
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class DescribePerformanceViewAttributeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribePerformanceViewAttributeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribePerformanceViewAttributeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribePerformanceViewsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribePerformanceViewsResponseBodyViews(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        update_time: str = None,
        view_name: str = None,
    ):
        # The time when created.
        self.create_time = create_time
        # The time when updated.
        self.update_time = update_time
        # The name of the view.
        self.view_name = view_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class DescribePerformanceViewsResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        request_id: str = None,
        views: List[DescribePerformanceViewsResponseBodyViews] = None,
    ):
        # The details about the access denial.
        # 
        # >  This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The request ID.
        self.request_id = request_id
        # the list of view.
        self.views = views

    def validate(self):
        if self.views:
            for k in self.views:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['Views'] = []
        if self.views is not None:
            for k in self.views:
                result['Views'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.views = []
        if m.get('Views') is not None:
            for k in m.get('Views'):
                temp_model = DescribePerformanceViewsResponseBodyViews()
                self.views.append(temp_model.from_map(k))
        return self


class DescribePerformanceViewsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribePerformanceViewsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribePerformanceViewsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeRegionsRequest(TeaModel):
    def __init__(
        self,
        accept_language: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The language that is used for the region and zone names indicated by the LocalName parameter in the response parameters. Valid values:
        # 
        # *   **zh-CN** (default): simplified Chinese.
        # *   **en-US**: English.
        # *   **ja**: Japanese.
        self.accept_language = accept_language
        self.owner_account = owner_account
        self.owner_id = owner_id
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.accept_language is not None:
            result['AcceptLanguage'] = self.accept_language
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AcceptLanguage') is not None:
            self.accept_language = m.get('AcceptLanguage')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeRegionsResponseBodyRegionsRegionZonesZone(TeaModel):
    def __init__(
        self,
        local_name: str = None,
        vpc_enabled: bool = None,
        zone_id: str = None,
    ):
        # The name of the zone.
        self.local_name = local_name
        # Indicates whether Virtual Private Cloud (VPC) is supported in the zone. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.vpc_enabled = vpc_enabled
        # The zone ID.
        self.zone_id = zone_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.local_name is not None:
            result['LocalName'] = self.local_name
        if self.vpc_enabled is not None:
            result['VpcEnabled'] = self.vpc_enabled
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('LocalName') is not None:
            self.local_name = m.get('LocalName')
        if m.get('VpcEnabled') is not None:
            self.vpc_enabled = m.get('VpcEnabled')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class DescribeRegionsResponseBodyRegionsRegionZones(TeaModel):
    def __init__(
        self,
        zone: List[DescribeRegionsResponseBodyRegionsRegionZonesZone] = None,
    ):
        self.zone = zone

    def validate(self):
        if self.zone:
            for k in self.zone:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Zone'] = []
        if self.zone is not None:
            for k in self.zone:
                result['Zone'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.zone = []
        if m.get('Zone') is not None:
            for k in m.get('Zone'):
                temp_model = DescribeRegionsResponseBodyRegionsRegionZonesZone()
                self.zone.append(temp_model.from_map(k))
        return self


class DescribeRegionsResponseBodyRegionsRegion(TeaModel):
    def __init__(
        self,
        local_name: str = None,
        region_endpoint: str = None,
        region_id: str = None,
        zones: DescribeRegionsResponseBodyRegionsRegionZones = None,
    ):
        # The name of the region.
        self.local_name = local_name
        # The endpoint of the region.
        self.region_endpoint = region_endpoint
        # The region ID.
        self.region_id = region_id
        # The queried zones.
        self.zones = zones

    def validate(self):
        if self.zones:
            self.zones.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.local_name is not None:
            result['LocalName'] = self.local_name
        if self.region_endpoint is not None:
            result['RegionEndpoint'] = self.region_endpoint
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.zones is not None:
            result['Zones'] = self.zones.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('LocalName') is not None:
            self.local_name = m.get('LocalName')
        if m.get('RegionEndpoint') is not None:
            self.region_endpoint = m.get('RegionEndpoint')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Zones') is not None:
            temp_model = DescribeRegionsResponseBodyRegionsRegionZones()
            self.zones = temp_model.from_map(m['Zones'])
        return self


class DescribeRegionsResponseBodyRegions(TeaModel):
    def __init__(
        self,
        region: List[DescribeRegionsResponseBodyRegionsRegion] = None,
    ):
        self.region = region

    def validate(self):
        if self.region:
            for k in self.region:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Region'] = []
        if self.region is not None:
            for k in self.region:
                result['Region'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.region = []
        if m.get('Region') is not None:
            for k in m.get('Region'):
                temp_model = DescribeRegionsResponseBodyRegionsRegion()
                self.region.append(temp_model.from_map(k))
        return self


class DescribeRegionsResponseBody(TeaModel):
    def __init__(
        self,
        regions: DescribeRegionsResponseBodyRegions = None,
        request_id: str = None,
    ):
        # The queried regions.
        self.regions = regions
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.regions:
            self.regions.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.regions is not None:
            result['Regions'] = self.regions.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Regions') is not None:
            temp_model = DescribeRegionsResponseBodyRegions()
            self.regions = temp_model.from_map(m['Regions'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeRegionsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeRegionsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeRegionsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeResourceGroupSpecRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        resource_group_type: str = None,
    ):
        # The Enterprise Edition, Basic Edition, or Data Lakehouse Edition cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        self.region_id = region_id
        # The type of the resource group.
        # 
        # This parameter is required.
        self.resource_group_type = resource_group_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group_type is not None:
            result['ResourceGroupType'] = self.resource_group_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroupType') is not None:
            self.resource_group_type = m.get('ResourceGroupType')
        return self


class DescribeResourceGroupSpecResponseBodySpecs(TeaModel):
    def __init__(
        self,
        allocate_units: List[str] = None,
        max_quantity: int = None,
        name: str = None,
        type: str = None,
    ):
        # The allocation units supported by this specification.
        self.allocate_units = allocate_units
        # The maximum number of resource groups that can be used with this specification.
        self.max_quantity = max_quantity
        # The name of the specification.
        self.name = name
        # The resource type.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.allocate_units is not None:
            result['AllocateUnits'] = self.allocate_units
        if self.max_quantity is not None:
            result['MaxQuantity'] = self.max_quantity
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AllocateUnits') is not None:
            self.allocate_units = m.get('AllocateUnits')
        if m.get('MaxQuantity') is not None:
            self.max_quantity = m.get('MaxQuantity')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeResourceGroupSpecResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        specs: List[DescribeResourceGroupSpecResponseBodySpecs] = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The queried specifications.
        self.specs = specs

    def validate(self):
        if self.specs:
            for k in self.specs:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['Specs'] = []
        if self.specs is not None:
            for k in self.specs:
                result['Specs'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.specs = []
        if m.get('Specs') is not None:
            for k in m.get('Specs'):
                temp_model = DescribeResourceGroupSpecResponseBodySpecs()
                self.specs.append(temp_model.from_map(k))
        return self


class DescribeResourceGroupSpecResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeResourceGroupSpecResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeResourceGroupSpecResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSQLPatternsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        keyword: str = None,
        lang: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        start_time: str = None,
        user_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        # 
        # > The end time must be later than the start time.
        self.end_time = end_time
        # The keyword that is used for the query.
        self.keyword = keyword
        # The language. Valid values:
        # 
        # *   **zh** (default): simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order by which to sort query results. Specify the parameter value in the JSON format. Example: `[{"Field":"AverageQueryTime","Type":"Asc"}]`.
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `PatternCreationTime`: the earliest commit time of the SQL pattern within the time range to query.
        #     *   `AverageQueryTime`: the average total amount of time consumed by the SQL pattern within the time range to query.
        #     *   `MaxQueryTime`: the maximum total amount of time consumed by the SQL pattern within the time range to query.
        #     *   `AverageExecutionTime`: the average execution duration of the SQL pattern within the time range to query.
        #     *   `MaxExecutionTime`: the maximum execution duration of the SQL pattern within the time range to query.
        #     *   `AveragePeakMemory`: the average peak memory usage of the SQL pattern within the time range to query.
        #     *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query.
        #     *   `AverageScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query.
        #     *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query.
        #     *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
        #     *   `FailedCount`: the number of failed queries performed in association with the SQL pattern within the time range to query.
        # 
        # *   `Type` specifies the sorting order. Valid values (case-insensitive):
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        self.order = order
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **10** (default)
        # *   **30**\
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        # 
        # > *   Only data within the last 14 days can be queried.
        # > * The maximum time range that can be specified is 24 hours.
        self.start_time = start_time
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeSQLPatternsResponseBodyPatternDetails(TeaModel):
    def __init__(
        self,
        access_ip: str = None,
        average_execution_time: float = None,
        average_operator_cost: float = None,
        average_peak_memory: float = None,
        average_query_time: float = None,
        average_scan_cost: float = None,
        average_scan_size: float = None,
        blockable: bool = None,
        failed_count: int = None,
        max_execution_time: int = None,
        max_operator_cost: float = None,
        max_peak_memory: int = None,
        max_query_time: int = None,
        max_scan_cost: float = None,
        max_scan_size: int = None,
        operator_cost_percentage: float = None,
        operator_cost_sum: float = None,
        pattern_creation_time: str = None,
        pattern_id: str = None,
        peak_memory_percentage: float = None,
        peak_memory_sum: float = None,
        query_count: int = None,
        query_time_percentage: float = None,
        query_time_sum: float = None,
        sqlpattern: str = None,
        scan_cost_percentage: float = None,
        scan_cost_sum: float = None,
        scan_size_percentage: float = None,
        scan_size_sum: float = None,
        tables: str = None,
        user: str = None,
    ):
        # The IP address of the SQL client that commits the SQL pattern.
        self.access_ip = access_ip
        # The average execution duration of the SQL pattern within the query time range. Unit: milliseconds.
        self.average_execution_time = average_execution_time
        self.average_operator_cost = average_operator_cost
        # The average peak memory usage of the SQL pattern within the query time range. Unit: bytes.
        self.average_peak_memory = average_peak_memory
        # The average total amount of time consumed by the SQL pattern within the query time range. Unit: milliseconds.
        self.average_query_time = average_query_time
        self.average_scan_cost = average_scan_cost
        # The average amount of data scanned based on the SQL pattern within the query time range. Unit: bytes.
        self.average_scan_size = average_scan_size
        # Indicates whether the execution of the SQL pattern can be intercepted. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        # 
        # >  Only SELECT and INSERT statements can be intercepted.
        self.blockable = blockable
        # The number of failed queries executed in association with the SQL pattern within the query time range.
        self.failed_count = failed_count
        # The maximum execution duration of the SQL pattern within the query time range. Unit: milliseconds.
        self.max_execution_time = max_execution_time
        self.max_operator_cost = max_operator_cost
        # The maximum peak memory usage of the SQL pattern within the query time range. Unit: bytes.
        self.max_peak_memory = max_peak_memory
        # The maximum total amount of time consumed by the SQL pattern within the query time range. Unit: milliseconds.
        self.max_query_time = max_query_time
        self.max_scan_cost = max_scan_cost
        # The maximum amount of data scanned based on the SQL pattern within the query time range. Unit: bytes.
        self.max_scan_size = max_scan_size
        self.operator_cost_percentage = operator_cost_percentage
        self.operator_cost_sum = operator_cost_sum
        # The earliest commit time of the SQL pattern within the query time range.
        self.pattern_creation_time = pattern_creation_time
        # The ID of the SQL pattern.
        self.pattern_id = pattern_id
        self.peak_memory_percentage = peak_memory_percentage
        self.peak_memory_sum = peak_memory_sum
        # The number of queries executed in association with the SQL pattern within the query time range.
        self.query_count = query_count
        self.query_time_percentage = query_time_percentage
        self.query_time_sum = query_time_sum
        # The statement of the SQL pattern.
        self.sqlpattern = sqlpattern
        self.scan_cost_percentage = scan_cost_percentage
        self.scan_cost_sum = scan_cost_sum
        self.scan_size_percentage = scan_size_percentage
        self.scan_size_sum = scan_size_sum
        # The tables scanned based on the SQL pattern.
        self.tables = tables
        # The name of the database account that is used to commit the SQL pattern.
        self.user = user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_ip is not None:
            result['AccessIp'] = self.access_ip
        if self.average_execution_time is not None:
            result['AverageExecutionTime'] = self.average_execution_time
        if self.average_operator_cost is not None:
            result['AverageOperatorCost'] = self.average_operator_cost
        if self.average_peak_memory is not None:
            result['AveragePeakMemory'] = self.average_peak_memory
        if self.average_query_time is not None:
            result['AverageQueryTime'] = self.average_query_time
        if self.average_scan_cost is not None:
            result['AverageScanCost'] = self.average_scan_cost
        if self.average_scan_size is not None:
            result['AverageScanSize'] = self.average_scan_size
        if self.blockable is not None:
            result['Blockable'] = self.blockable
        if self.failed_count is not None:
            result['FailedCount'] = self.failed_count
        if self.max_execution_time is not None:
            result['MaxExecutionTime'] = self.max_execution_time
        if self.max_operator_cost is not None:
            result['MaxOperatorCost'] = self.max_operator_cost
        if self.max_peak_memory is not None:
            result['MaxPeakMemory'] = self.max_peak_memory
        if self.max_query_time is not None:
            result['MaxQueryTime'] = self.max_query_time
        if self.max_scan_cost is not None:
            result['MaxScanCost'] = self.max_scan_cost
        if self.max_scan_size is not None:
            result['MaxScanSize'] = self.max_scan_size
        if self.operator_cost_percentage is not None:
            result['OperatorCostPercentage'] = self.operator_cost_percentage
        if self.operator_cost_sum is not None:
            result['OperatorCostSum'] = self.operator_cost_sum
        if self.pattern_creation_time is not None:
            result['PatternCreationTime'] = self.pattern_creation_time
        if self.pattern_id is not None:
            result['PatternId'] = self.pattern_id
        if self.peak_memory_percentage is not None:
            result['PeakMemoryPercentage'] = self.peak_memory_percentage
        if self.peak_memory_sum is not None:
            result['PeakMemorySum'] = self.peak_memory_sum
        if self.query_count is not None:
            result['QueryCount'] = self.query_count
        if self.query_time_percentage is not None:
            result['QueryTimePercentage'] = self.query_time_percentage
        if self.query_time_sum is not None:
            result['QueryTimeSum'] = self.query_time_sum
        if self.sqlpattern is not None:
            result['SQLPattern'] = self.sqlpattern
        if self.scan_cost_percentage is not None:
            result['ScanCostPercentage'] = self.scan_cost_percentage
        if self.scan_cost_sum is not None:
            result['ScanCostSum'] = self.scan_cost_sum
        if self.scan_size_percentage is not None:
            result['ScanSizePercentage'] = self.scan_size_percentage
        if self.scan_size_sum is not None:
            result['ScanSizeSum'] = self.scan_size_sum
        if self.tables is not None:
            result['Tables'] = self.tables
        if self.user is not None:
            result['User'] = self.user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessIp') is not None:
            self.access_ip = m.get('AccessIp')
        if m.get('AverageExecutionTime') is not None:
            self.average_execution_time = m.get('AverageExecutionTime')
        if m.get('AverageOperatorCost') is not None:
            self.average_operator_cost = m.get('AverageOperatorCost')
        if m.get('AveragePeakMemory') is not None:
            self.average_peak_memory = m.get('AveragePeakMemory')
        if m.get('AverageQueryTime') is not None:
            self.average_query_time = m.get('AverageQueryTime')
        if m.get('AverageScanCost') is not None:
            self.average_scan_cost = m.get('AverageScanCost')
        if m.get('AverageScanSize') is not None:
            self.average_scan_size = m.get('AverageScanSize')
        if m.get('Blockable') is not None:
            self.blockable = m.get('Blockable')
        if m.get('FailedCount') is not None:
            self.failed_count = m.get('FailedCount')
        if m.get('MaxExecutionTime') is not None:
            self.max_execution_time = m.get('MaxExecutionTime')
        if m.get('MaxOperatorCost') is not None:
            self.max_operator_cost = m.get('MaxOperatorCost')
        if m.get('MaxPeakMemory') is not None:
            self.max_peak_memory = m.get('MaxPeakMemory')
        if m.get('MaxQueryTime') is not None:
            self.max_query_time = m.get('MaxQueryTime')
        if m.get('MaxScanCost') is not None:
            self.max_scan_cost = m.get('MaxScanCost')
        if m.get('MaxScanSize') is not None:
            self.max_scan_size = m.get('MaxScanSize')
        if m.get('OperatorCostPercentage') is not None:
            self.operator_cost_percentage = m.get('OperatorCostPercentage')
        if m.get('OperatorCostSum') is not None:
            self.operator_cost_sum = m.get('OperatorCostSum')
        if m.get('PatternCreationTime') is not None:
            self.pattern_creation_time = m.get('PatternCreationTime')
        if m.get('PatternId') is not None:
            self.pattern_id = m.get('PatternId')
        if m.get('PeakMemoryPercentage') is not None:
            self.peak_memory_percentage = m.get('PeakMemoryPercentage')
        if m.get('PeakMemorySum') is not None:
            self.peak_memory_sum = m.get('PeakMemorySum')
        if m.get('QueryCount') is not None:
            self.query_count = m.get('QueryCount')
        if m.get('QueryTimePercentage') is not None:
            self.query_time_percentage = m.get('QueryTimePercentage')
        if m.get('QueryTimeSum') is not None:
            self.query_time_sum = m.get('QueryTimeSum')
        if m.get('SQLPattern') is not None:
            self.sqlpattern = m.get('SQLPattern')
        if m.get('ScanCostPercentage') is not None:
            self.scan_cost_percentage = m.get('ScanCostPercentage')
        if m.get('ScanCostSum') is not None:
            self.scan_cost_sum = m.get('ScanCostSum')
        if m.get('ScanSizePercentage') is not None:
            self.scan_size_percentage = m.get('ScanSizePercentage')
        if m.get('ScanSizeSum') is not None:
            self.scan_size_sum = m.get('ScanSizeSum')
        if m.get('Tables') is not None:
            self.tables = m.get('Tables')
        if m.get('User') is not None:
            self.user = m.get('User')
        return self


class DescribeSQLPatternsResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        page_number: int = None,
        page_size: int = None,
        pattern_details: List[DescribeSQLPatternsResponseBodyPatternDetails] = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The details about the access denial. This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The queried SQL patterns.
        self.pattern_details = pattern_details
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.pattern_details:
            for k in self.pattern_details:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        result['PatternDetails'] = []
        if self.pattern_details is not None:
            for k in self.pattern_details:
                result['PatternDetails'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        self.pattern_details = []
        if m.get('PatternDetails') is not None:
            for k in m.get('PatternDetails'):
                temp_model = DescribeSQLPatternsResponseBodyPatternDetails()
                self.pattern_details.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeSQLPatternsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSQLPatternsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSQLPatternsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSQLWebSocketDomainRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/98094.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSQLWebSocketDomainResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        domain: str = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The status code. The status code 200 indicates that the request was successful. Other status codes indicate that the request failed.
        self.code = code
        # The domain name.
        self.domain = domain
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.domain is not None:
            result['Domain'] = self.domain
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Domain') is not None:
            self.domain = m.get('Domain')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DescribeSQLWebSocketDomainResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSQLWebSocketDomainResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSQLWebSocketDomainResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSchemasRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSchemasResponseBodyItemsSchema(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        schema_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The name of the database.
        self.schema_name = schema_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        return self


class DescribeSchemasResponseBodyItems(TeaModel):
    def __init__(
        self,
        schema: List[DescribeSchemasResponseBodyItemsSchema] = None,
    ):
        self.schema = schema

    def validate(self):
        if self.schema:
            for k in self.schema:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Schema'] = []
        if self.schema is not None:
            for k in self.schema:
                result['Schema'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.schema = []
        if m.get('Schema') is not None:
            for k in m.get('Schema'):
                temp_model = DescribeSchemasResponseBodyItemsSchema()
                self.schema.append(temp_model.from_map(k))
        return self


class DescribeSchemasResponseBody(TeaModel):
    def __init__(
        self,
        items: DescribeSchemasResponseBodyItems = None,
        request_id: str = None,
    ):
        # The queried databases.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Items') is not None:
            temp_model = DescribeSchemasResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeSchemasResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSchemasResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSchemasResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkAppDiagnosisInfoRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        language: str = None,
        region_id: str = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query all application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/98094.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The language in which you want to display the results. Valid values:
        # 
        # *   en: English.
        # *   zh (default): Chinese.
        # 
        # This parameter is required.
        self.language = language
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.language is not None:
            result['Language'] = self.language
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Language') is not None:
            self.language = m.get('Language')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSparkAppDiagnosisInfoResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        app_id: str = None,
        cpu_utilization: float = None,
        diagnosis_info_list: List[Adb4MysqlSparkDiagnosisInfo] = None,
        duration_in_millis: int = None,
        jvmgc_cost_in_millis: int = None,
        peak_memory_in_byte: int = None,
        request_id: str = None,
        shuffle_read_in_byte: int = None,
        shuffle_write_in_byte: int = None,
        spill_in_byte: int = None,
        started_time: int = None,
        state: str = None,
    ):
        # The information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query all application IDs.
        self.app_id = app_id
        # The CPU utilization. Unit: %.
        self.cpu_utilization = cpu_utilization
        # The queried diagnostic information.
        self.diagnosis_info_list = diagnosis_info_list
        # The execution duration of the application. Unit: milliseconds.
        self.duration_in_millis = duration_in_millis
        # The amount of time consumed by the Java virtual machine to perform garbage collection operations. Unit: milliseconds.
        self.jvmgc_cost_in_millis = jvmgc_cost_in_millis
        # The peak memory usage. Unit: bytes.
        self.peak_memory_in_byte = peak_memory_in_byte
        # The request ID.
        self.request_id = request_id
        # The amount of data used for shuffle reads. Unit: bytes.
        self.shuffle_read_in_byte = shuffle_read_in_byte
        # The amount of data used for shuffle writes. Unit: bytes.
        self.shuffle_write_in_byte = shuffle_write_in_byte
        # The amount of data spilled to disks when the memory is insufficient. Unit: bytes.
        self.spill_in_byte = spill_in_byte
        # The time when the application started to be executed.
        self.started_time = started_time
        # The status of the asynchronous import or export job. Valid values:
        # 
        # *   **RUNNING**\
        # *   **FINISHED**\
        # *   **FAILED**\
        self.state = state

    def validate(self):
        if self.diagnosis_info_list:
            for k in self.diagnosis_info_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.cpu_utilization is not None:
            result['CpuUtilization'] = self.cpu_utilization
        result['DiagnosisInfoList'] = []
        if self.diagnosis_info_list is not None:
            for k in self.diagnosis_info_list:
                result['DiagnosisInfoList'].append(k.to_map() if k else None)
        if self.duration_in_millis is not None:
            result['DurationInMillis'] = self.duration_in_millis
        if self.jvmgc_cost_in_millis is not None:
            result['JVMGcCostInMillis'] = self.jvmgc_cost_in_millis
        if self.peak_memory_in_byte is not None:
            result['PeakMemoryInByte'] = self.peak_memory_in_byte
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.shuffle_read_in_byte is not None:
            result['ShuffleReadInByte'] = self.shuffle_read_in_byte
        if self.shuffle_write_in_byte is not None:
            result['ShuffleWriteInByte'] = self.shuffle_write_in_byte
        if self.spill_in_byte is not None:
            result['SpillInByte'] = self.spill_in_byte
        if self.started_time is not None:
            result['StartedTime'] = self.started_time
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('CpuUtilization') is not None:
            self.cpu_utilization = m.get('CpuUtilization')
        self.diagnosis_info_list = []
        if m.get('DiagnosisInfoList') is not None:
            for k in m.get('DiagnosisInfoList'):
                temp_model = Adb4MysqlSparkDiagnosisInfo()
                self.diagnosis_info_list.append(temp_model.from_map(k))
        if m.get('DurationInMillis') is not None:
            self.duration_in_millis = m.get('DurationInMillis')
        if m.get('JVMGcCostInMillis') is not None:
            self.jvmgc_cost_in_millis = m.get('JVMGcCostInMillis')
        if m.get('PeakMemoryInByte') is not None:
            self.peak_memory_in_byte = m.get('PeakMemoryInByte')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ShuffleReadInByte') is not None:
            self.shuffle_read_in_byte = m.get('ShuffleReadInByte')
        if m.get('ShuffleWriteInByte') is not None:
            self.shuffle_write_in_byte = m.get('ShuffleWriteInByte')
        if m.get('SpillInByte') is not None:
            self.spill_in_byte = m.get('SpillInByte')
        if m.get('StartedTime') is not None:
            self.started_time = m.get('StartedTime')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class DescribeSparkAppDiagnosisInfoResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkAppDiagnosisInfoResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkAppDiagnosisInfoResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkAppTypeRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/612475.html) operation to query the Spark application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/98094.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSparkAppTypeResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        request_id: str = None,
        type: str = None,
    ):
        # The detailed reason why the access was denied.
        self.access_denied_detail = access_denied_detail
        # The request ID.
        self.request_id = request_id
        # The type of the Spark application. Valid values:
        # 
        # *   BATCH
        # *   SQLENGINE
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeSparkAppTypeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkAppTypeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkAppTypeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkCodeLogRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        job_id: int = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the Spark job.
        # 
        # This parameter is required.
        self.job_id = job_id
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.job_id is not None:
            result['JobId'] = self.job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('JobId') is not None:
            self.job_id = m.get('JobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSparkCodeLogResponseBody(TeaModel):
    def __init__(
        self,
        log: str = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The content of the log.
        self.log = log
        # The returned message.
        # 
        # *   If the request was successful, **Success** is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.log is not None:
            result['Log'] = self.log
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Log') is not None:
            self.log = m.get('Log')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DescribeSparkCodeLogResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkCodeLogResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkCodeLogResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkCodeOutputRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        job_id: int = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the Spark job.
        # 
        # This parameter is required.
        self.job_id = job_id
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.job_id is not None:
            result['JobId'] = self.job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('JobId') is not None:
            self.job_id = m.get('JobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSparkCodeOutputResponseBody(TeaModel):
    def __init__(
        self,
        message: str = None,
        output: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The returned message.
        # 
        # *   If the request was successful, **Success** is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The execution result, which is in the format of JSON objects.
        self.output = output
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.output is not None:
            result['Output'] = self.output
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class DescribeSparkCodeOutputResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkCodeOutputResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkCodeOutputResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkCodeWebUiRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        job_id: int = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the Spark job.
        # 
        # This parameter is required.
        self.job_id = job_id
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.job_id is not None:
            result['JobId'] = self.job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('JobId') is not None:
            self.job_id = m.get('JobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSparkCodeWebUiResponseBody(TeaModel):
    def __init__(
        self,
        message: str = None,
        request_id: str = None,
        success: bool = None,
        url: str = None,
    ):
        # The returned message.
        # 
        # *   If the request was successful, **SUCCESS** is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The URL of the web UI for the Spark application.
        self.url = url

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.url is not None:
            result['Url'] = self.url
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('Url') is not None:
            self.url = m.get('Url')
        return self


class DescribeSparkCodeWebUiResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkCodeWebUiResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkCodeWebUiResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkSQLDiagnosisAttributeRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        inner_query_id: int = None,
        language: str = None,
        region_id: str = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/612475.html) operation to query a list of Spark application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The cluster ID.
        # 
        # > 
        # 
        # *   You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/98094.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the query executed within the Spark application.
        # 
        # This parameter is required.
        self.inner_query_id = inner_query_id
        # The language in which to return the query results. Valid values:
        # 
        # *   en: English.
        # *   zh: Chinese.
        # 
        # This parameter is required.
        self.language = language
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.inner_query_id is not None:
            result['InnerQueryId'] = self.inner_query_id
        if self.language is not None:
            result['Language'] = self.language
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('InnerQueryId') is not None:
            self.inner_query_id = m.get('InnerQueryId')
        if m.get('Language') is not None:
            self.language = m.get('Language')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeSparkSQLDiagnosisAttributeResponseBodyOperatorListSortedByMetrics(TeaModel):
    def __init__(
        self,
        operator_list_sorted_by_exclusive_time: List[SparkOperatorInfo] = None,
        operator_list_sorted_by_max_memory: List[SparkOperatorInfo] = None,
    ):
        # The operators sorted by the execution duration.
        self.operator_list_sorted_by_exclusive_time = operator_list_sorted_by_exclusive_time
        # The operators sorted by the maximum memory used.
        self.operator_list_sorted_by_max_memory = operator_list_sorted_by_max_memory

    def validate(self):
        if self.operator_list_sorted_by_exclusive_time:
            for k in self.operator_list_sorted_by_exclusive_time:
                if k:
                    k.validate()
        if self.operator_list_sorted_by_max_memory:
            for k in self.operator_list_sorted_by_max_memory:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['OperatorListSortedByExclusiveTime'] = []
        if self.operator_list_sorted_by_exclusive_time is not None:
            for k in self.operator_list_sorted_by_exclusive_time:
                result['OperatorListSortedByExclusiveTime'].append(k.to_map() if k else None)
        result['OperatorListSortedByMaxMemory'] = []
        if self.operator_list_sorted_by_max_memory is not None:
            for k in self.operator_list_sorted_by_max_memory:
                result['OperatorListSortedByMaxMemory'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.operator_list_sorted_by_exclusive_time = []
        if m.get('OperatorListSortedByExclusiveTime') is not None:
            for k in m.get('OperatorListSortedByExclusiveTime'):
                temp_model = SparkOperatorInfo()
                self.operator_list_sorted_by_exclusive_time.append(temp_model.from_map(k))
        self.operator_list_sorted_by_max_memory = []
        if m.get('OperatorListSortedByMaxMemory') is not None:
            for k in m.get('OperatorListSortedByMaxMemory'):
                temp_model = SparkOperatorInfo()
                self.operator_list_sorted_by_max_memory.append(temp_model.from_map(k))
        return self


class DescribeSparkSQLDiagnosisAttributeResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        app_id: str = None,
        diagnosis_infos: List[Adb4MysqlSparkDiagnosisInfo] = None,
        elapsed_time: int = None,
        inner_query_id: int = None,
        operator_list_sorted_by_metrics: DescribeSparkSQLDiagnosisAttributeResponseBodyOperatorListSortedByMetrics = None,
        request_id: str = None,
        root: OperatorNode = None,
    ):
        # The information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/612475.html) operation to query a list of Spark application IDs.
        self.app_id = app_id
        # The queried diagnostic information.
        self.diagnosis_infos = diagnosis_infos
        # The execution duration of the query. Unit: milliseconds.
        self.elapsed_time = elapsed_time
        # The ID of the query executed within the Spark application.
        self.inner_query_id = inner_query_id
        # The operators sorted by metrics.
        self.operator_list_sorted_by_metrics = operator_list_sorted_by_metrics
        # The request ID.
        self.request_id = request_id
        # The Spark execution plan tree.
        self.root = root

    def validate(self):
        if self.diagnosis_infos:
            for k in self.diagnosis_infos:
                if k:
                    k.validate()
        if self.operator_list_sorted_by_metrics:
            self.operator_list_sorted_by_metrics.validate()
        if self.root:
            self.root.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.app_id is not None:
            result['AppId'] = self.app_id
        result['DiagnosisInfos'] = []
        if self.diagnosis_infos is not None:
            for k in self.diagnosis_infos:
                result['DiagnosisInfos'].append(k.to_map() if k else None)
        if self.elapsed_time is not None:
            result['ElapsedTime'] = self.elapsed_time
        if self.inner_query_id is not None:
            result['InnerQueryId'] = self.inner_query_id
        if self.operator_list_sorted_by_metrics is not None:
            result['OperatorListSortedByMetrics'] = self.operator_list_sorted_by_metrics.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.root is not None:
            result['Root'] = self.root.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        self.diagnosis_infos = []
        if m.get('DiagnosisInfos') is not None:
            for k in m.get('DiagnosisInfos'):
                temp_model = Adb4MysqlSparkDiagnosisInfo()
                self.diagnosis_infos.append(temp_model.from_map(k))
        if m.get('ElapsedTime') is not None:
            self.elapsed_time = m.get('ElapsedTime')
        if m.get('InnerQueryId') is not None:
            self.inner_query_id = m.get('InnerQueryId')
        if m.get('OperatorListSortedByMetrics') is not None:
            temp_model = DescribeSparkSQLDiagnosisAttributeResponseBodyOperatorListSortedByMetrics()
            self.operator_list_sorted_by_metrics = temp_model.from_map(m['OperatorListSortedByMetrics'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Root') is not None:
            temp_model = OperatorNode()
            self.root = temp_model.from_map(m['Root'])
        return self


class DescribeSparkSQLDiagnosisAttributeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkSQLDiagnosisAttributeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkSQLDiagnosisAttributeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSparkSQLDiagnosisListRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        max_start_time: str = None,
        min_start_time: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        statement_id: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The latest start time.
        self.max_start_time = max_start_time
        # The earliest start time.
        self.min_start_time = min_start_time
        # The order by which to sort query results. Specify the parameter value in the JSON format. Example: `[{"Field":"MaxExclusiveTime","Type":"Asc"}]`.
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `MaxExclusiveTime`: the maximum execution duration.
        #     *   `PeakMemory`: the peak memory.
        #     *   `QueryStartTime`: the start time of the query.
        #     *   `QueryWallclockTime`: the execution duration of the query.
        # 
        # *   `Type` specifies the sorting order. Valid values:
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        # 
        # > 
        # 
        # *   If you do not specify this parameter, query results are sorted by `MaxExclusiveTime` in ascending order.
        self.order = order
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.max_start_time is not None:
            result['MaxStartTime'] = self.max_start_time
        if self.min_start_time is not None:
            result['MinStartTime'] = self.min_start_time
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('MaxStartTime') is not None:
            self.max_start_time = m.get('MaxStartTime')
        if m.get('MinStartTime') is not None:
            self.min_start_time = m.get('MinStartTime')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class DescribeSparkSQLDiagnosisListResponseBodySQLDiagnosisList(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        elapsed_time: int = None,
        inner_query_id: int = None,
        max_exclusive_time: int = None,
        peak_memory: int = None,
        sql: str = None,
        scan_row_count: int = None,
        start_time: str = None,
        state: str = None,
        statement_id: int = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/612475.html) operation to query a list of Spark application IDs.
        self.app_id = app_id
        # The execution duration of the query. Unit: milliseconds.
        self.elapsed_time = elapsed_time
        # The ID of the query executed within the Spark application.
        self.inner_query_id = inner_query_id
        # The maximum operator execution duration. Unit: milliseconds.
        self.max_exclusive_time = max_exclusive_time
        # The maximum operator memory used. Unit: bytes.
        self.peak_memory = peak_memory
        # The SQL statement.
        self.sql = sql
        # The number of entries scanned.
        self.scan_row_count = scan_row_count
        # The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.
        self.start_time = start_time
        # The execution status of the query. Valid values:
        # 
        # *   COMPLETED
        # *   CANCELED
        # *   ABORTED
        # *   FAILED
        self.state = state
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.elapsed_time is not None:
            result['ElapsedTime'] = self.elapsed_time
        if self.inner_query_id is not None:
            result['InnerQueryId'] = self.inner_query_id
        if self.max_exclusive_time is not None:
            result['MaxExclusiveTime'] = self.max_exclusive_time
        if self.peak_memory is not None:
            result['PeakMemory'] = self.peak_memory
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.scan_row_count is not None:
            result['ScanRowCount'] = self.scan_row_count
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.state is not None:
            result['State'] = self.state
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('ElapsedTime') is not None:
            self.elapsed_time = m.get('ElapsedTime')
        if m.get('InnerQueryId') is not None:
            self.inner_query_id = m.get('InnerQueryId')
        if m.get('MaxExclusiveTime') is not None:
            self.max_exclusive_time = m.get('MaxExclusiveTime')
        if m.get('PeakMemory') is not None:
            self.peak_memory = m.get('PeakMemory')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('ScanRowCount') is not None:
            self.scan_row_count = m.get('ScanRowCount')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class DescribeSparkSQLDiagnosisListResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        sqldiagnosis_list: List[DescribeSparkSQLDiagnosisListResponseBodySQLDiagnosisList] = None,
        total_count: int = None,
    ):
        # The information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The queried diagnostic information.
        self.sqldiagnosis_list = sqldiagnosis_list
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.sqldiagnosis_list:
            for k in self.sqldiagnosis_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['SQLDiagnosisList'] = []
        if self.sqldiagnosis_list is not None:
            for k in self.sqldiagnosis_list:
                result['SQLDiagnosisList'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.sqldiagnosis_list = []
        if m.get('SQLDiagnosisList') is not None:
            for k in m.get('SQLDiagnosisList'):
                temp_model = DescribeSparkSQLDiagnosisListResponseBodySQLDiagnosisList()
                self.sqldiagnosis_list.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeSparkSQLDiagnosisListResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSparkSQLDiagnosisListResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSparkSQLDiagnosisListResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeSqlPatternRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        sql_pattern: str = None,
        start_time: str = None,
        type: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # > You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"Pattern","Type":"Asc"}]`. Parameters:
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `Pattern`: the SQL pattern.
        #     *   `AccessIP`: the IP address of the client.
        #     *   `User`: the username.
        #     *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
        #     *   `AvgPeakMemory`: the average peak memory usage of the SQL pattern within the time range to query. Unit: KB.
        #     *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query. Unit: KB.
        #     *   `AvgCpuTime`: the average execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
        #     *   `MaxCpuTime`: the maximum execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
        #     *   `AvgStageCount`: the average number of stages.
        #     *   `MaxStageCount`: the maximum number of stages.
        #     *   `AvgTaskCount`: the average number of tasks.
        #     *   `MaxTaskCount`: the maximum number of tasks.
        #     *   `AvgScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.
        #     *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.
        # 
        # *   `Type` specifies the sorting order. Valid values:
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        # 
        # > 
        # 
        # *   If you do not specify this parameter, query results are sorted in ascending order of `Pattern`.
        # 
        # *   If you want to sort query results by `AccessIP`, you must set the `Type` parameter to `accessip`. If you want to sort query results by `User`, you must leave the `Type` parameter empty or set it to `user`.
        self.order = order
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **10** (default)
        # *   **30**\
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The keyword that is used for the query.
        # 
        # > If you do not specify this parameter, all SQL patterns of the AnalyticDB for MySQL cluster within the time period specified by `StartTime` are returned.
        self.sql_pattern = sql_pattern
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-dd format. The time must be in UTC.
        # 
        # > Only data within the last 30 days can be queried.
        self.start_time = start_time
        # The dimension by which to aggregate the SQL patterns. Valid values:
        # 
        # *   `user`: aggregates the SQL patterns by user.
        # *   `accessip`: aggregates the SQL patterns by client IP address.
        # 
        # > If you do not specify this parameter, the SQL patterns are aggregated by `user`.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.sql_pattern is not None:
            result['SqlPattern'] = self.sql_pattern
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SqlPattern') is not None:
            self.sql_pattern = m.get('SqlPattern')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeSqlPatternResponseBodyItems(TeaModel):
    def __init__(
        self,
        access_ip: str = None,
        avg_cpu_time: str = None,
        avg_peak_memory: str = None,
        avg_scan_size: str = None,
        avg_stage_count: str = None,
        avg_task_count: str = None,
        instance_name: str = None,
        max_cpu_time: str = None,
        max_peak_memory: str = None,
        max_scan_size: str = None,
        max_stage_count: str = None,
        max_task_count: str = None,
        pattern: str = None,
        query_count: str = None,
        report_date: str = None,
        user: str = None,
    ):
        # The IP address of the client.
        # 
        # >  This parameter is returned only when **Type** is set to **accessip**.
        self.access_ip = access_ip
        # The average execution duration of the SQL pattern within the query time range. Unit: milliseconds.
        self.avg_cpu_time = avg_cpu_time
        # The average peak memory usage of the SQL pattern within the query time range. Unit: KB.
        self.avg_peak_memory = avg_peak_memory
        # The average amount of data scanned based on the SQL pattern within the query time range. Unit: KB.
        self.avg_scan_size = avg_scan_size
        # The average number of scanned rows.
        self.avg_stage_count = avg_stage_count
        # The average number of tasks.
        self.avg_task_count = avg_task_count
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        self.instance_name = instance_name
        # The maximum execution duration of the SQL pattern within the query time range. Unit: milliseconds.
        self.max_cpu_time = max_cpu_time
        # The maximum peak memory usage of the SQL pattern within the query time range. Unit: KB.
        self.max_peak_memory = max_peak_memory
        # The maximum amount of data scanned based on the SQL pattern within the query time range. Unit: KB.
        self.max_scan_size = max_scan_size
        # The maximum number of stages.
        self.max_stage_count = max_stage_count
        # The maximum number of tasks.
        self.max_task_count = max_task_count
        # The SQL pattern.
        self.pattern = pattern
        # The number of queries performed in association with the SQL pattern within the query time range.
        self.query_count = query_count
        # The start date of the query.
        self.report_date = report_date
        # The username.
        # 
        # >  This parameter is returned only when **Type** is left empty or set to **user**.
        self.user = user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_ip is not None:
            result['AccessIP'] = self.access_ip
        if self.avg_cpu_time is not None:
            result['AvgCpuTime'] = self.avg_cpu_time
        if self.avg_peak_memory is not None:
            result['AvgPeakMemory'] = self.avg_peak_memory
        if self.avg_scan_size is not None:
            result['AvgScanSize'] = self.avg_scan_size
        if self.avg_stage_count is not None:
            result['AvgStageCount'] = self.avg_stage_count
        if self.avg_task_count is not None:
            result['AvgTaskCount'] = self.avg_task_count
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        if self.max_cpu_time is not None:
            result['MaxCpuTime'] = self.max_cpu_time
        if self.max_peak_memory is not None:
            result['MaxPeakMemory'] = self.max_peak_memory
        if self.max_scan_size is not None:
            result['MaxScanSize'] = self.max_scan_size
        if self.max_stage_count is not None:
            result['MaxStageCount'] = self.max_stage_count
        if self.max_task_count is not None:
            result['MaxTaskCount'] = self.max_task_count
        if self.pattern is not None:
            result['Pattern'] = self.pattern
        if self.query_count is not None:
            result['QueryCount'] = self.query_count
        if self.report_date is not None:
            result['ReportDate'] = self.report_date
        if self.user is not None:
            result['User'] = self.user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessIP') is not None:
            self.access_ip = m.get('AccessIP')
        if m.get('AvgCpuTime') is not None:
            self.avg_cpu_time = m.get('AvgCpuTime')
        if m.get('AvgPeakMemory') is not None:
            self.avg_peak_memory = m.get('AvgPeakMemory')
        if m.get('AvgScanSize') is not None:
            self.avg_scan_size = m.get('AvgScanSize')
        if m.get('AvgStageCount') is not None:
            self.avg_stage_count = m.get('AvgStageCount')
        if m.get('AvgTaskCount') is not None:
            self.avg_task_count = m.get('AvgTaskCount')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        if m.get('MaxCpuTime') is not None:
            self.max_cpu_time = m.get('MaxCpuTime')
        if m.get('MaxPeakMemory') is not None:
            self.max_peak_memory = m.get('MaxPeakMemory')
        if m.get('MaxScanSize') is not None:
            self.max_scan_size = m.get('MaxScanSize')
        if m.get('MaxStageCount') is not None:
            self.max_stage_count = m.get('MaxStageCount')
        if m.get('MaxTaskCount') is not None:
            self.max_task_count = m.get('MaxTaskCount')
        if m.get('Pattern') is not None:
            self.pattern = m.get('Pattern')
        if m.get('QueryCount') is not None:
            self.query_count = m.get('QueryCount')
        if m.get('ReportDate') is not None:
            self.report_date = m.get('ReportDate')
        if m.get('User') is not None:
            self.user = m.get('User')
        return self


class DescribeSqlPatternResponseBody(TeaModel):
    def __init__(
        self,
        items: List[DescribeSqlPatternResponseBodyItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The queried SQL pattern.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeSqlPatternResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeSqlPatternResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeSqlPatternResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeSqlPatternResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeStorageResourceUsageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.end_time = end_time
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeStorageResourceUsageResponseBodyDataAcuInfo(TeaModel):
    def __init__(
        self,
        name: str = None,
        values: List[str] = None,
    ):
        # The resource usage metric. Valid values:
        # 
        # *   `TotalAcuNumber`: the total number of ACUs.
        # *   `ReservedAcuNumber`: the number of ACUs for the reserved resources.
        self.name = name
        # The values of the metric at specific points in time.
        self.values = values

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.values is not None:
            result['Values'] = self.values
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Values') is not None:
            self.values = m.get('Values')
        return self


class DescribeStorageResourceUsageResponseBodyData(TeaModel):
    def __init__(
        self,
        acu_info: List[DescribeStorageResourceUsageResponseBodyDataAcuInfo] = None,
        dbcluster_id: str = None,
        end_time: str = None,
        start_time: str = None,
    ):
        # The AnalyticDB compute unit (ACU) usage of the cluster.
        self.acu_info = acu_info
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The end time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.end_time = end_time
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        if self.acu_info:
            for k in self.acu_info:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcuInfo'] = []
        if self.acu_info is not None:
            for k in self.acu_info:
                result['AcuInfo'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.acu_info = []
        if m.get('AcuInfo') is not None:
            for k in m.get('AcuInfo'):
                temp_model = DescribeStorageResourceUsageResponseBodyDataAcuInfo()
                self.acu_info.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeStorageResourceUsageResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: DescribeStorageResourceUsageResponseBodyData = None,
        request_id: str = None,
    ):
        # The HTTP status code.
        self.code = code
        # The queried resource usage.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = DescribeStorageResourceUsageResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeStorageResourceUsageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeStorageResourceUsageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeStorageResourceUsageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeTableAccessCountRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        start_time: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"TableSchema","Type":"Asc"}]`. Fields in the request parameter:
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `TableSchema`: the name of the database to which the table belongs.
        #     *   `TableName`: the name of the table.
        #     *   `AccessCount`: the number of accesses to the table.
        # 
        # *   `Type` specifies the sorting order. Valid values:
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        # 
        # >  If you do not specify this parameter, query results are sorted in ascending order based on the database and the table.
        self.order = order
        # The page number. Pages start from 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **10** (default)
        # *   **30**\
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # >  Only data within the last 30 days can be queried.
        self.start_time = start_time
        # The name of the table.
        # 
        # >  If you leave this parameter empty, the number of accesses to all tables in the cluster on a date is returned.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeTableAccessCountResponseBodyItems(TeaModel):
    def __init__(
        self,
        access_count: str = None,
        instance_name: str = None,
        report_date: str = None,
        table_name: str = None,
        table_schema: str = None,
    ):
        # The number of accesses to the table.
        self.access_count = access_count
        # The ID of the cluster to which the table belongs.
        self.instance_name = instance_name
        # The date when the table was accessed.
        self.report_date = report_date
        # The name of the table.
        self.table_name = table_name
        # The database to which the table belongs.
        self.table_schema = table_schema

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_count is not None:
            result['AccessCount'] = self.access_count
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        if self.report_date is not None:
            result['ReportDate'] = self.report_date
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.table_schema is not None:
            result['TableSchema'] = self.table_schema
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessCount') is not None:
            self.access_count = m.get('AccessCount')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        if m.get('ReportDate') is not None:
            self.report_date = m.get('ReportDate')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TableSchema') is not None:
            self.table_schema = m.get('TableSchema')
        return self


class DescribeTableAccessCountResponseBody(TeaModel):
    def __init__(
        self,
        items: List[DescribeTableAccessCountResponseBodyItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The queried tables.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeTableAccessCountResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeTableAccessCountResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeTableAccessCountResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeTableAccessCountResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeTableDetailRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeTableDetailResponseBodyItemsShard(TeaModel):
    def __init__(
        self,
        id: int = None,
        size: int = None,
    ):
        # The shard ID. Only the numeric part of the shard name is returned.
        self.id = id
        # The number of rows in the table.
        self.size = size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.id is not None:
            result['Id'] = self.id
        if self.size is not None:
            result['Size'] = self.size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        return self


class DescribeTableDetailResponseBodyItems(TeaModel):
    def __init__(
        self,
        shard: List[DescribeTableDetailResponseBodyItemsShard] = None,
    ):
        # The queried shards.
        self.shard = shard

    def validate(self):
        if self.shard:
            for k in self.shard:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Shard'] = []
        if self.shard is not None:
            for k in self.shard:
                result['Shard'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.shard = []
        if m.get('Shard') is not None:
            for k in m.get('Shard'):
                temp_model = DescribeTableDetailResponseBodyItemsShard()
                self.shard.append(temp_model.from_map(k))
        return self


class DescribeTableDetailResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        avg_size: str = None,
        items: DescribeTableDetailResponseBodyItems = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The detailed reason why the access was denied.
        self.access_denied_detail = access_denied_detail
        # The average number of rows in a shard.
        self.avg_size = avg_size
        # The queried data distribution.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.avg_size is not None:
            result['AvgSize'] = self.avg_size
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('AvgSize') is not None:
            self.avg_size = m.get('AvgSize')
        if m.get('Items') is not None:
            temp_model = DescribeTableDetailResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeTableDetailResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeTableDetailResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeTableDetailResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeTablePartitionDiagnoseRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lang: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The language of the content within the request and response. Default value: **zh**. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"TotalSize","Type":"Desc"}]`.
        # 
        # *   `Field` specifies the field by which to sort the query results. Valid values:
        # 
        #     *   `SchemaName`: the name of the database to which the table belongs.
        #     *   `TableName`: the name of the table.
        #     *   `TotalSize`: the total data size of the table.
        #     *   `SpaceRatio`: the storage percentage of the table.
        # 
        # *   `Type` specifies the sorting order. Valid values:
        # 
        #     *   `Asc`: ascending order.
        #     *   `Desc`: descending order.
        # 
        # >  If you do not specify this parameter, the query results are sorted by the TotalSize field in descending order.
        self.order = order
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeTablePartitionDiagnoseResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        status: str = None,
    ):
        # The detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The severity level of the detection result. Valid values:
        # 
        # *   NORMAL
        # *   WARNING
        # *   CRITICAL
        self.status = status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeTablePartitionDiagnoseResponseBodyItems(TeaModel):
    def __init__(
        self,
        partition_detail: str = None,
        partition_number: int = None,
        schema_name: str = None,
        space_ratio: float = None,
        table_name: str = None,
        total_size: int = None,
    ):
        # The improper partitions.
        self.partition_detail = partition_detail
        # The number of partitions.
        self.partition_number = partition_number
        # The name of the database.
        self.schema_name = schema_name
        # The storage percentage of the table. Unit: %.
        # 
        # >  Formula: Table storage percentage = Total data size of a table/Total data size of the cluster  100%.
        self.space_ratio = space_ratio
        # The name of the table.
        self.table_name = table_name
        # The total data size of the table. Unit: bytes.
        self.total_size = total_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.partition_detail is not None:
            result['PartitionDetail'] = self.partition_detail
        if self.partition_number is not None:
            result['PartitionNumber'] = self.partition_number
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.space_ratio is not None:
            result['SpaceRatio'] = self.space_ratio
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PartitionDetail') is not None:
            self.partition_detail = m.get('PartitionDetail')
        if m.get('PartitionNumber') is not None:
            self.partition_number = m.get('PartitionNumber')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('SpaceRatio') is not None:
            self.space_ratio = m.get('SpaceRatio')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        return self


class DescribeTablePartitionDiagnoseResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        dbcluster_id: str = None,
        detection_items: List[DescribeTablePartitionDiagnoseResponseBodyDetectionItems] = None,
        items: List[DescribeTablePartitionDiagnoseResponseBodyItems] = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        suggest_max_records_per_partition: int = None,
        suggest_min_records_per_partition: int = None,
        total_count: int = None,
    ):
        # The information about the request denial.
        self.access_denied_detail = access_denied_detail
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The queried partition diagnostic information.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The recommended maximum number of rows in each partition.
        self.suggest_max_records_per_partition = suggest_max_records_per_partition
        # The recommended minimum number of rows in each partition.
        self.suggest_min_records_per_partition = suggest_min_records_per_partition
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.suggest_max_records_per_partition is not None:
            result['SuggestMaxRecordsPerPartition'] = self.suggest_max_records_per_partition
        if self.suggest_min_records_per_partition is not None:
            result['SuggestMinRecordsPerPartition'] = self.suggest_min_records_per_partition
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeTablePartitionDiagnoseResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = DescribeTablePartitionDiagnoseResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SuggestMaxRecordsPerPartition') is not None:
            self.suggest_max_records_per_partition = m.get('SuggestMaxRecordsPerPartition')
        if m.get('SuggestMinRecordsPerPartition') is not None:
            self.suggest_min_records_per_partition = m.get('SuggestMinRecordsPerPartition')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeTablePartitionDiagnoseResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeTablePartitionDiagnoseResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeTablePartitionDiagnoseResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeTableStatisticsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        keyword: str = None,
        order: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        schema_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The keyword that is used to query information by table name.
        self.keyword = keyword
        # The order by which to sort query results. Specify the parameter value in the JSON format.
        # 
        # Example:
        # 
        #     [
        # 
        #         {
        # 
        #             "Field":"Name",
        # 
        #             "Type":"Asc"
        # 
        #         }
        # 
        #     ]
        # 
        # Field specifies the field by which to sort the query results. Set the value to Name. Type specifies the sorting order. Valid values: Desc and Asc.
        # 
        # Field and Type are case-insensitive.
        self.order = order
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The region ID
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612393.html) operation to query the most recent region list.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.order is not None:
            result['Order'] = self.order
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('Order') is not None:
            self.order = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        return self


class DescribeTableStatisticsResponseBodyItemsTableStatisticRecords(TeaModel):
    def __init__(
        self,
        cold_data_size: int = None,
        data_size: int = None,
        hot_data_size: int = None,
        index_size: int = None,
        other_size: int = None,
        partition_count: int = None,
        primary_key_index_size: int = None,
        row_count: int = None,
        schema_name: str = None,
        space_ratio: float = None,
        table_name: str = None,
        total_size: int = None,
    ):
        # The size of cold data. Unit: bytes.
        # 
        # >  This parameter is supported only for AnalyticDB for MySQL clusters of V3.1.3.4 or later.
        self.cold_data_size = cold_data_size
        # The data size of the table. Unit: bytes.
        self.data_size = data_size
        # The size of hot data. Unit: bytes.
        self.hot_data_size = hot_data_size
        # The data size of indexes. Unit: bytes.
        self.index_size = index_size
        # The data size of other data. Unit: bytes.
        self.other_size = other_size
        # The number of partitions.
        self.partition_count = partition_count
        # The data size of the primary key index. Unit: bytes.
        self.primary_key_index_size = primary_key_index_size
        # The number of rows in the table.
        self.row_count = row_count
        # The name of the database.
        self.schema_name = schema_name
        # The percentage of the table size. Unit: %.
        # 
        # >  Formula: Table storage percentage = Total data size of a table/Total data size of the cluster  100%.
        self.space_ratio = space_ratio
        # The name of the table.
        self.table_name = table_name
        # The total data size of the table. Unit: bytes.
        # 
        # >  The following formulas can be used to calculate the total data size:
        # 
        # *   Formula 1: Total data size = Hot data size + Cold data size.
        # *   Formula 2: Total data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.
        self.total_size = total_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cold_data_size is not None:
            result['ColdDataSize'] = self.cold_data_size
        if self.data_size is not None:
            result['DataSize'] = self.data_size
        if self.hot_data_size is not None:
            result['HotDataSize'] = self.hot_data_size
        if self.index_size is not None:
            result['IndexSize'] = self.index_size
        if self.other_size is not None:
            result['OtherSize'] = self.other_size
        if self.partition_count is not None:
            result['PartitionCount'] = self.partition_count
        if self.primary_key_index_size is not None:
            result['PrimaryKeyIndexSize'] = self.primary_key_index_size
        if self.row_count is not None:
            result['RowCount'] = self.row_count
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.space_ratio is not None:
            result['SpaceRatio'] = self.space_ratio
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_size is not None:
            result['TotalSize'] = self.total_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColdDataSize') is not None:
            self.cold_data_size = m.get('ColdDataSize')
        if m.get('DataSize') is not None:
            self.data_size = m.get('DataSize')
        if m.get('HotDataSize') is not None:
            self.hot_data_size = m.get('HotDataSize')
        if m.get('IndexSize') is not None:
            self.index_size = m.get('IndexSize')
        if m.get('OtherSize') is not None:
            self.other_size = m.get('OtherSize')
        if m.get('PartitionCount') is not None:
            self.partition_count = m.get('PartitionCount')
        if m.get('PrimaryKeyIndexSize') is not None:
            self.primary_key_index_size = m.get('PrimaryKeyIndexSize')
        if m.get('RowCount') is not None:
            self.row_count = m.get('RowCount')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('SpaceRatio') is not None:
            self.space_ratio = m.get('SpaceRatio')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalSize') is not None:
            self.total_size = m.get('TotalSize')
        return self


class DescribeTableStatisticsResponseBodyItems(TeaModel):
    def __init__(
        self,
        table_statistic_records: List[DescribeTableStatisticsResponseBodyItemsTableStatisticRecords] = None,
    ):
        self.table_statistic_records = table_statistic_records

    def validate(self):
        if self.table_statistic_records:
            for k in self.table_statistic_records:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['TableStatisticRecords'] = []
        if self.table_statistic_records is not None:
            for k in self.table_statistic_records:
                result['TableStatisticRecords'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.table_statistic_records = []
        if m.get('TableStatisticRecords') is not None:
            for k in m.get('TableStatisticRecords'):
                temp_model = DescribeTableStatisticsResponseBodyItemsTableStatisticRecords()
                self.table_statistic_records.append(temp_model.from_map(k))
        return self


class DescribeTableStatisticsResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        items: DescribeTableStatisticsResponseBodyItems = None,
        page_number: str = None,
        page_size: str = None,
        request_id: str = None,
        schema_names: str = None,
        total_count: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried table statistics.
        self.items = items
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The names of databases.
        self.schema_names = schema_names
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.schema_names is not None:
            result['SchemaNames'] = self.schema_names
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Items') is not None:
            temp_model = DescribeTableStatisticsResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SchemaNames') is not None:
            self.schema_names = m.get('SchemaNames')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeTableStatisticsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeTableStatisticsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeTableStatisticsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeTablesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        return self


class DescribeTablesResponseBodyItemsTable(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeTablesResponseBodyItems(TeaModel):
    def __init__(
        self,
        table: List[DescribeTablesResponseBodyItemsTable] = None,
    ):
        self.table = table

    def validate(self):
        if self.table:
            for k in self.table:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Table'] = []
        if self.table is not None:
            for k in self.table:
                result['Table'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.table = []
        if m.get('Table') is not None:
            for k in m.get('Table'):
                temp_model = DescribeTablesResponseBodyItemsTable()
                self.table.append(temp_model.from_map(k))
        return self


class DescribeTablesResponseBody(TeaModel):
    def __init__(
        self,
        items: DescribeTablesResponseBodyItems = None,
        request_id: str = None,
    ):
        # The queried tables.
        self.items = items
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.items:
            self.items.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.items is not None:
            result['Items'] = self.items.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Items') is not None:
            temp_model = DescribeTablesResponseBodyItems()
            self.items = temp_model.from_map(m['Items'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeTablesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeTablesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeTablesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeUserQuotaRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeUserQuotaResponseBody(TeaModel):
    def __init__(
        self,
        elastic_acu: str = None,
        request_id: str = None,
        reserverd_compte_acu: str = None,
        reserverd_storage_acu: str = None,
        resource_group_count: str = None,
    ):
        # The available elastic AnalyticDB compute units (ACUs).
        self.elastic_acu = elastic_acu
        # The request ID.
        self.request_id = request_id
        # The available reserved computing resources.
        self.reserverd_compte_acu = reserverd_compte_acu
        # The available reserved storage resources.
        self.reserverd_storage_acu = reserverd_storage_acu
        # The number of available resource groups.
        self.resource_group_count = resource_group_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.elastic_acu is not None:
            result['ElasticACU'] = self.elastic_acu
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.reserverd_compte_acu is not None:
            result['ReserverdCompteACU'] = self.reserverd_compte_acu
        if self.reserverd_storage_acu is not None:
            result['ReserverdStorageACU'] = self.reserverd_storage_acu
        if self.resource_group_count is not None:
            result['ResourceGroupCount'] = self.resource_group_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ElasticACU') is not None:
            self.elastic_acu = m.get('ElasticACU')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ReserverdCompteACU') is not None:
            self.reserverd_compte_acu = m.get('ReserverdCompteACU')
        if m.get('ReserverdStorageACU') is not None:
            self.reserverd_storage_acu = m.get('ReserverdStorageACU')
        if m.get('ResourceGroupCount') is not None:
            self.resource_group_count = m.get('ResourceGroupCount')
        return self


class DescribeUserQuotaResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeUserQuotaResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeUserQuotaResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeWorkerDetectionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        lang: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.end_time = end_time
        # The language. Valid values:
        # 
        # *   **zh** (default): simplified Chinese.
        # *   **en**: English
        self.lang = lang
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/612293.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorAggSearchResults(TeaModel):
    def __init__(
        self,
        avg_value: float = None,
        max_value: int = None,
        operator_count: int = None,
        operator_name: str = None,
        total_value: int = None,
    ):
        # The average value of the operator metric.
        self.avg_value = avg_value
        # The maximum value of the operator metric.
        self.max_value = max_value
        # The number of occurrences of the operator.
        self.operator_count = operator_count
        # The name of the operator.
        self.operator_name = operator_name
        # The cumulative value of the operator metric.
        self.total_value = total_value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.avg_value is not None:
            result['AvgValue'] = self.avg_value
        if self.max_value is not None:
            result['MaxValue'] = self.max_value
        if self.operator_count is not None:
            result['OperatorCount'] = self.operator_count
        if self.operator_name is not None:
            result['OperatorName'] = self.operator_name
        if self.total_value is not None:
            result['TotalValue'] = self.total_value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AvgValue') is not None:
            self.avg_value = m.get('AvgValue')
        if m.get('MaxValue') is not None:
            self.max_value = m.get('MaxValue')
        if m.get('OperatorCount') is not None:
            self.operator_count = m.get('OperatorCount')
        if m.get('OperatorName') is not None:
            self.operator_name = m.get('OperatorName')
        if m.get('TotalValue') is not None:
            self.total_value = m.get('TotalValue')
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorAgg(TeaModel):
    def __init__(
        self,
        metric_name: str = None,
        search_results: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorAggSearchResults] = None,
    ):
        # The detection result items of operator metric aggregation.
        self.metric_name = metric_name
        # The detection result items of operator metric aggregation.
        self.search_results = search_results

    def validate(self):
        if self.search_results:
            for k in self.search_results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        result['SearchResults'] = []
        if self.search_results is not None:
            for k in self.search_results:
                result['SearchResults'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        self.search_results = []
        if m.get('SearchResults') is not None:
            for k in m.get('SearchResults'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorAggSearchResults()
                self.search_results.append(temp_model.from_map(k))
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorDetailsSearchResults(TeaModel):
    def __init__(
        self,
        input_rows: int = None,
        input_size: int = None,
        operator_cost: int = None,
        operator_info: str = None,
        operator_name: str = None,
        output_rows: int = None,
        output_size: int = None,
        peak_memory: int = None,
        process_id: str = None,
        stage_id: str = None,
    ):
        # The number of rows input by the operator.
        self.input_rows = input_rows
        # The amount of data input by the operator. Unit: bytes.
        self.input_size = input_size
        # The total CPU time consumed by all operators in the stage, which is equivalent to the total CPU time of the stage. You can use this parameter to determine which parts of the stage consume a large amount of computing resources. Unit: milliseconds.
        self.operator_cost = operator_cost
        # The property information about the operator.
        self.operator_info = operator_info
        # The name of the operator.
        self.operator_name = operator_name
        # The number of rows output by the operator.
        self.output_rows = output_rows
        # The amount of data output by the operator. Unit: bytes.
        self.output_size = output_size
        # The peak memory. Unit: bytes.
        self.peak_memory = peak_memory
        # The query ID that can be used for diagnostics.
        self.process_id = process_id
        # The stage ID.
        self.stage_id = stage_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.input_rows is not None:
            result['InputRows'] = self.input_rows
        if self.input_size is not None:
            result['InputSize'] = self.input_size
        if self.operator_cost is not None:
            result['OperatorCost'] = self.operator_cost
        if self.operator_info is not None:
            result['OperatorInfo'] = self.operator_info
        if self.operator_name is not None:
            result['OperatorName'] = self.operator_name
        if self.output_rows is not None:
            result['OutputRows'] = self.output_rows
        if self.output_size is not None:
            result['OutputSize'] = self.output_size
        if self.peak_memory is not None:
            result['PeakMemory'] = self.peak_memory
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        if self.stage_id is not None:
            result['StageId'] = self.stage_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('InputRows') is not None:
            self.input_rows = m.get('InputRows')
        if m.get('InputSize') is not None:
            self.input_size = m.get('InputSize')
        if m.get('OperatorCost') is not None:
            self.operator_cost = m.get('OperatorCost')
        if m.get('OperatorInfo') is not None:
            self.operator_info = m.get('OperatorInfo')
        if m.get('OperatorName') is not None:
            self.operator_name = m.get('OperatorName')
        if m.get('OutputRows') is not None:
            self.output_rows = m.get('OutputRows')
        if m.get('OutputSize') is not None:
            self.output_size = m.get('OutputSize')
        if m.get('PeakMemory') is not None:
            self.peak_memory = m.get('PeakMemory')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        if m.get('StageId') is not None:
            self.stage_id = m.get('StageId')
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorDetails(TeaModel):
    def __init__(
        self,
        metric_name: str = None,
        search_results: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorDetailsSearchResults] = None,
    ):
        # The name of the detection metric.
        self.metric_name = metric_name
        # The detection result items of abnormal operators.
        self.search_results = search_results

    def validate(self):
        if self.search_results:
            for k in self.search_results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        result['SearchResults'] = []
        if self.search_results is not None:
            for k in self.search_results:
                result['SearchResults'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        self.search_results = []
        if m.get('SearchResults') is not None:
            for k in m.get('SearchResults'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorDetailsSearchResults()
                self.search_results.append(temp_model.from_map(k))
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsPartitionedTables(TeaModel):
    def __init__(
        self,
        ddl: str = None,
        partition_count: str = None,
        partition_ids: str = None,
        schema_name: str = None,
        table_name: str = None,
        total_data_size: int = None,
    ):
        # The SQL statement that is used to create the table.
        self.ddl = ddl
        # The number of partitions.
        self.partition_count = partition_count
        # The ID of the improper partition.
        self.partition_ids = partition_ids
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name
        # The total data size of the table.
        self.total_data_size = total_data_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.ddl is not None:
            result['DDL'] = self.ddl
        if self.partition_count is not None:
            result['PartitionCount'] = self.partition_count
        if self.partition_ids is not None:
            result['PartitionIds'] = self.partition_ids
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_data_size is not None:
            result['TotalDataSize'] = self.total_data_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DDL') is not None:
            self.ddl = m.get('DDL')
        if m.get('PartitionCount') is not None:
            self.partition_count = m.get('PartitionCount')
        if m.get('PartitionIds') is not None:
            self.partition_ids = m.get('PartitionIds')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalDataSize') is not None:
            self.total_data_size = m.get('TotalDataSize')
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsSkewedTables(TeaModel):
    def __init__(
        self,
        ddl: str = None,
        partition_count: int = None,
        schema_name: str = None,
        shard_skewed_rows: str = None,
        table_name: str = None,
        total_data_size: int = None,
        total_local_data_size: str = None,
        total_pk_size: int = None,
        total_remote_data_size: int = None,
        total_row_count: int = None,
    ):
        # The SQL statement that is used to create the table.
        self.ddl = ddl
        # The number of partitions.
        self.partition_count = partition_count
        # The name of the database.
        self.schema_name = schema_name
        # The number of skewed rows in the table.
        self.shard_skewed_rows = shard_skewed_rows
        # The name of the table.
        self.table_name = table_name
        # The total data size of the table. Unit: bytes.
        self.total_data_size = total_data_size
        # The size of hot data. Unit: bytes.
        self.total_local_data_size = total_local_data_size
        # The data size of the primary key. Unit: bytes.
        self.total_pk_size = total_pk_size
        # The size of cold data. Unit: bytes.
        self.total_remote_data_size = total_remote_data_size
        # The number of rows in the table.
        self.total_row_count = total_row_count

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.ddl is not None:
            result['DDL'] = self.ddl
        if self.partition_count is not None:
            result['PartitionCount'] = self.partition_count
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.shard_skewed_rows is not None:
            result['ShardSkewedRows'] = self.shard_skewed_rows
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.total_data_size is not None:
            result['TotalDataSize'] = self.total_data_size
        if self.total_local_data_size is not None:
            result['TotalLocalDataSize'] = self.total_local_data_size
        if self.total_pk_size is not None:
            result['TotalPkSize'] = self.total_pk_size
        if self.total_remote_data_size is not None:
            result['TotalRemoteDataSize'] = self.total_remote_data_size
        if self.total_row_count is not None:
            result['TotalRowCount'] = self.total_row_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DDL') is not None:
            self.ddl = m.get('DDL')
        if m.get('PartitionCount') is not None:
            self.partition_count = m.get('PartitionCount')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('ShardSkewedRows') is not None:
            self.shard_skewed_rows = m.get('ShardSkewedRows')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('TotalDataSize') is not None:
            self.total_data_size = m.get('TotalDataSize')
        if m.get('TotalLocalDataSize') is not None:
            self.total_local_data_size = m.get('TotalLocalDataSize')
        if m.get('TotalPkSize') is not None:
            self.total_pk_size = m.get('TotalPkSize')
        if m.get('TotalRemoteDataSize') is not None:
            self.total_remote_data_size = m.get('TotalRemoteDataSize')
        if m.get('TotalRowCount') is not None:
            self.total_row_count = m.get('TotalRowCount')
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsTopAccessTablesSearchResults(TeaModel):
    def __init__(
        self,
        access_count: int = None,
        avg_scan_cost: float = None,
        avg_scan_size: float = None,
        max_scan_cost: int = None,
        max_scan_size: int = None,
        table_name: str = None,
    ):
        # The number of accesses to the table.
        self.access_count = access_count
        # The average amount of time for scanning. Unit: milliseconds.
        self.avg_scan_cost = avg_scan_cost
        # The average data size for scanning. Unit: bytes.
        self.avg_scan_size = avg_scan_size
        # The maximum amount of time for scanning. Unit: milliseconds.
        self.max_scan_cost = max_scan_cost
        # The maximum data size for scanning. Unit: bytes.
        self.max_scan_size = max_scan_size
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_count is not None:
            result['AccessCount'] = self.access_count
        if self.avg_scan_cost is not None:
            result['AvgScanCost'] = self.avg_scan_cost
        if self.avg_scan_size is not None:
            result['AvgScanSize'] = self.avg_scan_size
        if self.max_scan_cost is not None:
            result['MaxScanCost'] = self.max_scan_cost
        if self.max_scan_size is not None:
            result['MaxScanSize'] = self.max_scan_size
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessCount') is not None:
            self.access_count = m.get('AccessCount')
        if m.get('AvgScanCost') is not None:
            self.avg_scan_cost = m.get('AvgScanCost')
        if m.get('AvgScanSize') is not None:
            self.avg_scan_size = m.get('AvgScanSize')
        if m.get('MaxScanCost') is not None:
            self.max_scan_cost = m.get('MaxScanCost')
        if m.get('MaxScanSize') is not None:
            self.max_scan_size = m.get('MaxScanSize')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResultsTopAccessTables(TeaModel):
    def __init__(
        self,
        metric_name: str = None,
        search_results: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsTopAccessTablesSearchResults] = None,
    ):
        # The name of the detection metric.
        self.metric_name = metric_name
        # The detection result items of table access.
        self.search_results = search_results

    def validate(self):
        if self.search_results:
            for k in self.search_results:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        result['SearchResults'] = []
        if self.search_results is not None:
            for k in self.search_results:
                result['SearchResults'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        self.search_results = []
        if m.get('SearchResults') is not None:
            for k in m.get('SearchResults'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsTopAccessTablesSearchResults()
                self.search_results.append(temp_model.from_map(k))
        return self


class DescribeWorkerDetectionResponseBodyDetectionItemsResults(TeaModel):
    def __init__(
        self,
        operator_agg: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorAgg] = None,
        operator_details: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorDetails] = None,
        partitioned_tables: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsPartitionedTables] = None,
        skewed_tables: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsSkewedTables] = None,
        top_access_tables: List[DescribeWorkerDetectionResponseBodyDetectionItemsResultsTopAccessTables] = None,
    ):
        # The detection result items of operator metric aggregation.
        self.operator_agg = operator_agg
        # The detection result items of abnormal operators.
        self.operator_details = operator_details
        # The detection result items of improper partitioned tables.
        self.partitioned_tables = partitioned_tables
        # The detection result items of skewed tables.
        self.skewed_tables = skewed_tables
        # The detection result items of table access.
        self.top_access_tables = top_access_tables

    def validate(self):
        if self.operator_agg:
            for k in self.operator_agg:
                if k:
                    k.validate()
        if self.operator_details:
            for k in self.operator_details:
                if k:
                    k.validate()
        if self.partitioned_tables:
            for k in self.partitioned_tables:
                if k:
                    k.validate()
        if self.skewed_tables:
            for k in self.skewed_tables:
                if k:
                    k.validate()
        if self.top_access_tables:
            for k in self.top_access_tables:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['OperatorAgg'] = []
        if self.operator_agg is not None:
            for k in self.operator_agg:
                result['OperatorAgg'].append(k.to_map() if k else None)
        result['OperatorDetails'] = []
        if self.operator_details is not None:
            for k in self.operator_details:
                result['OperatorDetails'].append(k.to_map() if k else None)
        result['PartitionedTables'] = []
        if self.partitioned_tables is not None:
            for k in self.partitioned_tables:
                result['PartitionedTables'].append(k.to_map() if k else None)
        result['SkewedTables'] = []
        if self.skewed_tables is not None:
            for k in self.skewed_tables:
                result['SkewedTables'].append(k.to_map() if k else None)
        result['TopAccessTables'] = []
        if self.top_access_tables is not None:
            for k in self.top_access_tables:
                result['TopAccessTables'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.operator_agg = []
        if m.get('OperatorAgg') is not None:
            for k in m.get('OperatorAgg'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorAgg()
                self.operator_agg.append(temp_model.from_map(k))
        self.operator_details = []
        if m.get('OperatorDetails') is not None:
            for k in m.get('OperatorDetails'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsOperatorDetails()
                self.operator_details.append(temp_model.from_map(k))
        self.partitioned_tables = []
        if m.get('PartitionedTables') is not None:
            for k in m.get('PartitionedTables'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsPartitionedTables()
                self.partitioned_tables.append(temp_model.from_map(k))
        self.skewed_tables = []
        if m.get('SkewedTables') is not None:
            for k in m.get('SkewedTables'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsSkewedTables()
                self.skewed_tables.append(temp_model.from_map(k))
        self.top_access_tables = []
        if m.get('TopAccessTables') is not None:
            for k in m.get('TopAccessTables'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResultsTopAccessTables()
                self.top_access_tables.append(temp_model.from_map(k))
        return self


class DescribeWorkerDetectionResponseBodyDetectionItems(TeaModel):
    def __init__(
        self,
        message: str = None,
        name: str = None,
        results: DescribeWorkerDetectionResponseBodyDetectionItemsResults = None,
        status: str = None,
    ):
        # The information about the detection result.
        self.message = message
        # The name of the detection item.
        self.name = name
        # The detection result items.
        self.results = results
        # The severity level of the detection result. Valid values:
        # 
        # *   NORMAL
        # *   WARNING
        # *   CRITICAL
        self.status = status

    def validate(self):
        if self.results:
            self.results.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.message is not None:
            result['Message'] = self.message
        if self.name is not None:
            result['Name'] = self.name
        if self.results is not None:
            result['Results'] = self.results.to_map()
        if self.status is not None:
            result['Status'] = self.status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Results') is not None:
            temp_model = DescribeWorkerDetectionResponseBodyDetectionItemsResults()
            self.results = temp_model.from_map(m['Results'])
        if m.get('Status') is not None:
            self.status = m.get('Status')
        return self


class DescribeWorkerDetectionResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        detection_items: List[DescribeWorkerDetectionResponseBodyDetectionItems] = None,
        request_id: str = None,
        total_count: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The queried detection items and detection results.
        self.detection_items = detection_items
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.detection_items:
            for k in self.detection_items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        result['DetectionItems'] = []
        if self.detection_items is not None:
            for k in self.detection_items:
                result['DetectionItems'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        self.detection_items = []
        if m.get('DetectionItems') is not None:
            for k in m.get('DetectionItems'):
                temp_model = DescribeWorkerDetectionResponseBodyDetectionItems()
                self.detection_items.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeWorkerDetectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DescribeWorkerDetectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeWorkerDetectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachUserENIRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The instance ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class DetachUserENIResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DetachUserENIResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DetachUserENIResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachUserENIResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DisableAdviceServiceRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DisableAdviceServiceResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DisableAdviceServiceResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DisableAdviceServiceResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DisableAdviceServiceResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DisableElasticPlanRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # >  You can call the [DescribeElasticPlans](https://help.aliyun.com/document_detail/601334.html) operation to query the names of scaling plans.
        # 
        # This parameter is required.
        self.elastic_plan_name = elastic_plan_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        return self


class DisableElasticPlanResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DisableElasticPlanResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DisableElasticPlanResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DisableElasticPlanResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DownloadDiagnosisRecordsRequest(TeaModel):
    def __init__(
        self,
        client_ip: str = None,
        dbcluster_id: str = None,
        database: str = None,
        end_time: str = None,
        keyword: str = None,
        lang: str = None,
        max_peak_memory: int = None,
        max_scan_size: int = None,
        min_peak_memory: int = None,
        min_scan_size: int = None,
        query_condition: str = None,
        region_id: str = None,
        resource_group: str = None,
        start_time: str = None,
        user_name: str = None,
    ):
        # The source IP address.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.client_ip = client_ip
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database on which the SQL statements are executed.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.database = database
        # The end of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # > 
        # 
        # *   The end time must be later than the start time.
        # 
        # *   The maximum time range that can be specified is 24 hours.
        self.end_time = end_time
        # The query keyword of the SQL statements.
        self.keyword = keyword
        # The language. Valid values:
        # 
        # *   **zh**: simplified Chinese.
        # *   **en**: English.
        # *   **ja**: Japanese.
        # *   **zh-tw**: traditional Chinese.
        self.lang = lang
        # The maximum peak memory of the SQL statements. Unit: bytes.
        self.max_peak_memory = max_peak_memory
        # The maximum scan size of the SQL statements. Unit: bytes.
        self.max_scan_size = max_scan_size
        # The minimum peak memory of the SQL statements. Unit: bytes.
        self.min_peak_memory = min_peak_memory
        # The minimum scan size of the SQL statements. Unit: bytes.
        self.min_scan_size = min_scan_size
        # The query condition for SQL statements, which can contain the `Type`, `Value`, `Min`, and `Max` fields. Specify the condition in the JSON format. `Type` specifies the query dimension. Valid values for Type: `maxCost`, `status`, and `cost`. `Value`, `Min`, or `Max` specifies the query range for the dimension. Valid values:
        # 
        # *   `{"Type":"maxCost","Value":"100"}`: queries the top 100 most time-consuming SQL statements. Set `Value` to 100.
        # *   `{"Type":"status","Value":"finished"}`: queries the executed SQL statements. You can set `Value` to `running` to query the SQL statements that are being executed. You can also set Value to `failed` to query the SQL statements that failed to be executed.
        # *   `{"Type":"cost","Min":"10","Max":"200"}`: queries the SQL statements whose execution duration is in the range of 10 to 200 milliseconds. You can also specify custom values for the Min and Max fields.
        self.query_condition = query_condition
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The resource group to which the SQL statements belong.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](https://help.aliyun.com/document_detail/308210.html) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.resource_group = resource_group
        # The beginning of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # >  You can query data only within the last 14 days.
        self.start_time = start_time
        # The username that is used to execute the SQL statements.
        # 
        # >  You can call the [DescribeDiagnosisDimensions](~~~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_ip is not None:
            result['ClientIp'] = self.client_ip
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database is not None:
            result['Database'] = self.database
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.keyword is not None:
            result['Keyword'] = self.keyword
        if self.lang is not None:
            result['Lang'] = self.lang
        if self.max_peak_memory is not None:
            result['MaxPeakMemory'] = self.max_peak_memory
        if self.max_scan_size is not None:
            result['MaxScanSize'] = self.max_scan_size
        if self.min_peak_memory is not None:
            result['MinPeakMemory'] = self.min_peak_memory
        if self.min_scan_size is not None:
            result['MinScanSize'] = self.min_scan_size
        if self.query_condition is not None:
            result['QueryCondition'] = self.query_condition
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ClientIp') is not None:
            self.client_ip = m.get('ClientIp')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Keyword') is not None:
            self.keyword = m.get('Keyword')
        if m.get('Lang') is not None:
            self.lang = m.get('Lang')
        if m.get('MaxPeakMemory') is not None:
            self.max_peak_memory = m.get('MaxPeakMemory')
        if m.get('MaxScanSize') is not None:
            self.max_scan_size = m.get('MaxScanSize')
        if m.get('MinPeakMemory') is not None:
            self.min_peak_memory = m.get('MinPeakMemory')
        if m.get('MinScanSize') is not None:
            self.min_scan_size = m.get('MinScanSize')
        if m.get('QueryCondition') is not None:
            self.query_condition = m.get('QueryCondition')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DownloadDiagnosisRecordsResponseBody(TeaModel):
    def __init__(
        self,
        download_id: int = None,
        request_id: str = None,
    ):
        # The download ID.
        self.download_id = download_id
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.download_id is not None:
            result['DownloadId'] = self.download_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DownloadId') is not None:
            self.download_id = m.get('DownloadId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DownloadDiagnosisRecordsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DownloadDiagnosisRecordsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DownloadDiagnosisRecordsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DownloadInstanceCACertificateRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        engine: str = None,
        owner_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DownloadInstanceCACertificateResponseBody(TeaModel):
    def __init__(
        self,
        download_url: str = None,
        request_id: str = None,
    ):
        # The OSS URL of the downloaded certificate.
        self.download_url = download_url
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.download_url is not None:
            result['DownloadUrl'] = self.download_url
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DownloadUrl') is not None:
            self.download_url = m.get('DownloadUrl')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DownloadInstanceCACertificateResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: DownloadInstanceCACertificateResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DownloadInstanceCACertificateResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class EnableAdviceServiceRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class EnableAdviceServiceResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class EnableAdviceServiceResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: EnableAdviceServiceResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = EnableAdviceServiceResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class EnableElasticPlanRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # >  You can call the [DescribeElasticPlans](https://help.aliyun.com/document_detail/601334.html) operation to query the names of scaling plans.
        # 
        # This parameter is required.
        self.elastic_plan_name = elastic_plan_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        return self


class EnableElasticPlanResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class EnableElasticPlanResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: EnableElasticPlanResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = EnableElasticPlanResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ExecuteSparkReplStatementRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        code: str = None,
        code_type: str = None,
        session_id: int = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query Spark application IDs.
        self.app_id = app_id
        # The code that you want to execute.
        # 
        # This parameter is required.
        self.code = code
        # The language type of the code. Valid values:
        # 
        # *   SCALA
        # *   PYTHON
        # 
        # This parameter is required.
        self.code_type = code_type
        # The ID of the session that you want to use to execute the code.
        # 
        # This parameter is required.
        self.session_id = session_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.code is not None:
            result['Code'] = self.code
        if self.code_type is not None:
            result['CodeType'] = self.code_type
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('CodeType') is not None:
            self.code_type = m.get('CodeType')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        return self


class ExecuteSparkReplStatementResponseBodyData(TeaModel):
    def __init__(
        self,
        aliyun_uid: int = None,
        code: str = None,
        code_state: str = None,
        code_type: str = None,
        columns: List[str] = None,
        end_time: int = None,
        error: str = None,
        output: str = None,
        output_type: str = None,
        start_time: int = None,
        statement_id: int = None,
    ):
        # The ID of the Alibaba Cloud account that owns the cluster.
        self.aliyun_uid = aliyun_uid
        # The code that is executed.
        self.code = code
        # The code execution status. Valid values:
        # 
        # *   CANCELLED
        # *   RUNNING
        # *   SUCCEEDED
        # *   ERROR
        self.code_state = code_state
        # The code type. Valid values:
        # 
        # *   SCALA
        # *   PYTHON
        self.code_type = code_type
        # The column names.
        self.columns = columns
        # The end time of the execution. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.end_time = end_time
        # The error message.
        self.error = error
        # The code execution result, which is a JSON string that conforms to Apache Livy.
        self.output = output
        # The execution result type, which is in the JSON format. Valid values:
        # 
        # *   TEXT: the text content that conforms to Apache Livy.
        # *   TABLE: the table content that conforms to Apache Livy.
        self.output_type = output_type
        # The start time of the execution. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.start_time = start_time
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.code is not None:
            result['Code'] = self.code
        if self.code_state is not None:
            result['CodeState'] = self.code_state
        if self.code_type is not None:
            result['CodeType'] = self.code_type
        if self.columns is not None:
            result['Columns'] = self.columns
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.error is not None:
            result['Error'] = self.error
        if self.output is not None:
            result['Output'] = self.output
        if self.output_type is not None:
            result['OutputType'] = self.output_type
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('CodeState') is not None:
            self.code_state = m.get('CodeState')
        if m.get('CodeType') is not None:
            self.code_type = m.get('CodeType')
        if m.get('Columns') is not None:
            self.columns = m.get('Columns')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('OutputType') is not None:
            self.output_type = m.get('OutputType')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class ExecuteSparkReplStatementResponseBody(TeaModel):
    def __init__(
        self,
        data: ExecuteSparkReplStatementResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = ExecuteSparkReplStatementResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ExecuteSparkReplStatementResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ExecuteSparkReplStatementResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ExecuteSparkReplStatementResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ExecuteSparkWarehouseBatchSQLRequest(TeaModel):
    def __init__(
        self,
        agency: str = None,
        dbcluster_id: str = None,
        execute_result_limit: int = None,
        execute_time_limit_in_seconds: int = None,
        query: str = None,
        resource_group_name: str = None,
        runtime_config: str = None,
        schema: str = None,
    ):
        # The name of the client.
        self.agency = agency
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The maximum amount of execution result data that can be written to Object Storage Service (OSS). Unit: MB. Default value: 4096. The size of compressed objects is difficult to estimate. The data that is actually written to OSS is smaller than the specified value.
        self.execute_result_limit = execute_result_limit
        # The maximum execution duration. Unit: seconds. If a set of SQL statements fail to be executed for the specified period of time after submission, they are marked as a timeout error. The default value is 360000 seconds, which is equivalent to 100 hours.
        self.execute_time_limit_in_seconds = execute_time_limit_in_seconds
        # The SQL statements that you want to execute in batches. Separate multiple SQL statements with semicolons (;). The execution engine executes the SQL statements in sequence in the same session.
        # 
        # This parameter is required.
        self.query = query
        # The name of the resource group.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name
        # The additional runtime parameter. Specify the parameter in the JSON format.
        self.runtime_config = runtime_config
        # The name of the database.
        self.schema = schema

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.agency is not None:
            result['Agency'] = self.agency
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.execute_result_limit is not None:
            result['ExecuteResultLimit'] = self.execute_result_limit
        if self.execute_time_limit_in_seconds is not None:
            result['ExecuteTimeLimitInSeconds'] = self.execute_time_limit_in_seconds
        if self.query is not None:
            result['Query'] = self.query
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.runtime_config is not None:
            result['RuntimeConfig'] = self.runtime_config
        if self.schema is not None:
            result['Schema'] = self.schema
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Agency') is not None:
            self.agency = m.get('Agency')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ExecuteResultLimit') is not None:
            self.execute_result_limit = m.get('ExecuteResultLimit')
        if m.get('ExecuteTimeLimitInSeconds') is not None:
            self.execute_time_limit_in_seconds = m.get('ExecuteTimeLimitInSeconds')
        if m.get('Query') is not None:
            self.query = m.get('Query')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('RuntimeConfig') is not None:
            self.runtime_config = m.get('RuntimeConfig')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        return self


class ExecuteSparkWarehouseBatchSQLResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkBatchSQL = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkBatchSQL()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ExecuteSparkWarehouseBatchSQLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ExecuteSparkWarehouseBatchSQLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ExecuteSparkWarehouseBatchSQLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ExistRunningSQLEngineRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        resource_group_name: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        # 
        # >  You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the name of the resource group for a cluster.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class ExistRunningSQLEngineResponseBody(TeaModel):
    def __init__(
        self,
        data: bool = None,
        request_id: str = None,
    ):
        # Indicates whether a running SQL engine exists in the resource group.
        # 
        # Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ExistRunningSQLEngineResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ExistRunningSQLEngineResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ExistRunningSQLEngineResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetApsManagedDatabasesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class GetApsManagedDatabasesResponseBody(TeaModel):
    def __init__(
        self,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class GetApsManagedDatabasesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetApsManagedDatabasesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetApsManagedDatabasesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetCreateTableSQLRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class GetCreateTableSQLResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        sql: str = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The SQL statement.
        self.sql = sql

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.sql is not None:
            result['SQL'] = self.sql
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        return self


class GetCreateTableSQLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetCreateTableSQLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetCreateTableSQLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetDatabaseObjectsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        filter_owner: str = None,
        filter_schema_name: str = None,
        order_by: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The owner of the database.
        self.filter_owner = filter_owner
        # The name of the database.
        self.filter_schema_name = filter_schema_name
        # The order in which you want to sort the query results. Valid values:
        # 
        # *   Asc
        # *   Desc
        # 
        # Valid values for Field: DatabaseName, CreateTime, and UpdateTime. -CreateTime; -UpdateTime;
        # 
        # Default value: {"Type": "Desc","Field": "DatabaseName"}.
        self.order_by = order_by
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   30
        # *   50
        # *   100
        # 
        # Default value: 30.
        self.page_size = page_size
        # The region ID of the database.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.filter_owner is not None:
            result['FilterOwner'] = self.filter_owner
        if self.filter_schema_name is not None:
            result['FilterSchemaName'] = self.filter_schema_name
        if self.order_by is not None:
            result['OrderBy'] = self.order_by
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FilterOwner') is not None:
            self.filter_owner = m.get('FilterOwner')
        if m.get('FilterSchemaName') is not None:
            self.filter_schema_name = m.get('FilterSchemaName')
        if m.get('OrderBy') is not None:
            self.order_by = m.get('OrderBy')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class GetDatabaseObjectsResponseBodyData(TeaModel):
    def __init__(
        self,
        database_summary_models: List[DatabaseSummaryModel] = None,
        page_number: int = None,
        page_size: int = None,
        total_count: int = None,
    ):
        # The queried databases.
        self.database_summary_models = database_summary_models
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   30
        # *   50
        # *   100
        # 
        # Default value: 30.
        self.page_size = page_size
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.database_summary_models:
            for k in self.database_summary_models:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['DatabaseSummaryModels'] = []
        if self.database_summary_models is not None:
            for k in self.database_summary_models:
                result['DatabaseSummaryModels'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.database_summary_models = []
        if m.get('DatabaseSummaryModels') is not None:
            for k in m.get('DatabaseSummaryModels'):
                temp_model = DatabaseSummaryModel()
                self.database_summary_models.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetDatabaseObjectsResponseBody(TeaModel):
    def __init__(
        self,
        data: GetDatabaseObjectsResponseBodyData = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The returned data.
        self.data = data
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetDatabaseObjectsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetDatabaseObjectsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetDatabaseObjectsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetDatabaseObjectsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetLakeStorageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        lake_storage_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The lake storage ID.
        self.lake_storage_id = lake_storage_id
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class GetLakeStorageResponseBodyDataPermissions(TeaModel):
    def __init__(
        self,
        account: str = None,
        read: bool = None,
        type: str = None,
        write: bool = None,
    ):
        # The account ID.
        self.account = account
        # The read permissions.
        self.read = read
        # The account type.
        self.type = type
        # The write permissions.
        self.write = write

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account is not None:
            result['Account'] = self.account
        if self.read is not None:
            result['Read'] = self.read
        if self.type is not None:
            result['Type'] = self.type
        if self.write is not None:
            result['Write'] = self.write
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Account') is not None:
            self.account = m.get('Account')
        if m.get('Read') is not None:
            self.read = m.get('Read')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Write') is not None:
            self.write = m.get('Write')
        return self


class GetLakeStorageResponseBodyData(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        creator_uid: str = None,
        dbcluster_id: str = None,
        description: str = None,
        file_size: str = None,
        lake_storage_id: str = None,
        operator_uid: str = None,
        owner_uid: str = None,
        partition_count: str = None,
        permissions: List[GetLakeStorageResponseBodyDataPermissions] = None,
        region_id: str = None,
        row_count: int = None,
        table_count: int = None,
        update_time: str = None,
    ):
        # The time when the lake storage was created.
        self.create_time = create_time
        # The creator UID.
        self.creator_uid = creator_uid
        # The ID of the AnalyticDB for MySQL cluster.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The total storage size.
        self.file_size = file_size
        # The unique identifier of the lake storage.
        self.lake_storage_id = lake_storage_id
        # The operator UID.
        self.operator_uid = operator_uid
        # The owner UID.
        self.owner_uid = owner_uid
        # The number of partitions.
        self.partition_count = partition_count
        # The permissions on the lake storage.
        self.permissions = permissions
        # The region ID.
        self.region_id = region_id
        # The total number of entries returned.
        self.row_count = row_count
        # The number of the tables.
        self.table_count = table_count
        # The time when the lake storage was last updated.
        self.update_time = update_time

    def validate(self):
        if self.permissions:
            for k in self.permissions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.creator_uid is not None:
            result['CreatorUid'] = self.creator_uid
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        if self.file_size is not None:
            result['FileSize'] = self.file_size
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        if self.operator_uid is not None:
            result['OperatorUid'] = self.operator_uid
        if self.owner_uid is not None:
            result['OwnerUid'] = self.owner_uid
        if self.partition_count is not None:
            result['PartitionCount'] = self.partition_count
        result['Permissions'] = []
        if self.permissions is not None:
            for k in self.permissions:
                result['Permissions'].append(k.to_map() if k else None)
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.row_count is not None:
            result['RowCount'] = self.row_count
        if self.table_count is not None:
            result['TableCount'] = self.table_count
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('CreatorUid') is not None:
            self.creator_uid = m.get('CreatorUid')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('FileSize') is not None:
            self.file_size = m.get('FileSize')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        if m.get('OperatorUid') is not None:
            self.operator_uid = m.get('OperatorUid')
        if m.get('OwnerUid') is not None:
            self.owner_uid = m.get('OwnerUid')
        if m.get('PartitionCount') is not None:
            self.partition_count = m.get('PartitionCount')
        self.permissions = []
        if m.get('Permissions') is not None:
            for k in m.get('Permissions'):
                temp_model = GetLakeStorageResponseBodyDataPermissions()
                self.permissions.append(temp_model.from_map(k))
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('RowCount') is not None:
            self.row_count = m.get('RowCount')
        if m.get('TableCount') is not None:
            self.table_count = m.get('TableCount')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class GetLakeStorageResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: GetLakeStorageResponseBodyData = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The queried lake storage.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = GetLakeStorageResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class GetLakeStorageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetLakeStorageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetLakeStorageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkAppAttemptLogRequest(TeaModel):
    def __init__(
        self,
        attempt_id: str = None,
        log_length: int = None,
        page_number: int = None,
        page_size: str = None,
    ):
        # The ID of the log.
        # 
        # > You can call the [ListSparkAppAttempts](https://help.aliyun.com/document_detail/455887.html) operation to query the information about the retry attempts of a Spark application, including the retry log IDs.
        # 
        # This parameter is required.
        self.attempt_id = attempt_id
        # The number of log entries to return. Valid values: 1 to 500. Default value: 300.
        self.log_length = log_length
        # The log offset.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.attempt_id is not None:
            result['AttemptId'] = self.attempt_id
        if self.log_length is not None:
            result['LogLength'] = self.log_length
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AttemptId') is not None:
            self.attempt_id = m.get('AttemptId')
        if m.get('LogLength') is not None:
            self.log_length = m.get('LogLength')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        return self


class GetSparkAppAttemptLogResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        log_content: str = None,
        log_size: int = None,
        message: str = None,
    ):
        # The application ID.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The content of the log.
        self.log_content = log_content
        # The number of log entries. A value of 0 indicates that no valid logs are returned.
        self.log_size = log_size
        # The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.
        self.message = message

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.log_content is not None:
            result['LogContent'] = self.log_content
        if self.log_size is not None:
            result['LogSize'] = self.log_size
        if self.message is not None:
            result['Message'] = self.message
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('LogContent') is not None:
            self.log_content = m.get('LogContent')
        if m.get('LogSize') is not None:
            self.log_size = m.get('LogSize')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        return self


class GetSparkAppAttemptLogResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkAppAttemptLogResponseBodyData = None,
        request_id: str = None,
    ):
        # The queried log.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkAppAttemptLogResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkAppAttemptLogResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkAppAttemptLogResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkAppAttemptLogResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkAppInfoRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query the Spark application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkAppInfoResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkAppInfo = None,
        request_id: str = None,
    ):
        # The queried Spark application. Fields in the response parameter:
        # 
        # *   **Data**: the data of the Spark application template.
        # *   **EstimateExecutionCpuTimeInSeconds**: the amount of time that is required to consume CPU resources for running the Spark application. Unit: milliseconds.
        # *   **LogRootPath**: the storage path of log files.
        # *   **LastAttemptId**: the most recent attempt ID.
        # *   **WebUiAddress**: the web UI URL.
        # *   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # *   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # *   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # *   **TerminatedTimeInMillis**: the time when the Spark application was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # *   **DBClusterId**: the ID of the cluster on which the Spark application runs.
        # *   **ResourceGroupName**: the name of the job resource group.
        # *   **DurationInMillis**: the amount of time that is required to run the Spark application. Unit: milliseconds.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkAppInfo()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkAppInfoResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkAppInfoResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkAppInfoResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkAppLogRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        log_length: int = None,
        page_number: int = None,
        page_size: int = None,
    ):
        # The Spark application ID.
        # 
        # > You can call the [ListSparkApps](https://help.aliyun.com/document_detail/612475.html) operation to query the Spark application ID.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id
        # The number of log entries to return. Valid values: 1 to 500. Default value: 300.
        self.log_length = log_length
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.log_length is not None:
            result['LogLength'] = self.log_length
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('LogLength') is not None:
            self.log_length = m.get('LogLength')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        return self


class GetSparkAppLogResponseBodyData(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        log_content: str = None,
        log_size: int = None,
        message: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The content of the log.
        self.log_content = log_content
        # The number of log entries. A value of 0 indicates that no valid logs are returned.
        self.log_size = log_size
        # The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.
        self.message = message

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.log_content is not None:
            result['LogContent'] = self.log_content
        if self.log_size is not None:
            result['LogSize'] = self.log_size
        if self.message is not None:
            result['Message'] = self.message
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('LogContent') is not None:
            self.log_content = m.get('LogContent')
        if m.get('LogSize') is not None:
            self.log_size = m.get('LogSize')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        return self


class GetSparkAppLogResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkAppLogResponseBodyData = None,
        request_id: str = None,
    ):
        # The queried log.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkAppLogResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkAppLogResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkAppLogResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkAppLogResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkAppMetricsRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
    ):
        # The ID of the Spark application.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkAppMetricsResponseBodyDataScanMetrics(TeaModel):
    def __init__(
        self,
        output_rows_count: int = None,
        total_read_file_size_in_byte: int = None,
    ):
        # The number of scanned rows.
        self.output_rows_count = output_rows_count
        # The number of scanned bytes.
        self.total_read_file_size_in_byte = total_read_file_size_in_byte

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.output_rows_count is not None:
            result['OutputRowsCount'] = self.output_rows_count
        if self.total_read_file_size_in_byte is not None:
            result['TotalReadFileSizeInByte'] = self.total_read_file_size_in_byte
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('OutputRowsCount') is not None:
            self.output_rows_count = m.get('OutputRowsCount')
        if m.get('TotalReadFileSizeInByte') is not None:
            self.total_read_file_size_in_byte = m.get('TotalReadFileSizeInByte')
        return self


class GetSparkAppMetricsResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        attempt_id: str = None,
        event_log_path: str = None,
        finished: bool = None,
        scan_metrics: GetSparkAppMetricsResponseBodyDataScanMetrics = None,
    ):
        # The ID of the Spark application.
        self.app_id = app_id
        # The attempt ID of the Spark application.
        self.attempt_id = attempt_id
        # The path of the event log.
        self.event_log_path = event_log_path
        # Indicates whether parsing is complete. Valid values:
        # 
        # *   true
        # *   false
        self.finished = finished
        # The metrics.
        self.scan_metrics = scan_metrics

    def validate(self):
        if self.scan_metrics:
            self.scan_metrics.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.attempt_id is not None:
            result['AttemptId'] = self.attempt_id
        if self.event_log_path is not None:
            result['EventLogPath'] = self.event_log_path
        if self.finished is not None:
            result['Finished'] = self.finished
        if self.scan_metrics is not None:
            result['ScanMetrics'] = self.scan_metrics.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AttemptId') is not None:
            self.attempt_id = m.get('AttemptId')
        if m.get('EventLogPath') is not None:
            self.event_log_path = m.get('EventLogPath')
        if m.get('Finished') is not None:
            self.finished = m.get('Finished')
        if m.get('ScanMetrics') is not None:
            temp_model = GetSparkAppMetricsResponseBodyDataScanMetrics()
            self.scan_metrics = temp_model.from_map(m['ScanMetrics'])
        return self


class GetSparkAppMetricsResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkAppMetricsResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkAppMetricsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkAppMetricsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkAppMetricsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkAppMetricsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkAppStateRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
    ):
        # The Spark application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query Spark application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkAppStateResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        app_name: str = None,
        dbcluster_id: str = None,
        message: str = None,
        state: str = None,
    ):
        # The Spark application ID.
        self.app_id = app_id
        # The name of the application.
        self.app_name = app_name
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The alert message returned for the operation, such as task execution failure or insufficient resources. If no alert occurs, null is returned.
        self.message = message
        # The execution state of the application. Valid values:
        # 
        # *   **SUBMITTED**\
        # *   **STARTING**\
        # *   **RUNNING**\
        # *   **FAILING**\
        # *   **FAILED**\
        # *   **KILLING**\
        # *   **KILLED**\
        # *   **SUCCEEDING**\
        # *   **COMPLETED**\
        # *   **FATAL**\
        # *   **UNKNOWN**\
        self.state = state

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.app_name is not None:
            result['AppName'] = self.app_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.message is not None:
            result['Message'] = self.message
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AppName') is not None:
            self.app_name = m.get('AppName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class GetSparkAppStateResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkAppStateResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkAppStateResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkAppStateResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkAppStateResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkAppStateResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkAppWebUiAddressRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
    ):
        # The Spark application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query Spark application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkAppWebUiAddressResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        expiration_time_in_millis: int = None,
        web_ui_address: str = None,
    ):
        # The Spark application ID.
        self.app_id = app_id
        # The database ID.
        self.dbcluster_id = dbcluster_id
        # The expiration time. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.expiration_time_in_millis = expiration_time_in_millis
        # The URL of the web UI for the Spark application.
        self.web_ui_address = web_ui_address

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.expiration_time_in_millis is not None:
            result['ExpirationTimeInMillis'] = self.expiration_time_in_millis
        if self.web_ui_address is not None:
            result['WebUiAddress'] = self.web_ui_address
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ExpirationTimeInMillis') is not None:
            self.expiration_time_in_millis = m.get('ExpirationTimeInMillis')
        if m.get('WebUiAddress') is not None:
            self.web_ui_address = m.get('WebUiAddress')
        return self


class GetSparkAppWebUiAddressResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkAppWebUiAddressResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkAppWebUiAddressResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkAppWebUiAddressResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkAppWebUiAddressResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkAppWebUiAddressResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkConfigLogPathRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkConfigLogPathResponseBodyData(TeaModel):
    def __init__(
        self,
        default_log_path: str = None,
        is_log_path_exists: bool = None,
        modified_timestamp: str = None,
        modified_uid: str = None,
        recorded_log_path: str = None,
    ):
        # The default log path.
        self.default_log_path = default_log_path
        # Indicates whether a log path exists.
        self.is_log_path_exists = is_log_path_exists
        # The last modification time.
        self.modified_timestamp = modified_timestamp
        # The account ID of the modifier.
        self.modified_uid = modified_uid
        # The recorded log path.
        self.recorded_log_path = recorded_log_path

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.default_log_path is not None:
            result['DefaultLogPath'] = self.default_log_path
        if self.is_log_path_exists is not None:
            result['IsLogPathExists'] = self.is_log_path_exists
        if self.modified_timestamp is not None:
            result['ModifiedTimestamp'] = self.modified_timestamp
        if self.modified_uid is not None:
            result['ModifiedUid'] = self.modified_uid
        if self.recorded_log_path is not None:
            result['RecordedLogPath'] = self.recorded_log_path
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DefaultLogPath') is not None:
            self.default_log_path = m.get('DefaultLogPath')
        if m.get('IsLogPathExists') is not None:
            self.is_log_path_exists = m.get('IsLogPathExists')
        if m.get('ModifiedTimestamp') is not None:
            self.modified_timestamp = m.get('ModifiedTimestamp')
        if m.get('ModifiedUid') is not None:
            self.modified_uid = m.get('ModifiedUid')
        if m.get('RecordedLogPath') is not None:
            self.recorded_log_path = m.get('RecordedLogPath')
        return self


class GetSparkConfigLogPathResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkConfigLogPathResponseBodyData = None,
        request_id: str = None,
    ):
        # The queried Spark log configuration.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkConfigLogPathResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkConfigLogPathResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkConfigLogPathResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkConfigLogPathResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkLogAnalyzeTaskRequest(TeaModel):
    def __init__(
        self,
        task_id: int = None,
    ):
        # The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs of all Spark log analysis tasks that are submitted in the current cluster.
        # 
        # This parameter is required.
        self.task_id = task_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.task_id is not None:
            result['TaskId'] = self.task_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('TaskId') is not None:
            self.task_id = m.get('TaskId')
        return self


class GetSparkLogAnalyzeTaskResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkAnalyzeLogTask = None,
        request_id: str = None,
    ):
        # The information about the Spark log analysis task.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkAnalyzeLogTask()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkLogAnalyzeTaskResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkLogAnalyzeTaskResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkLogAnalyzeTaskResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkReplSessionRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        session_id: int = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query all application IDs.
        self.app_id = app_id
        # The ID of the session that executes the code.
        # 
        # This parameter is required.
        self.session_id = session_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        return self


class GetSparkReplSessionResponseBodyData(TeaModel):
    def __init__(
        self,
        active: str = None,
        aliyun_uid: str = None,
        attempt_id: str = None,
        error: str = None,
        session_id: int = None,
        state: str = None,
        web_ui_address: str = None,
    ):
        # Indicates whether the session is active. Valid values:
        # 
        # *   true
        # *   false
        self.active = active
        # The ID of the Alibaba Cloud account that owns the cluster.
        self.aliyun_uid = aliyun_uid
        # The attempt ID of the Spark application.
        self.attempt_id = attempt_id
        # The error message.
        self.error = error
        # The ID of the session that executes the code.
        self.session_id = session_id
        # The status of the session. Valid values:
        # 
        # *   IDLE
        # *   BUSY
        # *   DEAD
        self.state = state
        # The URL of the web UI for the Spark application.
        self.web_ui_address = web_ui_address

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active is not None:
            result['Active'] = self.active
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.attempt_id is not None:
            result['AttemptId'] = self.attempt_id
        if self.error is not None:
            result['Error'] = self.error
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        if self.state is not None:
            result['State'] = self.state
        if self.web_ui_address is not None:
            result['WebUiAddress'] = self.web_ui_address
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Active') is not None:
            self.active = m.get('Active')
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('AttemptId') is not None:
            self.attempt_id = m.get('AttemptId')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('WebUiAddress') is not None:
            self.web_ui_address = m.get('WebUiAddress')
        return self


class GetSparkReplSessionResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkReplSessionResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkReplSessionResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkReplSessionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkReplSessionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkReplSessionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkReplStatementRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        session_id: int = None,
        statement_id: int = None,
    ):
        # The application ID.
        # 
        # >  You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query Spark application IDs.
        self.app_id = app_id
        # The ID of the session that executes the code.
        self.session_id = session_id
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class GetSparkReplStatementResponseBodyData(TeaModel):
    def __init__(
        self,
        aliyun_uid: int = None,
        code: str = None,
        code_state: str = None,
        code_type: str = None,
        columns: List[str] = None,
        end_time: int = None,
        error: str = None,
        output: str = None,
        output_type: str = None,
        start_time: int = None,
        statement_id: int = None,
    ):
        # The ID of the Alibaba Cloud account that owns the cluster.
        self.aliyun_uid = aliyun_uid
        # The code that is executed.
        self.code = code
        # The code execution status. Valid values:
        # 
        # *   CANCELLED
        # *   RUNNING
        # *   SUCCEEDED
        # *   ERROR
        self.code_state = code_state
        # The code type. Valid values:
        # 
        # *   PYTHON
        # *   SCALA
        self.code_type = code_type
        # The column names.
        self.columns = columns
        # The end time of the query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.end_time = end_time
        # The error message.
        self.error = error
        # The code execution result, which is a JSON string.
        self.output = output
        # The execution result type.
        # 
        # Valid values:
        # 
        # *   TABLE
        # *   TEXT
        self.output_type = output_type
        # The start time of the query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        self.start_time = start_time
        # The unique ID of the code block in the Spark job.
        self.statement_id = statement_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.code is not None:
            result['Code'] = self.code
        if self.code_state is not None:
            result['CodeState'] = self.code_state
        if self.code_type is not None:
            result['CodeType'] = self.code_type
        if self.columns is not None:
            result['Columns'] = self.columns
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.error is not None:
            result['Error'] = self.error
        if self.output is not None:
            result['Output'] = self.output
        if self.output_type is not None:
            result['OutputType'] = self.output_type
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.statement_id is not None:
            result['StatementId'] = self.statement_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('CodeState') is not None:
            self.code_state = m.get('CodeState')
        if m.get('CodeType') is not None:
            self.code_type = m.get('CodeType')
        if m.get('Columns') is not None:
            self.columns = m.get('Columns')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('OutputType') is not None:
            self.output_type = m.get('OutputType')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StatementId') is not None:
            self.statement_id = m.get('StatementId')
        return self


class GetSparkReplStatementResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkReplStatementResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkReplStatementResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkReplStatementResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkReplStatementResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkReplStatementResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkSQLEngineStateRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        resource_group_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the job resource group.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class GetSparkSQLEngineStateResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        config: str = None,
        jars: str = None,
        max_executor: str = None,
        min_executor: str = None,
        slot_num: str = None,
        state: str = None,
        submitted_time_in_millis: str = None,
    ):
        # The ID of the Spark application.
        self.app_id = app_id
        # The configuration of the Spark application.
        self.config = config
        # The third-party JAR package.
        self.jars = jars
        # The maximum number of started Spark executors.
        self.max_executor = max_executor
        # The minimum number of started Spark executors.
        self.min_executor = min_executor
        # The slot number of the Spark application.
        self.slot_num = slot_num
        # The execution state of the application. Valid values:
        # 
        # *   SUBMITTED
        # *   STARTING
        # *   RUNNING
        # *   FAILING
        # *   FAILED
        # *   KILLING
        # *   KILLED
        # *   SUCCEEDING
        # *   COMPLETED
        # *   FATAL
        # *   UNKNOWN
        self.state = state
        # The timestamp when the Spark SQL application was submitted. Unit: milliseconds.
        self.submitted_time_in_millis = submitted_time_in_millis

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.config is not None:
            result['Config'] = self.config
        if self.jars is not None:
            result['Jars'] = self.jars
        if self.max_executor is not None:
            result['MaxExecutor'] = self.max_executor
        if self.min_executor is not None:
            result['MinExecutor'] = self.min_executor
        if self.slot_num is not None:
            result['SlotNum'] = self.slot_num
        if self.state is not None:
            result['State'] = self.state
        if self.submitted_time_in_millis is not None:
            result['SubmittedTimeInMillis'] = self.submitted_time_in_millis
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('Config') is not None:
            self.config = m.get('Config')
        if m.get('Jars') is not None:
            self.jars = m.get('Jars')
        if m.get('MaxExecutor') is not None:
            self.max_executor = m.get('MaxExecutor')
        if m.get('MinExecutor') is not None:
            self.min_executor = m.get('MinExecutor')
        if m.get('SlotNum') is not None:
            self.slot_num = m.get('SlotNum')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('SubmittedTimeInMillis') is not None:
            self.submitted_time_in_millis = m.get('SubmittedTimeInMillis')
        return self


class GetSparkSQLEngineStateResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkSQLEngineStateResponseBodyData = None,
        request_id: str = None,
    ):
        # The state information about the Spark SQL engine.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkSQLEngineStateResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkSQLEngineStateResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkSQLEngineStateResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkSQLEngineStateResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkTemplateFileContentRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        id: int = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The application template ID.
        # 
        # >  You can call the [GetSparkTemplateFullTree](https://help.aliyun.com/document_detail/456205.html) operation to query the application template ID.
        # 
        # This parameter is required.
        self.id = id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.id is not None:
            result['Id'] = self.id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        return self


class GetSparkTemplateFileContentResponseBodyData(TeaModel):
    def __init__(
        self,
        app_type: str = None,
        content: str = None,
        id: int = None,
        resource_group_name: str = None,
        type: str = None,
    ):
        # The application type. Valid values:
        # 
        # *   **SQL**\
        # *   **STREAMING**\
        # *   **BATCH**\
        self.app_type = app_type
        # The content of the application template.
        self.content = content
        # The application template ID.
        self.id = id
        # The name of the resource group.
        self.resource_group_name = resource_group_name
        # The file type. Valid values:
        # 
        # *   **folder**\
        # *   **file**\
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_type is not None:
            result['AppType'] = self.app_type
        if self.content is not None:
            result['Content'] = self.content
        if self.id is not None:
            result['Id'] = self.id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppType') is not None:
            self.app_type = m.get('AppType')
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class GetSparkTemplateFileContentResponseBody(TeaModel):
    def __init__(
        self,
        data: GetSparkTemplateFileContentResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetSparkTemplateFileContentResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkTemplateFileContentResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkTemplateFileContentResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkTemplateFileContentResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkTemplateFolderTreeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkTemplateFolderTreeResponseBody(TeaModel):
    def __init__(
        self,
        data: str = None,
        request_id: str = None,
    ):
        # The directory structure of Spark applications, which is in the tree format. Fields in the response parameter:
        # 
        # *   **Uid**: the UID of the Alibaba Cloud account.
        # 
        # *   **Type**: the application template type. Valid values: **FOLDER**\
        # 
        # *   **Parent**: indicates whether a child directory exists. Valid values:
        # 
        #     *   **0**: no.
        #     *   **-1**: yes.
        # 
        # *   **Children**: the child directory.
        # 
        # *   **LastModified**: the time when applications in the directory are last modified. This value is a UNIX timestamp representing the number of seconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # *   **Name**: the name of the directory.
        # 
        # *   **Id**: the directory ID.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkTemplateFolderTreeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkTemplateFolderTreeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkTemplateFolderTreeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkTemplateFullTreeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class GetSparkTemplateFullTreeResponseBody(TeaModel):
    def __init__(
        self,
        data: str = None,
        request_id: str = None,
    ):
        # The directory structure of Spark applications. Fields in the response parameter:
        # 
        # *   **Uid**: the UID of the Alibaba Cloud account.
        # 
        # *   **Type**: the application template type. Valid values:
        # 
        #     *   **FOLDER**\
        #     *   **FILE**\
        # 
        # *   **Parent**: indicates whether a child directory exists. Valid values:
        # 
        #     *   **0**: no.
        #     *   **-1**: yes.
        # 
        # *   **Children**: the child directory.
        # 
        # *   **LastModified**: the time when applications are last modified. This value is a UNIX timestamp representing the number of seconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # *   **AppType**: the application type. Valid values:
        # 
        #     *   **SQL**\
        #     *   **STREAMING**\
        #     *   **BATCH**\
        # 
        # *   **Name**: the name of the directory or application.
        # 
        # *   **Id**: the directory ID or application ID.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkTemplateFullTreeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkTemplateFullTreeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkTemplateFullTreeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetSparkWarehouseBatchSQLRequest(TeaModel):
    def __init__(
        self,
        agency: str = None,
        dbcluster_id: str = None,
        query_id: str = None,
    ):
        # The name of the client, which can be up to 16 characters in length. Specify a descriptive name that makes it easy to identify.
        self.agency = agency
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The query ID of the Spark SQL statement.
        # 
        # This parameter is required.
        self.query_id = query_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.agency is not None:
            result['Agency'] = self.agency
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.query_id is not None:
            result['QueryId'] = self.query_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Agency') is not None:
            self.agency = m.get('Agency')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('QueryId') is not None:
            self.query_id = m.get('QueryId')
        return self


class GetSparkWarehouseBatchSQLResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkBatchSQL = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkBatchSQL()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GetSparkWarehouseBatchSQLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetSparkWarehouseBatchSQLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetSparkWarehouseBatchSQLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetTableRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        db_name: str = None,
        region_id: str = None,
        table_name: str = None,
    ):
        # The ID of the cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database.
        self.db_name = db_name
        # The ID of the region in which the cluster resides.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class GetTableResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
        table: TableModel = None,
    ):
        # The error code returned.
        self.code = code
        # The error message returned.
        self.message = message
        # The ID of the request.
        self.request_id = request_id
        # Indicates whether the query succeeded.
        self.success = success
        # The information about the table.
        self.table = table

    def validate(self):
        if self.table:
            self.table.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.table is not None:
            result['Table'] = self.table.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('Table') is not None:
            temp_model = TableModel()
            self.table = temp_model.from_map(m['Table'])
        return self


class GetTableResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetTableResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetTableResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetTableColumnsRequest(TeaModel):
    def __init__(
        self,
        column_name: str = None,
        dbcluster_id: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The name of the column.
        self.column_name = column_name
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column_name is not None:
            result['ColumnName'] = self.column_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ColumnName') is not None:
            self.column_name = m.get('ColumnName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class GetTableColumnsResponseBodyData(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        table: TableDetailModel = None,
        total_count: int = None,
    ):
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The information about the table.
        self.table = table
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.table:
            self.table.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.table is not None:
            result['Table'] = self.table.to_map()
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('Table') is not None:
            temp_model = TableDetailModel()
            self.table = temp_model.from_map(m['Table'])
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetTableColumnsResponseBody(TeaModel):
    def __init__(
        self,
        data: GetTableColumnsResponseBodyData = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The returned data.
        self.data = data
        # The page number. Pages start from page 1. Default value: 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetTableColumnsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetTableColumnsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetTableColumnsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetTableColumnsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetTableDDLRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema_name: str = None,
        table_name: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the table.
        self.table_name = table_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.table_name is not None:
            result['TableName'] = self.table_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        return self


class GetTableDDLResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        sql: str = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The SQL statement.
        self.sql = sql

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.sql is not None:
            result['SQL'] = self.sql
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        return self


class GetTableDDLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetTableDDLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetTableDDLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetTableObjectsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        filter_description: str = None,
        filter_owner: str = None,
        filter_tbl_name: str = None,
        filter_tbl_type: str = None,
        order_by: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        schema_name: str = None,
    ):
        # The ID of the cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The description of the table.
        self.filter_description = filter_description
        # The owner of the table.
        self.filter_owner = filter_owner
        # The name of the table.
        self.filter_tbl_name = filter_tbl_name
        # The type of the table.
        # 
        # Valid values:
        # 
        # DIMENSION_TABLE
        # 
        # FACT_TABLE
        # 
        # EXTERNAL_TABLE
        # 
        # Default value: null.
        self.filter_tbl_type = filter_tbl_type
        # The order in which the fields to be returned are sorted.
        # 
        # Valid values:
        # 
        # *   Asc
        # *   Desc
        # 
        # Values for fields:
        # 
        # TableName
        # 
        # TableSize
        # 
        # CreateTime
        # 
        # UpdateTime
        # 
        # Default value: {"Type": "Desc","Field": "TableName"};
        self.order_by = order_by
        # The number of the page to return. The value is an integer that is greater than 0. Default value: **1**.
        self.page_number = page_number
        # The number of entries to return on each page. Valid values:
        # 
        # *   30
        # *   50
        # *   100
        # 
        # Default value: 30.
        self.page_size = page_size
        # The ID of the region in which the cluster resides.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.filter_description is not None:
            result['FilterDescription'] = self.filter_description
        if self.filter_owner is not None:
            result['FilterOwner'] = self.filter_owner
        if self.filter_tbl_name is not None:
            result['FilterTblName'] = self.filter_tbl_name
        if self.filter_tbl_type is not None:
            result['FilterTblType'] = self.filter_tbl_type
        if self.order_by is not None:
            result['OrderBy'] = self.order_by
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FilterDescription') is not None:
            self.filter_description = m.get('FilterDescription')
        if m.get('FilterOwner') is not None:
            self.filter_owner = m.get('FilterOwner')
        if m.get('FilterTblName') is not None:
            self.filter_tbl_name = m.get('FilterTblName')
        if m.get('FilterTblType') is not None:
            self.filter_tbl_type = m.get('FilterTblType')
        if m.get('OrderBy') is not None:
            self.order_by = m.get('OrderBy')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        return self


class GetTableObjectsResponseBodyData(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        table_summary_models: List[TableSummaryModel] = None,
        total_count: int = None,
    ):
        # The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.
        self.page_number = page_number
        # The number of entries returned per page. Default value: 30. Valid values:
        # 
        # *   **30**\
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # Details of the tables.
        self.table_summary_models = table_summary_models
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.table_summary_models:
            for k in self.table_summary_models:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        result['TableSummaryModels'] = []
        if self.table_summary_models is not None:
            for k in self.table_summary_models:
                result['TableSummaryModels'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        self.table_summary_models = []
        if m.get('TableSummaryModels') is not None:
            for k in m.get('TableSummaryModels'):
                temp_model = TableSummaryModel()
                self.table_summary_models.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetTableObjectsResponseBody(TeaModel):
    def __init__(
        self,
        data: GetTableObjectsResponseBodyData = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The data returned.
        self.data = data
        # The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.
        self.page_number = page_number
        # The number of entries returned per page. Default value: 30. Valid values:
        # 
        # *   **30**\
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The ID of the request.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetTableObjectsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetTableObjectsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetTableObjectsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetTableObjectsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetViewDDLRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        schema_name: str = None,
        view_name: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        # The name of the view.
        self.view_name = view_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class GetViewDDLResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        sql: str = None,
    ):
        # The request ID.
        self.request_id = request_id
        # The SQL statement.
        self.sql = sql

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.sql is not None:
            result['SQL'] = self.sql
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        return self


class GetViewDDLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetViewDDLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetViewDDLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GetViewObjectsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        filter_owner: str = None,
        filter_view_name: str = None,
        filter_view_type: str = None,
        order_by: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        schema_name: str = None,
        show_mv_base_table: bool = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The owner of the view.
        self.filter_owner = filter_owner
        # The name of the view.
        self.filter_view_name = filter_view_name
        # The type of the view.
        # 
        # Valid values:
        # 
        # \\-VIRTUAL_VIEW
        # 
        # \\-MATERIALIZED_VIEW
        # 
        # Default value: null.
        self.filter_view_type = filter_view_type
        # The order in which you want to sort the query results. Valid values for Type:
        # 
        # *   Asc
        # *   Desc
        # 
        # Valid values for Field: -ViewName
        # 
        # \\-CreateTime
        # 
        # \\-UpdateTime
        # 
        # Default value: {"Type": "Desc","Field": "ViewName"}.
        self.order_by = order_by
        # The page number.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the database.
        self.schema_name = schema_name
        self.show_mv_base_table = show_mv_base_table

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.filter_owner is not None:
            result['FilterOwner'] = self.filter_owner
        if self.filter_view_name is not None:
            result['FilterViewName'] = self.filter_view_name
        if self.filter_view_type is not None:
            result['FilterViewType'] = self.filter_view_type
        if self.order_by is not None:
            result['OrderBy'] = self.order_by
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.schema_name is not None:
            result['SchemaName'] = self.schema_name
        if self.show_mv_base_table is not None:
            result['ShowMvBaseTable'] = self.show_mv_base_table
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('FilterOwner') is not None:
            self.filter_owner = m.get('FilterOwner')
        if m.get('FilterViewName') is not None:
            self.filter_view_name = m.get('FilterViewName')
        if m.get('FilterViewType') is not None:
            self.filter_view_type = m.get('FilterViewType')
        if m.get('OrderBy') is not None:
            self.order_by = m.get('OrderBy')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SchemaName') is not None:
            self.schema_name = m.get('SchemaName')
        if m.get('ShowMvBaseTable') is not None:
            self.show_mv_base_table = m.get('ShowMvBaseTable')
        return self


class GetViewObjectsResponseBodyData(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        table_summary_models: List[TableSummaryModel] = None,
        total_count: int = None,
    ):
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The queried views.
        self.table_summary_models = table_summary_models
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.table_summary_models:
            for k in self.table_summary_models:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        result['TableSummaryModels'] = []
        if self.table_summary_models is not None:
            for k in self.table_summary_models:
                result['TableSummaryModels'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        self.table_summary_models = []
        if m.get('TableSummaryModels') is not None:
            for k in m.get('TableSummaryModels'):
                temp_model = TableSummaryModel()
                self.table_summary_models.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetViewObjectsResponseBody(TeaModel):
    def __init__(
        self,
        data: GetViewObjectsResponseBodyData = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The returned data.
        self.data = data
        # The page number. Pages start from page 1. Default value: **1**.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = GetViewObjectsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class GetViewObjectsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GetViewObjectsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GetViewObjectsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class GrantOperatorPermissionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        expired_time: str = None,
        owner_account: str = None,
        owner_id: int = None,
        privileges: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The expiration time of the service account permissions. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # This parameter is required.
        self.expired_time = expired_time
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The name of the permissions. Valid values:
        # 
        # *   **Control**: the configuration permissions. The service account is granted the permissions to query and modify cluster configurations.
        # *   **Data**: the data permissions. The service account is granted the permissions to query schemas, indexes, and SQL statements.
        # 
        # This parameter is required.
        self.privileges = privileges
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.expired_time is not None:
            result['ExpiredTime'] = self.expired_time
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.privileges is not None:
            result['Privileges'] = self.privileges
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ExpiredTime') is not None:
            self.expired_time = m.get('ExpiredTime')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Privileges') is not None:
            self.privileges = m.get('Privileges')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class GrantOperatorPermissionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class GrantOperatorPermissionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: GrantOperatorPermissionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = GrantOperatorPermissionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class KillProcessRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        process_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The query ID.
        # 
        # >  You can call the [DescribeProcessList](https://help.aliyun.com/document_detail/612277.html) operation to query the IDs of queries that are being executed.
        self.process_id = process_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class KillProcessResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        request_id: str = None,
    ):
        # The details about the access denial.
        self.access_denied_detail = access_denied_detail
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class KillProcessResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: KillProcessResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = KillProcessResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class KillSparkAppRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
    ):
        # The ID of the Spark application that you want to terminate.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class KillSparkAppResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        app_name: str = None,
        dbcluster_id: str = None,
        message: str = None,
        state: str = None,
    ):
        # The Spark application ID.
        self.app_id = app_id
        # The name of the application.
        self.app_name = app_name
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The error message returned.
        self.message = message
        # The execution state of the Spark application. Valid values:
        # 
        # *   **SUBMITTED**\
        # *   **STARTING**\
        # *   **RUNNING**\
        # *   **FAILING**\
        # *   **FAILED**\
        # *   **KILLING**\
        # *   **KILLED**\
        # *   **SUCCEEDING**\
        # *   **COMPLETED**\
        # *   **FATAL**\
        # *   **UNKNOWN**\
        self.state = state

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.app_name is not None:
            result['AppName'] = self.app_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.message is not None:
            result['Message'] = self.message
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AppName') is not None:
            self.app_name = m.get('AppName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class KillSparkAppResponseBody(TeaModel):
    def __init__(
        self,
        data: KillSparkAppResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = KillSparkAppResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class KillSparkAppResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: KillSparkAppResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = KillSparkAppResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class KillSparkLogAnalyzeTaskRequest(TeaModel):
    def __init__(
        self,
        task_id: int = None,
    ):
        # The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs and states of all analysis tasks in the current cluster.
        # 
        # This parameter is required.
        self.task_id = task_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.task_id is not None:
            result['TaskId'] = self.task_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('TaskId') is not None:
            self.task_id = m.get('TaskId')
        return self


class KillSparkLogAnalyzeTaskResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkAnalyzeLogTask = None,
        request_id: str = None,
    ):
        # The information about the Spark log analysis task.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkAnalyzeLogTask()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class KillSparkLogAnalyzeTaskResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: KillSparkLogAnalyzeTaskResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = KillSparkLogAnalyzeTaskResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class KillSparkSQLEngineRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        resource_group_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class KillSparkSQLEngineResponseBody(TeaModel):
    def __init__(
        self,
        data: bool = None,
        request_id: str = None,
    ):
        # Indicates whether the request was successful.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class KillSparkSQLEngineResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: KillSparkSQLEngineResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = KillSparkSQLEngineResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListApsLifecycleStrategyRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        page_number: str = None,
        page_size: str = None,
        region_id: str = None,
        start_time: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        self.end_time = end_time
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        self.start_time = start_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        return self


class ListApsLifecycleStrategyResponseBodyItemsOperationTables(TeaModel):
    def __init__(
        self,
        database_name: str = None,
        process_all: str = None,
        table_names: List[str] = None,
    ):
        # The name of the database.
        self.database_name = database_name
        # Indicates whether all tables in the database are selected.
        self.process_all = process_all
        # The names of the tables.
        self.table_names = table_names

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.database_name is not None:
            result['DatabaseName'] = self.database_name
        if self.process_all is not None:
            result['ProcessAll'] = self.process_all
        if self.table_names is not None:
            result['TableNames'] = self.table_names
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DatabaseName') is not None:
            self.database_name = m.get('DatabaseName')
        if m.get('ProcessAll') is not None:
            self.process_all = m.get('ProcessAll')
        if m.get('TableNames') is not None:
            self.table_names = m.get('TableNames')
        return self


class ListApsLifecycleStrategyResponseBodyItems(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        created_time: str = None,
        dbcluster_id: str = None,
        modified_time: str = None,
        operation_tables: List[ListApsLifecycleStrategyResponseBodyItemsOperationTables] = None,
        status: str = None,
        strategy_databases: int = None,
        strategy_desc: str = None,
        strategy_name: str = None,
        strategy_tables: int = None,
        strategy_type: str = None,
        strategy_value: str = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The time when the policy was created.
        self.created_time = created_time
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The time when the policy was modified.
        self.modified_time = modified_time
        # The operation tables.
        self.operation_tables = operation_tables
        # The status of the lifecycle management policy. Valid values:
        # 
        # 1.  on: enables the current policy.
        # 2.  off: disables the current policy.
        self.status = status
        # The number of databases that are managed during the lifecycle management.
        self.strategy_databases = strategy_databases
        # The description of the lifecycle management policy.
        self.strategy_desc = strategy_desc
        # The name of the lifecycle management policy.
        self.strategy_name = strategy_name
        # The number of tables that are managed during the lifecycle management.
        self.strategy_tables = strategy_tables
        # The type of the lifecycle management policy.
        self.strategy_type = strategy_type
        # The value of the lifecycle management policy.
        self.strategy_value = strategy_value

    def validate(self):
        if self.operation_tables:
            for k in self.operation_tables:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.created_time is not None:
            result['CreatedTime'] = self.created_time
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.modified_time is not None:
            result['ModifiedTime'] = self.modified_time
        result['OperationTables'] = []
        if self.operation_tables is not None:
            for k in self.operation_tables:
                result['OperationTables'].append(k.to_map() if k else None)
        if self.status is not None:
            result['Status'] = self.status
        if self.strategy_databases is not None:
            result['StrategyDatabases'] = self.strategy_databases
        if self.strategy_desc is not None:
            result['StrategyDesc'] = self.strategy_desc
        if self.strategy_name is not None:
            result['StrategyName'] = self.strategy_name
        if self.strategy_tables is not None:
            result['StrategyTables'] = self.strategy_tables
        if self.strategy_type is not None:
            result['StrategyType'] = self.strategy_type
        if self.strategy_value is not None:
            result['StrategyValue'] = self.strategy_value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('CreatedTime') is not None:
            self.created_time = m.get('CreatedTime')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ModifiedTime') is not None:
            self.modified_time = m.get('ModifiedTime')
        self.operation_tables = []
        if m.get('OperationTables') is not None:
            for k in m.get('OperationTables'):
                temp_model = ListApsLifecycleStrategyResponseBodyItemsOperationTables()
                self.operation_tables.append(temp_model.from_map(k))
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('StrategyDatabases') is not None:
            self.strategy_databases = m.get('StrategyDatabases')
        if m.get('StrategyDesc') is not None:
            self.strategy_desc = m.get('StrategyDesc')
        if m.get('StrategyName') is not None:
            self.strategy_name = m.get('StrategyName')
        if m.get('StrategyTables') is not None:
            self.strategy_tables = m.get('StrategyTables')
        if m.get('StrategyType') is not None:
            self.strategy_type = m.get('StrategyType')
        if m.get('StrategyValue') is not None:
            self.strategy_value = m.get('StrategyValue')
        return self


class ListApsLifecycleStrategyResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        http_status_code: int = None,
        items: List[ListApsLifecycleStrategyResponseBodyItems] = None,
        message: str = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        success: bool = None,
        total_count: int = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The queried lifecycle management policies.
        self.items = items
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = ListApsLifecycleStrategyResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListApsLifecycleStrategyResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListApsLifecycleStrategyResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListApsLifecycleStrategyResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListApsOptimizationStrategyRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ListApsOptimizationStrategyResponseBodyData(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        status: str = None,
        strategy_desc: str = None,
        strategy_name: str = None,
        strategy_type: str = None,
    ):
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The status of the lifecycle management policy. Valid values:
        # 
        # 1.  on: enabled.
        # 2.  off: disabled.
        self.status = status
        # The description of the lifecycle management policy.
        self.strategy_desc = strategy_desc
        # The name of the lifecycle management policy.
        self.strategy_name = strategy_name
        # The type of the lifecycle management policy. Only StrategyValue is returned.
        self.strategy_type = strategy_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.status is not None:
            result['Status'] = self.status
        if self.strategy_desc is not None:
            result['StrategyDesc'] = self.strategy_desc
        if self.strategy_name is not None:
            result['StrategyName'] = self.strategy_name
        if self.strategy_type is not None:
            result['StrategyType'] = self.strategy_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('StrategyDesc') is not None:
            self.strategy_desc = m.get('StrategyDesc')
        if m.get('StrategyName') is not None:
            self.strategy_name = m.get('StrategyName')
        if m.get('StrategyType') is not None:
            self.strategy_type = m.get('StrategyType')
        return self


class ListApsOptimizationStrategyResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: List[ListApsOptimizationStrategyResponseBodyData] = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The response code.
        self.code = code
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        if self.data:
            for k in self.data:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        result['Data'] = []
        if self.data is not None:
            for k in self.data:
                result['Data'].append(k.to_map() if k else None)
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        self.data = []
        if m.get('Data') is not None:
            for k in m.get('Data'):
                temp_model = ListApsOptimizationStrategyResponseBodyData()
                self.data.append(temp_model.from_map(k))
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class ListApsOptimizationStrategyResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListApsOptimizationStrategyResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListApsOptimizationStrategyResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListApsOptimizationTasksRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        end_time: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
        start_time: str = None,
        strategy_type: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        self.end_time = end_time
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.
        self.start_time = start_time
        # The type of the lifecycle management policy.
        # 
        # This parameter is required.
        self.strategy_type = strategy_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.strategy_type is not None:
            result['StrategyType'] = self.strategy_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StrategyType') is not None:
            self.strategy_type = m.get('StrategyType')
        return self


class ListApsOptimizationTasksResponseBodyItems(TeaModel):
    def __init__(
        self,
        compute_unit: str = None,
        created_time: str = None,
        dbcluster_id: str = None,
        modified_time: str = None,
        strategy_type: str = None,
        task_desc: str = None,
        task_duration: int = None,
        task_id: str = None,
        task_message: str = None,
        task_status: str = None,
    ):
        # The computing resources used by the optimization job.
        self.compute_unit = compute_unit
        # The time when the optimization job was created.
        self.created_time = created_time
        # The cluster ID.
        self.dbcluster_id = dbcluster_id
        # The time when the optimization job was modified.
        self.modified_time = modified_time
        # The type of the lifecycle management policy.
        self.strategy_type = strategy_type
        # The description of the optimization job.
        self.task_desc = task_desc
        # The execution duration of the optimization job.
        self.task_duration = task_duration
        # The job ID.
        self.task_id = task_id
        # The error message.
        self.task_message = task_message
        # The execution status. Valid values:
        # 
        # 1.  NEW
        # 2.  RUNNING
        # 3.  SUCCESS
        # 4.  STOPPED
        # 5.  FAILED
        self.task_status = task_status

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.compute_unit is not None:
            result['ComputeUnit'] = self.compute_unit
        if self.created_time is not None:
            result['CreatedTime'] = self.created_time
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.modified_time is not None:
            result['ModifiedTime'] = self.modified_time
        if self.strategy_type is not None:
            result['StrategyType'] = self.strategy_type
        if self.task_desc is not None:
            result['TaskDesc'] = self.task_desc
        if self.task_duration is not None:
            result['TaskDuration'] = self.task_duration
        if self.task_id is not None:
            result['TaskId'] = self.task_id
        if self.task_message is not None:
            result['TaskMessage'] = self.task_message
        if self.task_status is not None:
            result['TaskStatus'] = self.task_status
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ComputeUnit') is not None:
            self.compute_unit = m.get('ComputeUnit')
        if m.get('CreatedTime') is not None:
            self.created_time = m.get('CreatedTime')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ModifiedTime') is not None:
            self.modified_time = m.get('ModifiedTime')
        if m.get('StrategyType') is not None:
            self.strategy_type = m.get('StrategyType')
        if m.get('TaskDesc') is not None:
            self.task_desc = m.get('TaskDesc')
        if m.get('TaskDuration') is not None:
            self.task_duration = m.get('TaskDuration')
        if m.get('TaskId') is not None:
            self.task_id = m.get('TaskId')
        if m.get('TaskMessage') is not None:
            self.task_message = m.get('TaskMessage')
        if m.get('TaskStatus') is not None:
            self.task_status = m.get('TaskStatus')
        return self


class ListApsOptimizationTasksResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        http_status_code: int = None,
        items: List[ListApsOptimizationTasksResponseBodyItems] = None,
        message: str = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        success: bool = None,
        total_count: int = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The queried optimization jobs.
        self.items = items
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = ListApsOptimizationTasksResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListApsOptimizationTasksResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListApsOptimizationTasksResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListApsOptimizationTasksResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListLakeStoragesRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        filter: str = None,
        page_number: int = None,
        page_size: int = None,
        region_id: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The filter parameters that you want to use to query lake storages. Specify multiple parameters in an AND relationship. For example, if you want to query lake storage whose names are in the range of i-a123, or i-b123, and in the Stopped state, set this parameter to \\&Filter. 1.Name=InstanceName\\&Filter. 1.Value.1=i-a123\\&Filter.1.Value.2=i-b123\\&Filter.2.Name=Status\\&Filter. 2.Value=Stopped.
        self.filter = filter
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.filter is not None:
            result['Filter'] = self.filter
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Filter') is not None:
            self.filter = m.get('Filter')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ListLakeStoragesResponseBodyItemsPermissions(TeaModel):
    def __init__(
        self,
        account: str = None,
        read: bool = None,
        type: str = None,
        write: bool = None,
    ):
        # The database account ID.
        self.account = account
        # The read permissions.
        self.read = read
        # The type of the database account.
        self.type = type
        # The write permissions.
        self.write = write

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account is not None:
            result['Account'] = self.account
        if self.read is not None:
            result['Read'] = self.read
        if self.type is not None:
            result['Type'] = self.type
        if self.write is not None:
            result['Write'] = self.write
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Account') is not None:
            self.account = m.get('Account')
        if m.get('Read') is not None:
            self.read = m.get('Read')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Write') is not None:
            self.write = m.get('Write')
        return self


class ListLakeStoragesResponseBodyItems(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        creator_uid: str = None,
        dbcluster_id: str = None,
        description: str = None,
        file_size: str = None,
        lake_storage_id: str = None,
        operator_uid: str = None,
        owner_uid: str = None,
        permissions: List[ListLakeStoragesResponseBodyItemsPermissions] = None,
        region_id: str = None,
        table_count: int = None,
        total_rows: int = None,
        total_storage: str = None,
        update_time: str = None,
    ):
        # The time when the lake storage was created.
        self.create_time = create_time
        # The creator UID.
        self.creator_uid = creator_uid
        # The ID of the AnalyticDB for MySQL cluster.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The size of data files.
        self.file_size = file_size
        # The unique identifier of the lake storage.
        self.lake_storage_id = lake_storage_id
        # The operator UID.
        self.operator_uid = operator_uid
        # The queried lake storage.
        self.owner_uid = owner_uid
        # The permissions on the lake storage.
        self.permissions = permissions
        # The region ID.
        self.region_id = region_id
        # The number of tables.
        self.table_count = table_count
        # The total number of entries returned.
        self.total_rows = total_rows
        # The total storage size.
        self.total_storage = total_storage
        # The time when the lake storage was last updated.
        self.update_time = update_time

    def validate(self):
        if self.permissions:
            for k in self.permissions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.creator_uid is not None:
            result['CreatorUid'] = self.creator_uid
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        if self.file_size is not None:
            result['FileSize'] = self.file_size
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        if self.operator_uid is not None:
            result['OperatorUid'] = self.operator_uid
        if self.owner_uid is not None:
            result['OwnerUid'] = self.owner_uid
        result['Permissions'] = []
        if self.permissions is not None:
            for k in self.permissions:
                result['Permissions'].append(k.to_map() if k else None)
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.table_count is not None:
            result['TableCount'] = self.table_count
        if self.total_rows is not None:
            result['TotalRows'] = self.total_rows
        if self.total_storage is not None:
            result['TotalStorage'] = self.total_storage
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('CreatorUid') is not None:
            self.creator_uid = m.get('CreatorUid')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('FileSize') is not None:
            self.file_size = m.get('FileSize')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        if m.get('OperatorUid') is not None:
            self.operator_uid = m.get('OperatorUid')
        if m.get('OwnerUid') is not None:
            self.owner_uid = m.get('OwnerUid')
        self.permissions = []
        if m.get('Permissions') is not None:
            for k in m.get('Permissions'):
                temp_model = ListLakeStoragesResponseBodyItemsPermissions()
                self.permissions.append(temp_model.from_map(k))
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('TableCount') is not None:
            self.table_count = m.get('TableCount')
        if m.get('TotalRows') is not None:
            self.total_rows = m.get('TotalRows')
        if m.get('TotalStorage') is not None:
            self.total_storage = m.get('TotalStorage')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class ListLakeStoragesResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        http_status_code: int = None,
        items: List[ListLakeStoragesResponseBodyItems] = None,
        message: str = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        success: bool = None,
        total_count: int = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The queried lake storages.
        self.items = items
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The token that is used for paging when the number of results is greater than the value of MaxResults.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # Indicates whether the dry run succeeds. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = ListLakeStoragesResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListLakeStoragesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListLakeStoragesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListLakeStoragesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListResultExportJobHistoryRequestOrder(TeaModel):
    def __init__(
        self,
        field: str = None,
        type: str = None,
    ):
        # The field that is used to sort the SQL statements. Valid values:
        # 
        # *   CreateTime
        # *   DatabaseUser
        # *   TimeCost
        # *   ResourceGroup
        # *   Status
        # *   Progress
        # *   ExportRows
        self.field = field
        # The sorting order. Valid values (case-insensitive):
        # 
        # *   **Desc**: descending order.
        # *   **Asc**: ascending order.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field is not None:
            result['Field'] = self.field
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Field') is not None:
            self.field = m.get('Field')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class ListResultExportJobHistoryRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        database_user: str = None,
        end_time: str = None,
        order: ListResultExportJobHistoryRequestOrder = None,
        page_number: str = None,
        page_size: str = None,
        region_id: str = None,
        resource_group: str = None,
        start_time: str = None,
        status_list: List[str] = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database account.
        self.database_user = database_user
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # >  The end time must be later than the start time.
        self.end_time = end_time
        # The order in which to sort the SQL statements by field, which contains the `Field` and `Type` fields. Specify the order in the JSON format. Example: `[{"Field":"CreateTimee", "Type": "desc" }]`.
        # 
        # *   `Field` specifies the field that is used to sort the SQL statements. Valid values:
        # 
        #     *   `CreateTime`: the time when the result set export job was created.
        #     *   `Status`: the execution status.
        #     *   `DatabaseUser`: the name of the database account.
        #     *   `TimeCost`: the execution duration.
        #     *   `ResourceGroup`: the name of the resource group.
        #     *   `ExportRows`: the number of exported rows.
        #     *   `Progress`: the export progress.
        # 
        # *   `Type` specifies the sorting order. Valid values (case-insensitive):
        # 
        #     *   `Desc`: descending order.
        #     *   `Asc`: ascending order.
        self.order = order
        # The page number. Pages start from page 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the resource group that runs the result set export jobs. You can use this parameter to query the execution records of export jobs that are run in a specific resource group.
        self.resource_group = resource_group
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        self.start_time = start_time
        # The execution status of result set export jobs. You can use this parameter to query the execution records of export jobs that are in a specific state.
        self.status_list = status_list

    def validate(self):
        if self.order:
            self.order.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database_user is not None:
            result['DatabaseUser'] = self.database_user
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.order is not None:
            result['Order'] = self.order.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status_list is not None:
            result['StatusList'] = self.status_list
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabaseUser') is not None:
            self.database_user = m.get('DatabaseUser')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Order') is not None:
            temp_model = ListResultExportJobHistoryRequestOrder()
            self.order = temp_model.from_map(m['Order'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StatusList') is not None:
            self.status_list = m.get('StatusList')
        return self


class ListResultExportJobHistoryShrinkRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        database_user: str = None,
        end_time: str = None,
        order_shrink: str = None,
        page_number: str = None,
        page_size: str = None,
        region_id: str = None,
        resource_group: str = None,
        start_time: str = None,
        status_list_shrink: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database account.
        self.database_user = database_user
        # The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        # 
        # >  The end time must be later than the start time.
        self.end_time = end_time
        # The order in which to sort the SQL statements by field, which contains the `Field` and `Type` fields. Specify the order in the JSON format. Example: `[{"Field":"CreateTimee", "Type": "desc" }]`.
        # 
        # *   `Field` specifies the field that is used to sort the SQL statements. Valid values:
        # 
        #     *   `CreateTime`: the time when the result set export job was created.
        #     *   `Status`: the execution status.
        #     *   `DatabaseUser`: the name of the database account.
        #     *   `TimeCost`: the execution duration.
        #     *   `ResourceGroup`: the name of the resource group.
        #     *   `ExportRows`: the number of exported rows.
        #     *   `Progress`: the export progress.
        # 
        # *   `Type` specifies the sorting order. Valid values (case-insensitive):
        # 
        #     *   `Desc`: descending order.
        #     *   `Asc`: ascending order.
        self.order_shrink = order_shrink
        # The page number. Pages start from page 1.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **30** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the resource group that runs the result set export jobs. You can use this parameter to query the execution records of export jobs that are run in a specific resource group.
        self.resource_group = resource_group
        # The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.
        self.start_time = start_time
        # The execution status of result set export jobs. You can use this parameter to query the execution records of export jobs that are in a specific state.
        self.status_list_shrink = status_list_shrink

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database_user is not None:
            result['DatabaseUser'] = self.database_user
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.order_shrink is not None:
            result['Order'] = self.order_shrink
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status_list_shrink is not None:
            result['StatusList'] = self.status_list_shrink
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabaseUser') is not None:
            self.database_user = m.get('DatabaseUser')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Order') is not None:
            self.order_shrink = m.get('Order')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StatusList') is not None:
            self.status_list_shrink = m.get('StatusList')
        return self


class ListResultExportJobHistoryResponseBodyItems(TeaModel):
    def __init__(
        self,
        ali_uid: str = None,
        create_time: str = None,
        dbcluster_id: str = None,
        database_user: str = None,
        end_time: str = None,
        engine: str = None,
        export_job_id: str = None,
        export_path: str = None,
        export_rows: str = None,
        export_type: str = None,
        is_expired: bool = None,
        message: str = None,
        process_id: str = None,
        progress: str = None,
        resource_group: str = None,
        schema: str = None,
        sql: str = None,
        start_time: str = None,
        status: str = None,
        time_cost: int = None,
    ):
        # The RAM user ID.
        self.ali_uid = ali_uid
        # The time when the result set export job was created. The time follows the ISO 8601 standard in the *yyyy-mm-ddThh:mm:ssZ* format. The time is displayed in UTC.
        self.create_time = create_time
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        self.dbcluster_id = dbcluster_id
        # The name of the database account that is associated with the RAM user.
        self.database_user = database_user
        # The end time of the result set export job. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.
        # 
        # >  The end time must be later than the start time.
        self.end_time = end_time
        # The engine that is used to execute the result set export job. Only XIHE is returned.
        self.engine = engine
        # The unique identifier of the result set export job.
        self.export_job_id = export_job_id
        # The complete URL of the path to store the exported result set.
        self.export_path = export_path
        # The number of exported rows. This parameter is returned only when the request was successful.
        self.export_rows = export_rows
        # The type of the result set export job.
        self.export_type = export_type
        # Indicates whether the result set export job has expired. Valid values:
        # 
        # *   **false**\
        # *   **true**\
        self.is_expired = is_expired
        # The returned message. This parameter is returned only when the request failed.
        self.message = message
        # The query ID that can be used for diagnostics.
        # 
        # >  You can call the [DescribeDiagnosisSQLInfo](https://help.aliyun.com/document_detail/612337.html) operation to query the execution information about a query.
        self.process_id = process_id
        # The progress of the result set export job. Unit: %. Valid values: 0 to 100.
        self.progress = progress
        # The name of the resource group that runs the result set export job.
        self.resource_group = resource_group
        # The name of the database.
        self.schema = schema
        # The SQL statement that is used in the result set export job.
        self.sql = sql
        # The start time of the result set export job. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.
        self.start_time = start_time
        # The execution status of the result set export job. Valid values:
        # 
        # 1.  **SUBMITTED**\
        # 2.  **RUNNING**\
        # 3.  **SUCCEEDED**\
        # 4.  **FAILED**\
        self.status = status
        # The amount of time consumed to export execution records. Unit: milliseconds.
        # 
        # >  The value is the duration between the time when the result set export job starts and the time when the result set export job ends.
        self.time_cost = time_cost

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.ali_uid is not None:
            result['AliUid'] = self.ali_uid
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.database_user is not None:
            result['DatabaseUser'] = self.database_user
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.export_job_id is not None:
            result['ExportJobId'] = self.export_job_id
        if self.export_path is not None:
            result['ExportPath'] = self.export_path
        if self.export_rows is not None:
            result['ExportRows'] = self.export_rows
        if self.export_type is not None:
            result['ExportType'] = self.export_type
        if self.is_expired is not None:
            result['IsExpired'] = self.is_expired
        if self.message is not None:
            result['Message'] = self.message
        if self.process_id is not None:
            result['ProcessId'] = self.process_id
        if self.progress is not None:
            result['Progress'] = self.progress
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.schema is not None:
            result['Schema'] = self.schema
        if self.sql is not None:
            result['Sql'] = self.sql
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.status is not None:
            result['Status'] = self.status
        if self.time_cost is not None:
            result['TimeCost'] = self.time_cost
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AliUid') is not None:
            self.ali_uid = m.get('AliUid')
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatabaseUser') is not None:
            self.database_user = m.get('DatabaseUser')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('ExportJobId') is not None:
            self.export_job_id = m.get('ExportJobId')
        if m.get('ExportPath') is not None:
            self.export_path = m.get('ExportPath')
        if m.get('ExportRows') is not None:
            self.export_rows = m.get('ExportRows')
        if m.get('ExportType') is not None:
            self.export_type = m.get('ExportType')
        if m.get('IsExpired') is not None:
            self.is_expired = m.get('IsExpired')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('ProcessId') is not None:
            self.process_id = m.get('ProcessId')
        if m.get('Progress') is not None:
            self.progress = m.get('Progress')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        if m.get('Sql') is not None:
            self.sql = m.get('Sql')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TimeCost') is not None:
            self.time_cost = m.get('TimeCost')
        return self


class ListResultExportJobHistoryResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        http_status_code: int = None,
        items: List[ListResultExportJobHistoryResponseBodyItems] = None,
        message: str = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        success: bool = None,
        total_count: int = None,
    ):
        # The HTTP status code.
        self.code = code
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The queried result set export jobs.
        self.items = items
        # The returned message. Valid values:
        # 
        # *   If the request was successful, an **OK** message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.items:
            for k in self.items:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        result['Items'] = []
        if self.items is not None:
            for k in self.items:
                result['Items'].append(k.to_map() if k else None)
        if self.message is not None:
            result['Message'] = self.message
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        self.items = []
        if m.get('Items') is not None:
            for k in m.get('Items'):
                temp_model = ListResultExportJobHistoryResponseBodyItems()
                self.items.append(temp_model.from_map(k))
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListResultExportJobHistoryResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListResultExportJobHistoryResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListResultExportJobHistoryResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListSparkAppAttemptsRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
        page_number: int = None,
        page_size: int = None,
    ):
        # The ID of the Spark application.
        # 
        # > You can call the [ListSparkApps](https://help.aliyun.com/document_detail/455888.html) operation to query all application IDs.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The page number. The value must be an integer that is greater than 0. Default value: **1**.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page. Valid values:
        # 
        # *   **10** (default)
        # *   **50**\
        # *   **100**\
        self.page_size = page_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        return self


class ListSparkAppAttemptsResponseBodyData(TeaModel):
    def __init__(
        self,
        attempt_info_list: List[SparkAttemptInfo] = None,
        page_number: int = None,
        page_size: int = None,
        total_count: int = None,
    ):
        # The queried attempts. Fields in the response parameter:
        # 
        # *   **AttemptId**: the attempt ID.
        # 
        # *   **State**: the state of the Spark application. Valid values:
        # 
        #     *   **SUBMITTED**\
        #     *   **STARTING**\
        #     *   **RUNNING**\
        #     *   **FAILING**\
        #     *   **FAILED**\
        #     *   **KILLING**\
        #     *   **KILLED**\
        #     *   **SUCCEEDING**\
        #     *   **COMPLETED**\
        #     *   **FATAL**\
        #     *   **UNKNOWN**\
        # 
        # *   **Message**: the alert message that is returned. If no alert is generated, null is returned.
        # 
        # *   **Data** the data of the Spark application template.
        # 
        # *   **EstimateExecutionCpuTimeInSeconds**: the amount of time that is required to consume CPU resources for running the Spark application. Unit: milliseconds.
        # 
        # *   **LogRootPath**: the storage path of log files.
        # 
        # *   **LastAttemptId**: the ID of the last attempt.
        # 
        # *   **WebUiAddress**: the web UI URL.
        # 
        # *   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # *   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # *   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # *   **TerminatedTimeInMillis**: the time when the Spark application task was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
        # 
        # *   **DBClusterId**: the ID of the cluster on which the Spark application runs.
        # 
        # *   **ResourceGroupName**: the name of the job resource group.
        # 
        # *   **DurationInMillis**: the amount of time that is required to run the Spark application. Unit: milliseconds.
        self.attempt_info_list = attempt_info_list
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.attempt_info_list:
            for k in self.attempt_info_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AttemptInfoList'] = []
        if self.attempt_info_list is not None:
            for k in self.attempt_info_list:
                result['AttemptInfoList'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.attempt_info_list = []
        if m.get('AttemptInfoList') is not None:
            for k in m.get('AttemptInfoList'):
                temp_model = SparkAttemptInfo()
                self.attempt_info_list.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListSparkAppAttemptsResponseBody(TeaModel):
    def __init__(
        self,
        data: ListSparkAppAttemptsResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = ListSparkAppAttemptsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ListSparkAppAttemptsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListSparkAppAttemptsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListSparkAppAttemptsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListSparkAppsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        filters: str = None,
        page_number: int = None,
        page_size: int = None,
        resource_group_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.filters = filters
        # The number of the page to return. The value must be an integer that is greater than 0. Default value: **1**.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries to return on each page. Default value: 10. Valid values:
        # 
        # - **10**\
        # - **50**\
        # - **100**\
        self.page_size = page_size
        # The name of the job resource group.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.filters is not None:
            result['Filters'] = self.filters
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Filters') is not None:
            self.filters = m.get('Filters')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class ListSparkAppsResponseBodyData(TeaModel):
    def __init__(
        self,
        app_info_list: List[SparkAppInfo] = None,
        page_number: int = None,
        page_size: int = None,
        total_count: int = None,
    ):
        # Details of the applications. Fields in the response parameter:
        # 
        # - **Data**: the data of the Spark application template.
        # - **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.
        # - **LogRootPath**: the storage path of log files.
        # - **LastAttemptId**: the most recent attempt ID.
        # - **WebUiAddress**: the web UI URL.
        # - **SubmittedTimeInMillis**: the time when the Spark application was submitted. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
        # - **StartedTimeInMillis**: the time when the Spark application was created. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
        # - **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
        # - **TerminatedTimeInMillis**: the time when the Spark application task was terminated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
        # - **DBClusterId**: the ID of the cluster on which the Spark application runs.
        # - **ResourceGroupName**: the name of the job resource group.
        # - **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.
        self.app_info_list = app_info_list
        # The page number of the returned page.
        self.page_number = page_number
        # The number of entries returned per page.
        self.page_size = page_size
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.app_info_list:
            for k in self.app_info_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AppInfoList'] = []
        if self.app_info_list is not None:
            for k in self.app_info_list:
                result['AppInfoList'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.app_info_list = []
        if m.get('AppInfoList') is not None:
            for k in m.get('AppInfoList'):
                temp_model = SparkAppInfo()
                self.app_info_list.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListSparkAppsResponseBody(TeaModel):
    def __init__(
        self,
        data: ListSparkAppsResponseBodyData = None,
        page_number: int = None,
        page_size: int = None,
        request_id: str = None,
        total_count: int = None,
    ):
        # The data returned.
        self.data = data
        # The page number of the returned page.
        self.page_number = page_number
        # The number of entries returned per page.
        self.page_size = page_size
        # The ID of the request.
        self.request_id = request_id
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = ListSparkAppsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListSparkAppsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListSparkAppsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListSparkAppsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListSparkLogAnalyzeTasksRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        page_number: int = None,
        page_size: int = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The page number.
        # 
        # This parameter is required.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        return self


class ListSparkLogAnalyzeTasksResponseBodyData(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        task_list: List[SparkAnalyzeLogTask] = None,
        total_count: int = None,
    ):
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The queried Spark log analysis tasks.
        self.task_list = task_list
        # The total number of entries returned.
        self.total_count = total_count

    def validate(self):
        if self.task_list:
            for k in self.task_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        result['TaskList'] = []
        if self.task_list is not None:
            for k in self.task_list:
                result['TaskList'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        self.task_list = []
        if m.get('TaskList') is not None:
            for k in m.get('TaskList'):
                temp_model = SparkAnalyzeLogTask()
                self.task_list.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class ListSparkLogAnalyzeTasksResponseBody(TeaModel):
    def __init__(
        self,
        data: ListSparkLogAnalyzeTasksResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = ListSparkLogAnalyzeTasksResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ListSparkLogAnalyzeTasksResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListSparkLogAnalyzeTasksResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListSparkLogAnalyzeTasksResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListSparkTemplateFileIdsRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class ListSparkTemplateFileIdsResponseBody(TeaModel):
    def __init__(
        self,
        data: List[int] = None,
        request_id: str = None,
    ):
        # The IDs of Spark template files.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ListSparkTemplateFileIdsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListSparkTemplateFileIdsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListSparkTemplateFileIdsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListSparkWarehouseBatchSQLRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        page_number: int = None,
        page_size: str = None,
        resource_group_name: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The name of the interactive resource group for which the Spark engine is enabled.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class ListSparkWarehouseBatchSQLResponseBodyData(TeaModel):
    def __init__(
        self,
        page_number: int = None,
        page_size: int = None,
        queries: List[SparkBatchSQL] = None,
        total: int = None,
    ):
        # The page number.
        self.page_number = page_number
        # The number of entries per page.
        self.page_size = page_size
        # The queried Spark SQL statements.
        self.queries = queries
        # The total number of entries.
        self.total = total

    def validate(self):
        if self.queries:
            for k in self.queries:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        result['Queries'] = []
        if self.queries is not None:
            for k in self.queries:
                result['Queries'].append(k.to_map() if k else None)
        if self.total is not None:
            result['Total'] = self.total
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        self.queries = []
        if m.get('Queries') is not None:
            for k in m.get('Queries'):
                temp_model = SparkBatchSQL()
                self.queries.append(temp_model.from_map(k))
        if m.get('Total') is not None:
            self.total = m.get('Total')
        return self


class ListSparkWarehouseBatchSQLResponseBody(TeaModel):
    def __init__(
        self,
        data: ListSparkWarehouseBatchSQLResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = ListSparkWarehouseBatchSQLResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ListSparkWarehouseBatchSQLResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListSparkWarehouseBatchSQLResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListSparkWarehouseBatchSQLResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListTagResourcesRequestTag(TeaModel):
    def __init__(
        self,
        key: str = None,
        value: str = None,
    ):
        # The tag key. You can specify N tag keys. The tag key cannot be an empty string. Valid values of N: 1 to 20.
        # 
        # >  You must specify at least one of the ResourceId.N and Tag.N.Key parameters.
        self.key = key
        # The tag value. You can specify N tag values. The tag value can be an empty string. Valid values of N: 1 to 20.
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ListTagResourcesRequest(TeaModel):
    def __init__(
        self,
        next_token: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_id: List[str] = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        resource_type: str = None,
        tag: List[ListTagResourcesRequestTag] = None,
    ):
        # The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.
        self.next_token = next_token
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID. You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The cluster ID. You can specify N cluster IDs. Valid values of N: 1 to 50.
        # 
        # >  You must specify at least one of the ResourceId.N and Tag.N.Key parameters.
        self.resource_id = resource_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The resource type. Set the value to **dbclusterlakeversion**.
        # 
        # This parameter is required.
        self.resource_type = resource_type
        # The tags.
        self.tag = tag

    def validate(self):
        if self.tag:
            for k in self.tag:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_id is not None:
            result['ResourceId'] = self.resource_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        result['Tag'] = []
        if self.tag is not None:
            for k in self.tag:
                result['Tag'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceId') is not None:
            self.resource_id = m.get('ResourceId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        self.tag = []
        if m.get('Tag') is not None:
            for k in m.get('Tag'):
                temp_model = ListTagResourcesRequestTag()
                self.tag.append(temp_model.from_map(k))
        return self


class ListTagResourcesResponseBodyTagResourcesTagResource(TeaModel):
    def __init__(
        self,
        resource_id: str = None,
        resource_type: str = None,
        tag_key: str = None,
        tag_value: str = None,
    ):
        # The cluster ID.
        self.resource_id = resource_id
        # The resource type.
        self.resource_type = resource_type
        # The tag key.
        self.tag_key = tag_key
        # The tag value.
        self.tag_value = tag_value

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.resource_id is not None:
            result['ResourceId'] = self.resource_id
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        if self.tag_key is not None:
            result['TagKey'] = self.tag_key
        if self.tag_value is not None:
            result['TagValue'] = self.tag_value
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ResourceId') is not None:
            self.resource_id = m.get('ResourceId')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        if m.get('TagKey') is not None:
            self.tag_key = m.get('TagKey')
        if m.get('TagValue') is not None:
            self.tag_value = m.get('TagValue')
        return self


class ListTagResourcesResponseBodyTagResources(TeaModel):
    def __init__(
        self,
        tag_resource: List[ListTagResourcesResponseBodyTagResourcesTagResource] = None,
    ):
        self.tag_resource = tag_resource

    def validate(self):
        if self.tag_resource:
            for k in self.tag_resource:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['TagResource'] = []
        if self.tag_resource is not None:
            for k in self.tag_resource:
                result['TagResource'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.tag_resource = []
        if m.get('TagResource') is not None:
            for k in m.get('TagResource'):
                temp_model = ListTagResourcesResponseBodyTagResourcesTagResource()
                self.tag_resource.append(temp_model.from_map(k))
        return self


class ListTagResourcesResponseBody(TeaModel):
    def __init__(
        self,
        next_token: str = None,
        request_id: str = None,
        tag_resources: ListTagResourcesResponseBodyTagResources = None,
    ):
        # A pagination token. It can be used in the next request to retrieve a new page of results.
        self.next_token = next_token
        # The request ID.
        self.request_id = request_id
        # The queried clusters and tags.
        self.tag_resources = tag_resources

    def validate(self):
        if self.tag_resources:
            self.tag_resources.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.tag_resources is not None:
            result['TagResources'] = self.tag_resources.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TagResources') is not None:
            temp_model = ListTagResourcesResponseBodyTagResources()
            self.tag_resources = temp_model.from_map(m['TagResources'])
        return self


class ListTagResourcesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ListTagResourcesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListTagResourcesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class LoadSampleDataSetRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class LoadSampleDataSetResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        request_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class LoadSampleDataSetResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: LoadSampleDataSetResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = LoadSampleDataSetResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyAccountDescriptionRequest(TeaModel):
    def __init__(
        self,
        account_description: str = None,
        account_name: str = None,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The description of the database account.
        # 
        # *   The description cannot start with `http://` or `https://`.
        # *   The description must be 2 to 256 characters in length.
        # 
        # This parameter is required.
        self.account_description = account_description
        # The name of the database account.
        # 
        # >  You can call the [DescribeAccounts](https://help.aliyun.com/document_detail/612430.html) operation to query the information about database accounts of an AnalyticDB for MySQL cluster, including database account names.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_description is not None:
            result['AccountDescription'] = self.account_description
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountDescription') is not None:
            self.account_description = m.get('AccountDescription')
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class ModifyAccountDescriptionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyAccountDescriptionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyAccountDescriptionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyAccountDescriptionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyAccountPrivilegesRequestAccountPrivilegesPrivilegeObject(TeaModel):
    def __init__(
        self,
        column: str = None,
        database: str = None,
        table: str = None,
    ):
        # The columns on which you want to grant permissions. This parameter must be specified when the PrivilegeType parameter is set to Column.
        self.column = column
        # The databases on which you want to grant permissions. This parameter must be specified when the PrivilegeType parameter is set to Database, Table, or Column.
        self.database = database
        # The tables on which you want to grant permissions. This parameter must be specified when the PrivilegeType parameter is set to Table or Column.
        self.table = table

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.column is not None:
            result['Column'] = self.column
        if self.database is not None:
            result['Database'] = self.database
        if self.table is not None:
            result['Table'] = self.table
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Column') is not None:
            self.column = m.get('Column')
        if m.get('Database') is not None:
            self.database = m.get('Database')
        if m.get('Table') is not None:
            self.table = m.get('Table')
        return self


class ModifyAccountPrivilegesRequestAccountPrivileges(TeaModel):
    def __init__(
        self,
        privilege_object: ModifyAccountPrivilegesRequestAccountPrivilegesPrivilegeObject = None,
        privilege_type: str = None,
        privileges: List[str] = None,
    ):
        # The objects on which you want to grant permissions, including databases, tables, and columns.
        self.privilege_object = privilege_object
        # The permission level that you want to assign to the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level that can be assigned to the database account.
        self.privilege_type = privilege_type
        # The permissions that you want to grant to the database account.
        self.privileges = privileges

    def validate(self):
        if self.privilege_object:
            self.privilege_object.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.privilege_object is not None:
            result['PrivilegeObject'] = self.privilege_object.to_map()
        if self.privilege_type is not None:
            result['PrivilegeType'] = self.privilege_type
        if self.privileges is not None:
            result['Privileges'] = self.privileges
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('PrivilegeObject') is not None:
            temp_model = ModifyAccountPrivilegesRequestAccountPrivilegesPrivilegeObject()
            self.privilege_object = temp_model.from_map(m['PrivilegeObject'])
        if m.get('PrivilegeType') is not None:
            self.privilege_type = m.get('PrivilegeType')
        if m.get('Privileges') is not None:
            self.privileges = m.get('Privileges')
        return self


class ModifyAccountPrivilegesRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        account_privileges: List[ModifyAccountPrivilegesRequestAccountPrivileges] = None,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The name of the database account.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The permissions that you want to grant to the database account.
        # 
        # This parameter is required.
        self.account_privileges = account_privileges
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        if self.account_privileges:
            for k in self.account_privileges:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        result['AccountPrivileges'] = []
        if self.account_privileges is not None:
            for k in self.account_privileges:
                result['AccountPrivileges'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        self.account_privileges = []
        if m.get('AccountPrivileges') is not None:
            for k in m.get('AccountPrivileges'):
                temp_model = ModifyAccountPrivilegesRequestAccountPrivileges()
                self.account_privileges.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ModifyAccountPrivilegesShrinkRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        account_privileges_shrink: str = None,
        dbcluster_id: str = None,
        region_id: str = None,
    ):
        # The name of the database account.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The permissions that you want to grant to the database account.
        # 
        # This parameter is required.
        self.account_privileges_shrink = account_privileges_shrink
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.account_privileges_shrink is not None:
            result['AccountPrivileges'] = self.account_privileges_shrink
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('AccountPrivileges') is not None:
            self.account_privileges_shrink = m.get('AccountPrivileges')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ModifyAccountPrivilegesResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyAccountPrivilegesResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyAccountPrivilegesResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyAccountPrivilegesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyApsDatasoureRequestKafkaInfo(TeaModel):
    def __init__(
        self,
        kafka_cluster_id: str = None,
        kafka_topic: str = None,
    ):
        # The ID of the Kafka instance.
        self.kafka_cluster_id = kafka_cluster_id
        # The topic of the Kafka instance.
        self.kafka_topic = kafka_topic

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.kafka_cluster_id is not None:
            result['KafkaClusterId'] = self.kafka_cluster_id
        if self.kafka_topic is not None:
            result['KafkaTopic'] = self.kafka_topic
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('KafkaClusterId') is not None:
            self.kafka_cluster_id = m.get('KafkaClusterId')
        if m.get('KafkaTopic') is not None:
            self.kafka_topic = m.get('KafkaTopic')
        return self


class ModifyApsDatasoureRequestLakehouseId(TeaModel):
    def __init__(
        self,
        security_group: str = None,
        vpc_id: str = None,
        vswitch: str = None,
    ):
        # The name of the security group.
        self.security_group = security_group
        # The virtual private cloud (VPC) ID.
        self.vpc_id = vpc_id
        # The name of the vSwitch.
        self.vswitch = vswitch

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.security_group is not None:
            result['SecurityGroup'] = self.security_group
        if self.vpc_id is not None:
            result['VpcId'] = self.vpc_id
        if self.vswitch is not None:
            result['Vswitch'] = self.vswitch
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('SecurityGroup') is not None:
            self.security_group = m.get('SecurityGroup')
        if m.get('VpcId') is not None:
            self.vpc_id = m.get('VpcId')
        if m.get('Vswitch') is not None:
            self.vswitch = m.get('Vswitch')
        return self


class ModifyApsDatasoureRequestPolarDBMysqlInfo(TeaModel):
    def __init__(
        self,
        connect_url: str = None,
        password: str = None,
        region_id: str = None,
        user_name: str = None,
    ):
        # The parameter is no longer supported.
        self.connect_url = connect_url
        # The parameter is no longer supported.
        self.password = password
        # The parameter is no longer supported.
        self.region_id = region_id
        # The parameter is no longer supported.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connect_url is not None:
            result['ConnectUrl'] = self.connect_url
        if self.password is not None:
            result['Password'] = self.password
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectUrl') is not None:
            self.connect_url = m.get('ConnectUrl')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class ModifyApsDatasoureRequestRdsMysqlInfo(TeaModel):
    def __init__(
        self,
        connect_url: str = None,
        password: str = None,
        region_id: str = None,
        user_name: str = None,
    ):
        # The parameter is no longer supported.
        self.connect_url = connect_url
        # The parameter is no longer supported.
        self.password = password
        # The parameter is no longer supported.
        self.region_id = region_id
        # The parameter is no longer supported.
        self.user_name = user_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connect_url is not None:
            result['ConnectUrl'] = self.connect_url
        if self.password is not None:
            result['Password'] = self.password
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectUrl') is not None:
            self.connect_url = m.get('ConnectUrl')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class ModifyApsDatasoureRequestSlsInfo(TeaModel):
    def __init__(
        self,
        across: bool = None,
        across_role: str = None,
        across_uid: str = None,
        source_region_id: str = None,
    ):
        # Specifies whether to use a cross-account resource as the data source. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.across = across
        # The name of the cross-account role.
        self.across_role = across_role
        # The cross-account UID.
        self.across_uid = across_uid
        # The region ID.
        self.source_region_id = source_region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.across is not None:
            result['Across'] = self.across
        if self.across_role is not None:
            result['AcrossRole'] = self.across_role
        if self.across_uid is not None:
            result['AcrossUid'] = self.across_uid
        if self.source_region_id is not None:
            result['SourceRegionId'] = self.source_region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Across') is not None:
            self.across = m.get('Across')
        if m.get('AcrossRole') is not None:
            self.across_role = m.get('AcrossRole')
        if m.get('AcrossUid') is not None:
            self.across_uid = m.get('AcrossUid')
        if m.get('SourceRegionId') is not None:
            self.source_region_id = m.get('SourceRegionId')
        return self


class ModifyApsDatasoureRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        datasource_description: str = None,
        datasource_id: int = None,
        datasource_name: str = None,
        kafka_info: ModifyApsDatasoureRequestKafkaInfo = None,
        lakehouse_id: ModifyApsDatasoureRequestLakehouseId = None,
        polar_dbmysql_info: ModifyApsDatasoureRequestPolarDBMysqlInfo = None,
        rds_mysql_info: ModifyApsDatasoureRequestRdsMysqlInfo = None,
        region_id: str = None,
        sls_info: ModifyApsDatasoureRequestSlsInfo = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The description of the data source.
        self.datasource_description = datasource_description
        # The data source ID.
        # 
        # This parameter is required.
        self.datasource_id = datasource_id
        # The name of the data source.
        self.datasource_name = datasource_name
        # The information about the Kafka instance.
        self.kafka_info = kafka_info
        # The lakehouse ID.
        self.lakehouse_id = lakehouse_id
        # The parameter is no longer supported.
        self.polar_dbmysql_info = polar_dbmysql_info
        # The parameter is no longer supported.
        self.rds_mysql_info = rds_mysql_info
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The information about Simple Log Service (SLS).
        self.sls_info = sls_info

    def validate(self):
        if self.kafka_info:
            self.kafka_info.validate()
        if self.lakehouse_id:
            self.lakehouse_id.validate()
        if self.polar_dbmysql_info:
            self.polar_dbmysql_info.validate()
        if self.rds_mysql_info:
            self.rds_mysql_info.validate()
        if self.sls_info:
            self.sls_info.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_description is not None:
            result['DatasourceDescription'] = self.datasource_description
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.kafka_info is not None:
            result['KafkaInfo'] = self.kafka_info.to_map()
        if self.lakehouse_id is not None:
            result['LakehouseId'] = self.lakehouse_id.to_map()
        if self.polar_dbmysql_info is not None:
            result['PolarDBMysqlInfo'] = self.polar_dbmysql_info.to_map()
        if self.rds_mysql_info is not None:
            result['RdsMysqlInfo'] = self.rds_mysql_info.to_map()
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.sls_info is not None:
            result['SlsInfo'] = self.sls_info.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceDescription') is not None:
            self.datasource_description = m.get('DatasourceDescription')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('KafkaInfo') is not None:
            temp_model = ModifyApsDatasoureRequestKafkaInfo()
            self.kafka_info = temp_model.from_map(m['KafkaInfo'])
        if m.get('LakehouseId') is not None:
            temp_model = ModifyApsDatasoureRequestLakehouseId()
            self.lakehouse_id = temp_model.from_map(m['LakehouseId'])
        if m.get('PolarDBMysqlInfo') is not None:
            temp_model = ModifyApsDatasoureRequestPolarDBMysqlInfo()
            self.polar_dbmysql_info = temp_model.from_map(m['PolarDBMysqlInfo'])
        if m.get('RdsMysqlInfo') is not None:
            temp_model = ModifyApsDatasoureRequestRdsMysqlInfo()
            self.rds_mysql_info = temp_model.from_map(m['RdsMysqlInfo'])
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SlsInfo') is not None:
            temp_model = ModifyApsDatasoureRequestSlsInfo()
            self.sls_info = temp_model.from_map(m['SlsInfo'])
        return self


class ModifyApsDatasoureShrinkRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        datasource_description: str = None,
        datasource_id: int = None,
        datasource_name: str = None,
        kafka_info_shrink: str = None,
        lakehouse_id_shrink: str = None,
        polar_dbmysql_info_shrink: str = None,
        rds_mysql_info_shrink: str = None,
        region_id: str = None,
        sls_info_shrink: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The description of the data source.
        self.datasource_description = datasource_description
        # The data source ID.
        # 
        # This parameter is required.
        self.datasource_id = datasource_id
        # The name of the data source.
        self.datasource_name = datasource_name
        # The information about the Kafka instance.
        self.kafka_info_shrink = kafka_info_shrink
        # The lakehouse ID.
        self.lakehouse_id_shrink = lakehouse_id_shrink
        # The parameter is no longer supported.
        self.polar_dbmysql_info_shrink = polar_dbmysql_info_shrink
        # The parameter is no longer supported.
        self.rds_mysql_info_shrink = rds_mysql_info_shrink
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The information about Simple Log Service (SLS).
        self.sls_info_shrink = sls_info_shrink

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.datasource_description is not None:
            result['DatasourceDescription'] = self.datasource_description
        if self.datasource_id is not None:
            result['DatasourceId'] = self.datasource_id
        if self.datasource_name is not None:
            result['DatasourceName'] = self.datasource_name
        if self.kafka_info_shrink is not None:
            result['KafkaInfo'] = self.kafka_info_shrink
        if self.lakehouse_id_shrink is not None:
            result['LakehouseId'] = self.lakehouse_id_shrink
        if self.polar_dbmysql_info_shrink is not None:
            result['PolarDBMysqlInfo'] = self.polar_dbmysql_info_shrink
        if self.rds_mysql_info_shrink is not None:
            result['RdsMysqlInfo'] = self.rds_mysql_info_shrink
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.sls_info_shrink is not None:
            result['SlsInfo'] = self.sls_info_shrink
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DatasourceDescription') is not None:
            self.datasource_description = m.get('DatasourceDescription')
        if m.get('DatasourceId') is not None:
            self.datasource_id = m.get('DatasourceId')
        if m.get('DatasourceName') is not None:
            self.datasource_name = m.get('DatasourceName')
        if m.get('KafkaInfo') is not None:
            self.kafka_info_shrink = m.get('KafkaInfo')
        if m.get('LakehouseId') is not None:
            self.lakehouse_id_shrink = m.get('LakehouseId')
        if m.get('PolarDBMysqlInfo') is not None:
            self.polar_dbmysql_info_shrink = m.get('PolarDBMysqlInfo')
        if m.get('RdsMysqlInfo') is not None:
            self.rds_mysql_info_shrink = m.get('RdsMysqlInfo')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('SlsInfo') is not None:
            self.sls_info_shrink = m.get('SlsInfo')
        return self


class ModifyApsDatasoureResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: str = None,
        message: str = None,
        request_id: str = None,
        success: str = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class ModifyApsDatasoureResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyApsDatasoureResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyApsDatasoureResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyApsJobRequest(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        db_list: str = None,
        partition_list: str = None,
        region_id: str = None,
    ):
        # The job ID.
        # 
        # This parameter is required.
        self.aps_job_id = aps_job_id
        # The objects to be synchronized.
        # 
        # This parameter is required.
        self.db_list = db_list
        # The partitions.
        self.partition_list = partition_list
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.db_list is not None:
            result['DbList'] = self.db_list
        if self.partition_list is not None:
            result['PartitionList'] = self.partition_list
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('DbList') is not None:
            self.db_list = m.get('DbList')
        if m.get('PartitionList') is not None:
            self.partition_list = m.get('PartitionList')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ModifyApsJobResponseBody(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        code: str = None,
        err_code: str = None,
        err_message: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The status code. A value of 200 indicates that the request is successful.
        self.code = code
        # The error code.
        self.err_code = err_code
        # The error message returned if the request failed.
        self.err_message = err_message
        # The status code. A value of 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.code is not None:
            result['Code'] = self.code
        if self.err_code is not None:
            result['ErrCode'] = self.err_code
        if self.err_message is not None:
            result['ErrMessage'] = self.err_message
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('ErrCode') is not None:
            self.err_code = m.get('ErrCode')
        if m.get('ErrMessage') is not None:
            self.err_message = m.get('ErrMessage')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class ModifyApsJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyApsJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyApsJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyApsSlsADBJobRequestColumns(TeaModel):
    def __init__(
        self,
        map_name: str = None,
        map_type: str = None,
        name: str = None,
        type: str = None,
    ):
        # The name of the mapping.
        self.map_name = map_name
        # The type of the mapping.
        self.map_type = map_type
        # The name of the column.
        self.name = name
        # The data type of the column.
        self.type = type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.map_name is not None:
            result['MapName'] = self.map_name
        if self.map_type is not None:
            result['MapType'] = self.map_type
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('MapName') is not None:
            self.map_name = m.get('MapName')
        if m.get('MapType') is not None:
            self.map_type = m.get('MapType')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class ModifyApsSlsADBJobRequest(TeaModel):
    def __init__(
        self,
        columns: List[ModifyApsSlsADBJobRequestColumns] = None,
        dbcluster_id: str = None,
        db_name: str = None,
        dirty_data_process_pattern: str = None,
        exactly_once: str = None,
        password: str = None,
        region_id: str = None,
        starting_offsets: str = None,
        table_name: str = None,
        unix_timestamp_convert: str = None,
        user_name: str = None,
        workload_id: str = None,
        workload_name: str = None,
    ):
        # The information about columns.
        self.columns = columns
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database.
        self.db_name = db_name
        # The dirty data processing mode.
        self.dirty_data_process_pattern = dirty_data_process_pattern
        # Specifies whether to enable the consistency check.
        self.exactly_once = exactly_once
        # The password of the database account.
        self.password = password
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The start offset.
        self.starting_offsets = starting_offsets
        # The name of the table.
        self.table_name = table_name
        # The timestamp conversion.
        self.unix_timestamp_convert = unix_timestamp_convert
        # The name of the database account.
        self.user_name = user_name
        # The job ID.
        # 
        # This parameter is required.
        self.workload_id = workload_id
        # The name of the workload.
        self.workload_name = workload_name

    def validate(self):
        if self.columns:
            for k in self.columns:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Columns'] = []
        if self.columns is not None:
            for k in self.columns:
                result['Columns'].append(k.to_map() if k else None)
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.dirty_data_process_pattern is not None:
            result['DirtyDataProcessPattern'] = self.dirty_data_process_pattern
        if self.exactly_once is not None:
            result['ExactlyOnce'] = self.exactly_once
        if self.password is not None:
            result['Password'] = self.password
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.starting_offsets is not None:
            result['StartingOffsets'] = self.starting_offsets
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.unix_timestamp_convert is not None:
            result['UnixTimestampConvert'] = self.unix_timestamp_convert
        if self.user_name is not None:
            result['UserName'] = self.user_name
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.columns = []
        if m.get('Columns') is not None:
            for k in m.get('Columns'):
                temp_model = ModifyApsSlsADBJobRequestColumns()
                self.columns.append(temp_model.from_map(k))
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('DirtyDataProcessPattern') is not None:
            self.dirty_data_process_pattern = m.get('DirtyDataProcessPattern')
        if m.get('ExactlyOnce') is not None:
            self.exactly_once = m.get('ExactlyOnce')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartingOffsets') is not None:
            self.starting_offsets = m.get('StartingOffsets')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('UnixTimestampConvert') is not None:
            self.unix_timestamp_convert = m.get('UnixTimestampConvert')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class ModifyApsSlsADBJobShrinkRequest(TeaModel):
    def __init__(
        self,
        columns_shrink: str = None,
        dbcluster_id: str = None,
        db_name: str = None,
        dirty_data_process_pattern: str = None,
        exactly_once: str = None,
        password: str = None,
        region_id: str = None,
        starting_offsets: str = None,
        table_name: str = None,
        unix_timestamp_convert: str = None,
        user_name: str = None,
        workload_id: str = None,
        workload_name: str = None,
    ):
        # The information about columns.
        self.columns_shrink = columns_shrink
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the database.
        self.db_name = db_name
        # The dirty data processing mode.
        self.dirty_data_process_pattern = dirty_data_process_pattern
        # Specifies whether to enable the consistency check.
        self.exactly_once = exactly_once
        # The password of the database account.
        self.password = password
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The start offset.
        self.starting_offsets = starting_offsets
        # The name of the table.
        self.table_name = table_name
        # The timestamp conversion.
        self.unix_timestamp_convert = unix_timestamp_convert
        # The name of the database account.
        self.user_name = user_name
        # The job ID.
        # 
        # This parameter is required.
        self.workload_id = workload_id
        # The name of the workload.
        self.workload_name = workload_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.columns_shrink is not None:
            result['Columns'] = self.columns_shrink
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.db_name is not None:
            result['DbName'] = self.db_name
        if self.dirty_data_process_pattern is not None:
            result['DirtyDataProcessPattern'] = self.dirty_data_process_pattern
        if self.exactly_once is not None:
            result['ExactlyOnce'] = self.exactly_once
        if self.password is not None:
            result['Password'] = self.password
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.starting_offsets is not None:
            result['StartingOffsets'] = self.starting_offsets
        if self.table_name is not None:
            result['TableName'] = self.table_name
        if self.unix_timestamp_convert is not None:
            result['UnixTimestampConvert'] = self.unix_timestamp_convert
        if self.user_name is not None:
            result['UserName'] = self.user_name
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Columns') is not None:
            self.columns_shrink = m.get('Columns')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DbName') is not None:
            self.db_name = m.get('DbName')
        if m.get('DirtyDataProcessPattern') is not None:
            self.dirty_data_process_pattern = m.get('DirtyDataProcessPattern')
        if m.get('ExactlyOnce') is not None:
            self.exactly_once = m.get('ExactlyOnce')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('StartingOffsets') is not None:
            self.starting_offsets = m.get('StartingOffsets')
        if m.get('TableName') is not None:
            self.table_name = m.get('TableName')
        if m.get('UnixTimestampConvert') is not None:
            self.unix_timestamp_convert = m.get('UnixTimestampConvert')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class ModifyApsSlsADBJobResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: Dict[str, Any] = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The returned data.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class ModifyApsSlsADBJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyApsSlsADBJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyApsSlsADBJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyApsWorkloadNameRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        region_id: str = None,
        workload_id: str = None,
        workload_name: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The region ID.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The job ID.
        # 
        # This parameter is required.
        self.workload_id = workload_id
        # The name of the workload.
        # 
        # This parameter is required.
        self.workload_name = workload_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.workload_id is not None:
            result['WorkloadId'] = self.workload_id
        if self.workload_name is not None:
            result['WorkloadName'] = self.workload_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('WorkloadId') is not None:
            self.workload_id = m.get('WorkloadId')
        if m.get('WorkloadName') is not None:
            self.workload_name = m.get('WorkloadName')
        return self


class ModifyApsWorkloadNameResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The returned data.
        self.data = data
        # The status code. A value of 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class ModifyApsWorkloadNameResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyApsWorkloadNameResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyApsWorkloadNameResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyAuditLogConfigRequest(TeaModel):
    def __init__(
        self,
        audit_log_status: str = None,
        dbcluster_id: str = None,
        engine_type: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The status to which you want to change the SQL audit feature. Valid values:
        # 
        # *   **on**\
        # *   **off**\
        # 
        # >  After you disable the SQL audit feature, all SQL audit logs are deleted. You must query and export SQL audit logs before you disable SQL audit. For more information, see [DescribeAuditLogRecords](https://help.aliyun.com/document_detail/612426.html). When you re-enable SQL audit, audit logs that are generated from the time when SQL audit was last enabled are available for queries.
        # 
        # This parameter is required.
        self.audit_log_status = audit_log_status
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The type of the compute engine. Valid values:
        # 
        # *   XIHE (**default**)
        # *   SPARK
        self.engine_type = engine_type
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.audit_log_status is not None:
            result['AuditLogStatus'] = self.audit_log_status
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine_type is not None:
            result['EngineType'] = self.engine_type
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AuditLogStatus') is not None:
            self.audit_log_status = m.get('AuditLogStatus')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EngineType') is not None:
            self.engine_type = m.get('EngineType')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class ModifyAuditLogConfigResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
        update_succeed: bool = None,
    ):
        # The request ID.
        self.request_id = request_id
        # Indicates whether the status of SQL audit is updated. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.update_succeed = update_succeed

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.update_succeed is not None:
            result['UpdateSucceed'] = self.update_succeed
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('UpdateSucceed') is not None:
            self.update_succeed = m.get('UpdateSucceed')
        return self


class ModifyAuditLogConfigResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyAuditLogConfigResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyAuditLogConfigResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyBackupPolicyRequest(TeaModel):
    def __init__(
        self,
        backup_retention_period: str = None,
        dbcluster_id: str = None,
        enable_backup_log: str = None,
        log_backup_retention_period: int = None,
        owner_account: str = None,
        owner_id: int = None,
        preferred_backup_period: str = None,
        preferred_backup_time: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The number of days for which to retain full backup files. Valid values: 7 to 730.
        # 
        # >  If you do not specify this parameter, the default value 7 is used.
        self.backup_retention_period = backup_retention_period
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable log backup. Valid values:
        # 
        # *   **Enable**\
        # *   **Disable**\
        # 
        # >  If you do not specify this parameter, the default value Enable is used.
        self.enable_backup_log = enable_backup_log
        # The number of days for which to retain log backup files. Valid values: 7 to 730.
        # 
        # >  If you do not specify this parameter, the default value 7 is used.
        self.log_backup_retention_period = log_backup_retention_period
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The days of the week on which to perform a full backup. Separate multiple values with commas (,). Valid values:
        # 
        # *   **Monday**\
        # *   **Tuesday**\
        # *   **Wednesday**\
        # *   **Thursday**\
        # *   **Friday**\
        # *   **Saturday**\
        # *   **Sunday**\
        # 
        # >  To ensure data security, we recommend that you specify at least two values.
        self.preferred_backup_period = preferred_backup_period
        # The start time to perform a full backup. Specify the time in the HH:mmZ-HH:mmZ format. The time must be in UTC.
        # 
        # >  The time range must be 1 hour.
        # 
        # This parameter is required.
        self.preferred_backup_time = preferred_backup_time
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.backup_retention_period is not None:
            result['BackupRetentionPeriod'] = self.backup_retention_period
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_backup_log is not None:
            result['EnableBackupLog'] = self.enable_backup_log
        if self.log_backup_retention_period is not None:
            result['LogBackupRetentionPeriod'] = self.log_backup_retention_period
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.preferred_backup_period is not None:
            result['PreferredBackupPeriod'] = self.preferred_backup_period
        if self.preferred_backup_time is not None:
            result['PreferredBackupTime'] = self.preferred_backup_time
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('BackupRetentionPeriod') is not None:
            self.backup_retention_period = m.get('BackupRetentionPeriod')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableBackupLog') is not None:
            self.enable_backup_log = m.get('EnableBackupLog')
        if m.get('LogBackupRetentionPeriod') is not None:
            self.log_backup_retention_period = m.get('LogBackupRetentionPeriod')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PreferredBackupPeriod') is not None:
            self.preferred_backup_period = m.get('PreferredBackupPeriod')
        if m.get('PreferredBackupTime') is not None:
            self.preferred_backup_time = m.get('PreferredBackupTime')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class ModifyBackupPolicyResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyBackupPolicyResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyBackupPolicyResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyBackupPolicyResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyClickhouseEngineRequest(TeaModel):
    def __init__(
        self,
        cache_size: int = None,
        dbcluster_id: str = None,
        enabled: bool = None,
        owner_id: str = None,
    ):
        # The disk cache size of the wide table engine. Unit: GB. Default value: 100. Valid values: 100 to 1000.
        self.cache_size = cache_size
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the wide table engine feature. Valid values:
        # 
        # - true
        # 
        # - false
        self.enabled = enabled
        self.owner_id = owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cache_size is not None:
            result['CacheSize'] = self.cache_size
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enabled is not None:
            result['Enabled'] = self.enabled
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CacheSize') is not None:
            self.cache_size = m.get('CacheSize')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Enabled') is not None:
            self.enabled = m.get('Enabled')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        return self


class ModifyClickhouseEngineResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyClickhouseEngineResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyClickhouseEngineResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyClickhouseEngineResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyClusterAccessWhiteListRequest(TeaModel):
    def __init__(
        self,
        dbcluster_iparray_attribute: str = None,
        dbcluster_iparray_name: str = None,
        dbcluster_id: str = None,
        modify_mode: str = None,
        security_ips: str = None,
    ):
        # The attribute of the IP address whitelist. By default, this parameter is empty.
        # 
        # >  IP address whitelists with the hidden attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.
        self.dbcluster_iparray_attribute = dbcluster_iparray_attribute
        # The name of the IP address whitelist. If you do not specify this parameter, the Default whitelist is modified.
        # 
        # *   The whitelist name must be 2 to 32 characters in length. The name can contain lowercase letters, digits, and underscores (_). The name must start with a lowercase letter and end with a lowercase letter or a digit.
        # *   Each cluster supports up to 50 IP address whitelists.
        self.dbcluster_iparray_name = dbcluster_iparray_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The method used to modify the IP address whitelist. Valid values:
        # 
        # *   **Cover** (default)
        # *   **Append**\
        # *   **Delete**\
        self.modify_mode = modify_mode
        # The IP addresses in an IP address whitelist of a cluster. Separate multiple IP addresses with commas (,). You can add a maximum of 500 different IP addresses to a whitelist. The entries in the IP address whitelist must be in one of the following formats:
        # 
        # *   IP addresses, such as 10.23.XX.XX.
        # *   CIDR blocks, such as 10.23.xx.xx/24. In this example, 24 indicates that the prefix of each IP address in the IP whitelist is 24 bits in length. You can replace 24 with a value within the range of 1 to 32.
        # 
        # This parameter is required.
        self.security_ips = security_ips

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_iparray_attribute is not None:
            result['DBClusterIPArrayAttribute'] = self.dbcluster_iparray_attribute
        if self.dbcluster_iparray_name is not None:
            result['DBClusterIPArrayName'] = self.dbcluster_iparray_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.modify_mode is not None:
            result['ModifyMode'] = self.modify_mode
        if self.security_ips is not None:
            result['SecurityIps'] = self.security_ips
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterIPArrayAttribute') is not None:
            self.dbcluster_iparray_attribute = m.get('DBClusterIPArrayAttribute')
        if m.get('DBClusterIPArrayName') is not None:
            self.dbcluster_iparray_name = m.get('DBClusterIPArrayName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ModifyMode') is not None:
            self.modify_mode = m.get('ModifyMode')
        if m.get('SecurityIps') is not None:
            self.security_ips = m.get('SecurityIps')
        return self


class ModifyClusterAccessWhiteListResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        request_id: str = None,
        task_id: int = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The request ID.
        self.request_id = request_id
        # The task ID.
        self.task_id = task_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.task_id is not None:
            result['TaskId'] = self.task_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TaskId') is not None:
            self.task_id = m.get('TaskId')
        return self


class ModifyClusterAccessWhiteListResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyClusterAccessWhiteListResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyClusterAccessWhiteListResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyClusterConnectionStringRequest(TeaModel):
    def __init__(
        self,
        connection_string_prefix: str = None,
        current_connection_string: str = None,
        dbcluster_id: str = None,
        port: int = None,
    ):
        # The prefix of the public endpoint.
        # 
        # *   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
        # *   The prefix can be up to 30 characters in length.
        # 
        # This parameter is required.
        self.connection_string_prefix = connection_string_prefix
        # The public endpoint of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.current_connection_string = current_connection_string
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The port number. Set the value to **3306**.
        self.port = port

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connection_string_prefix is not None:
            result['ConnectionStringPrefix'] = self.connection_string_prefix
        if self.current_connection_string is not None:
            result['CurrentConnectionString'] = self.current_connection_string
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.port is not None:
            result['Port'] = self.port
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectionStringPrefix') is not None:
            self.connection_string_prefix = m.get('ConnectionStringPrefix')
        if m.get('CurrentConnectionString') is not None:
            self.current_connection_string = m.get('CurrentConnectionString')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        return self


class ModifyClusterConnectionStringResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyClusterConnectionStringResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyClusterConnectionStringResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyClusterConnectionStringResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyCompactionServiceSwitchRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        enable_compaction_service: bool = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the remote build feature.
        # 
        # Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is required.
        self.enable_compaction_service = enable_compaction_service

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_compaction_service is not None:
            result['EnableCompactionService'] = self.enable_compaction_service
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableCompactionService') is not None:
            self.enable_compaction_service = m.get('EnableCompactionService')
        return self


class ModifyCompactionServiceSwitchResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyCompactionServiceSwitchResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyCompactionServiceSwitchResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyCompactionServiceSwitchResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyDBClusterRequest(TeaModel):
    def __init__(
        self,
        compute_resource: str = None,
        dbcluster_id: str = None,
        enable_default_resource_pool: bool = None,
        product_form: str = None,
        region_id: str = None,
        reserved_node_count: int = None,
        reserved_node_size: str = None,
        storage_resource: str = None,
    ):
        # The reserved computing resources. Valid values: 0ACU to 4096ACU. The value must be in increments of 16ACU. Each ACU is approximately equal to 1 core and 4 GB memory.
        # 
        # >  This parameter must be specified with a unit.
        self.compute_resource = compute_resource
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:
        # 
        # *   true (default)
        # *   false
        self.enable_default_resource_pool = enable_default_resource_pool
        self.product_form = product_form
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        self.region_id = region_id
        self.reserved_node_count = reserved_node_count
        self.reserved_node_size = reserved_node_size
        # The reserved storage resources. Valid values: 0ACU to 2064ACU. The value must be in increments of 24ACU. Each ACU is approximately equal to 1 core and 4 GB memory.
        # 
        # >  This parameter must be specified with a unit.
        self.storage_resource = storage_resource

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.compute_resource is not None:
            result['ComputeResource'] = self.compute_resource
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_default_resource_pool is not None:
            result['EnableDefaultResourcePool'] = self.enable_default_resource_pool
        if self.product_form is not None:
            result['ProductForm'] = self.product_form
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.reserved_node_count is not None:
            result['ReservedNodeCount'] = self.reserved_node_count
        if self.reserved_node_size is not None:
            result['ReservedNodeSize'] = self.reserved_node_size
        if self.storage_resource is not None:
            result['StorageResource'] = self.storage_resource
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ComputeResource') is not None:
            self.compute_resource = m.get('ComputeResource')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableDefaultResourcePool') is not None:
            self.enable_default_resource_pool = m.get('EnableDefaultResourcePool')
        if m.get('ProductForm') is not None:
            self.product_form = m.get('ProductForm')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ReservedNodeCount') is not None:
            self.reserved_node_count = m.get('ReservedNodeCount')
        if m.get('ReservedNodeSize') is not None:
            self.reserved_node_size = m.get('ReservedNodeSize')
        if m.get('StorageResource') is not None:
            self.storage_resource = m.get('StorageResource')
        return self


class ModifyDBClusterResponseBody(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        order_id: str = None,
        request_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        self.dbcluster_id = dbcluster_id
        # The order ID.
        self.order_id = order_id
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.order_id is not None:
            result['OrderId'] = self.order_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OrderId') is not None:
            self.order_id = m.get('OrderId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyDBClusterResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyDBClusterResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyDBClusterResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyDBClusterDescriptionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_description: str = None,
        dbcluster_id: str = None,
    ):
        # The description of the cluster.
        # 
        # *   The description cannot start with `http://` or `https`.
        # *   The description must be 2 to 256 characters in length.
        # 
        # This parameter is required.
        self.dbcluster_description = dbcluster_description
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class ModifyDBClusterDescriptionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyDBClusterDescriptionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyDBClusterDescriptionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyDBClusterDescriptionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyDBClusterMaintainTimeRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        maintain_time: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The maintenance window of the cluster. It must be in the hh:mmZ-hh:mmZ format.
        # 
        # > The interval must be 1 hour and start and end at the beginning of an hour.
        # 
        # This parameter is required.
        self.maintain_time = maintain_time

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.maintain_time is not None:
            result['MaintainTime'] = self.maintain_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('MaintainTime') is not None:
            self.maintain_time = m.get('MaintainTime')
        return self


class ModifyDBClusterMaintainTimeResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyDBClusterMaintainTimeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyDBClusterMaintainTimeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyDBClusterMaintainTimeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyDBClusterResourceGroupRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        new_resource_group_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The ID of the resource group to which you want to move the AnalyticDB for MySQL cluster.
        # 
        # >  You can use resource groups to manage resources within your Alibaba Cloud account by group. This helps you resolve issues such as resource grouping and permission management within a single Alibaba Cloud account. For more information, see [What is Resource Management?](https://help.aliyun.com/document_detail/94475.html)
        # 
        # This parameter is required.
        self.new_resource_group_id = new_resource_group_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.new_resource_group_id is not None:
            result['NewResourceGroupId'] = self.new_resource_group_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('NewResourceGroupId') is not None:
            self.new_resource_group_id = m.get('NewResourceGroupId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class ModifyDBClusterResourceGroupResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyDBClusterResourceGroupResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyDBClusterResourceGroupResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyDBClusterResourceGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyDBClusterVipRequest(TeaModel):
    def __init__(
        self,
        connect_string: str = None,
        dbcluster_id: str = None,
        vpcid: str = None,
        v_switch_id: str = None,
    ):
        # The endpoint of the cluster.
        self.connect_string = connect_string
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The VPC ID.
        # 
        # > 
        # 
        # *   The new **VPC** must reside in the same region as the cluster.
        # 
        # This parameter is required.
        self.vpcid = vpcid
        # The vSwitch ID.
        # 
        # > 
        # 
        # *   The new vSwitch must reside in the same zone as the cluster.
        # 
        # This parameter is required.
        self.v_switch_id = v_switch_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.connect_string is not None:
            result['ConnectString'] = self.connect_string
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.vpcid is not None:
            result['VPCId'] = self.vpcid
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ConnectString') is not None:
            self.connect_string = m.get('ConnectString')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('VPCId') is not None:
            self.vpcid = m.get('VPCId')
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        return self


class ModifyDBClusterVipResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyDBClusterVipResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyDBClusterVipResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyDBClusterVipResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyDBResourceGroupRequestRayConfigWorkerGroups(TeaModel):
    def __init__(
        self,
        allocate_unit: str = None,
        group_name: str = None,
        max_worker_quantity: int = None,
        min_worker_quantity: int = None,
        worker_disk_capacity: str = None,
        worker_spec_name: str = None,
        worker_spec_type: str = None,
    ):
        self.allocate_unit = allocate_unit
        self.group_name = group_name
        self.max_worker_quantity = max_worker_quantity
        self.min_worker_quantity = min_worker_quantity
        self.worker_disk_capacity = worker_disk_capacity
        self.worker_spec_name = worker_spec_name
        self.worker_spec_type = worker_spec_type

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.allocate_unit is not None:
            result['AllocateUnit'] = self.allocate_unit
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.max_worker_quantity is not None:
            result['MaxWorkerQuantity'] = self.max_worker_quantity
        if self.min_worker_quantity is not None:
            result['MinWorkerQuantity'] = self.min_worker_quantity
        if self.worker_disk_capacity is not None:
            result['WorkerDiskCapacity'] = self.worker_disk_capacity
        if self.worker_spec_name is not None:
            result['WorkerSpecName'] = self.worker_spec_name
        if self.worker_spec_type is not None:
            result['WorkerSpecType'] = self.worker_spec_type
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AllocateUnit') is not None:
            self.allocate_unit = m.get('AllocateUnit')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('MaxWorkerQuantity') is not None:
            self.max_worker_quantity = m.get('MaxWorkerQuantity')
        if m.get('MinWorkerQuantity') is not None:
            self.min_worker_quantity = m.get('MinWorkerQuantity')
        if m.get('WorkerDiskCapacity') is not None:
            self.worker_disk_capacity = m.get('WorkerDiskCapacity')
        if m.get('WorkerSpecName') is not None:
            self.worker_spec_name = m.get('WorkerSpecName')
        if m.get('WorkerSpecType') is not None:
            self.worker_spec_type = m.get('WorkerSpecType')
        return self


class ModifyDBResourceGroupRequestRayConfig(TeaModel):
    def __init__(
        self,
        category: str = None,
        head_spec: str = None,
        worker_groups: List[ModifyDBResourceGroupRequestRayConfigWorkerGroups] = None,
    ):
        self.category = category
        self.head_spec = head_spec
        self.worker_groups = worker_groups

    def validate(self):
        if self.worker_groups:
            for k in self.worker_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        if self.head_spec is not None:
            result['HeadSpec'] = self.head_spec
        result['WorkerGroups'] = []
        if self.worker_groups is not None:
            for k in self.worker_groups:
                result['WorkerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('HeadSpec') is not None:
            self.head_spec = m.get('HeadSpec')
        self.worker_groups = []
        if m.get('WorkerGroups') is not None:
            for k in m.get('WorkerGroups'):
                temp_model = ModifyDBResourceGroupRequestRayConfigWorkerGroups()
                self.worker_groups.append(temp_model.from_map(k))
        return self


class ModifyDBResourceGroupRequestRules(TeaModel):
    def __init__(
        self,
        group_name: str = None,
        query_time: str = None,
        target_group_name: str = None,
    ):
        # The name of the resource group.
        self.group_name = group_name
        # The execution duration of the query. Unit: milliseconds.
        self.query_time = query_time
        # The name of the destination resource group.
        self.target_group_name = target_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.query_time is not None:
            result['QueryTime'] = self.query_time
        if self.target_group_name is not None:
            result['TargetGroupName'] = self.target_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('QueryTime') is not None:
            self.query_time = m.get('QueryTime')
        if m.get('TargetGroupName') is not None:
            self.target_group_name = m.get('TargetGroupName')
        return self


class ModifyDBResourceGroupRequest(TeaModel):
    def __init__(
        self,
        auto_stop_interval: str = None,
        cluster_mode: str = None,
        cluster_size_resource: str = None,
        dbcluster_id: str = None,
        enable_spot: bool = None,
        engine_params: Dict[str, Any] = None,
        group_name: str = None,
        group_type: str = None,
        max_cluster_count: int = None,
        max_compute_resource: str = None,
        max_gpu_quantity: int = None,
        min_cluster_count: int = None,
        min_compute_resource: str = None,
        min_gpu_quantity: int = None,
        ray_config: ModifyDBResourceGroupRequestRayConfig = None,
        region_id: str = None,
        rules: List[ModifyDBResourceGroupRequestRules] = None,
        spec_name: str = None,
        status: str = None,
        target_resource_group_name: str = None,
    ):
        self.auto_stop_interval = auto_stop_interval
        # A reserved parameter.
        self.cluster_mode = cluster_mode
        # A reserved parameter.
        self.cluster_size_resource = cluster_size_resource
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the spot instance feature for the resource group. After you enable the spot instance feature, you are charged for resources at a lower unit price but the resources are probably released. You can enable the spot instance feature only for job resource groups. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.enable_spot = enable_spot
        self.engine_params = engine_params
        # The name of the resource group.
        # 
        # > You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the name of a resource group in a cluster.
        # 
        # This parameter is required.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # > For information about resource groups of Data Lakehouse Edition, see [Resource groups](https://help.aliyun.com/document_detail/428610.html).
        # 
        # This parameter is required.
        self.group_type = group_type
        # A reserved parameter.
        self.max_cluster_count = max_cluster_count
        # The maximum amount of reserved computing resources.
        # 
        # *   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16ACU.
        # *   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8ACU.
        self.max_compute_resource = max_compute_resource
        self.max_gpu_quantity = max_gpu_quantity
        # A reserved parameter.
        self.min_cluster_count = min_cluster_count
        # The minimum amount of reserved computing resources.
        # 
        # *   If the GroupType parameter is set to Interactive, set the value to 16ACU.
        # *   If GroupType is set to Job, set the value to 0ACU.
        self.min_compute_resource = min_compute_resource
        self.min_gpu_quantity = min_gpu_quantity
        self.ray_config = ray_config
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        self.region_id = region_id
        # The job resubmission rules.
        self.rules = rules
        self.spec_name = spec_name
        self.status = status
        self.target_resource_group_name = target_resource_group_name

    def validate(self):
        if self.ray_config:
            self.ray_config.validate()
        if self.rules:
            for k in self.rules:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_stop_interval is not None:
            result['AutoStopInterval'] = self.auto_stop_interval
        if self.cluster_mode is not None:
            result['ClusterMode'] = self.cluster_mode
        if self.cluster_size_resource is not None:
            result['ClusterSizeResource'] = self.cluster_size_resource
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_spot is not None:
            result['EnableSpot'] = self.enable_spot
        if self.engine_params is not None:
            result['EngineParams'] = self.engine_params
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.max_cluster_count is not None:
            result['MaxClusterCount'] = self.max_cluster_count
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.max_gpu_quantity is not None:
            result['MaxGpuQuantity'] = self.max_gpu_quantity
        if self.min_cluster_count is not None:
            result['MinClusterCount'] = self.min_cluster_count
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        if self.min_gpu_quantity is not None:
            result['MinGpuQuantity'] = self.min_gpu_quantity
        if self.ray_config is not None:
            result['RayConfig'] = self.ray_config.to_map()
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        result['Rules'] = []
        if self.rules is not None:
            for k in self.rules:
                result['Rules'].append(k.to_map() if k else None)
        if self.spec_name is not None:
            result['SpecName'] = self.spec_name
        if self.status is not None:
            result['Status'] = self.status
        if self.target_resource_group_name is not None:
            result['TargetResourceGroupName'] = self.target_resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoStopInterval') is not None:
            self.auto_stop_interval = m.get('AutoStopInterval')
        if m.get('ClusterMode') is not None:
            self.cluster_mode = m.get('ClusterMode')
        if m.get('ClusterSizeResource') is not None:
            self.cluster_size_resource = m.get('ClusterSizeResource')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableSpot') is not None:
            self.enable_spot = m.get('EnableSpot')
        if m.get('EngineParams') is not None:
            self.engine_params = m.get('EngineParams')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('MaxClusterCount') is not None:
            self.max_cluster_count = m.get('MaxClusterCount')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MaxGpuQuantity') is not None:
            self.max_gpu_quantity = m.get('MaxGpuQuantity')
        if m.get('MinClusterCount') is not None:
            self.min_cluster_count = m.get('MinClusterCount')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        if m.get('MinGpuQuantity') is not None:
            self.min_gpu_quantity = m.get('MinGpuQuantity')
        if m.get('RayConfig') is not None:
            temp_model = ModifyDBResourceGroupRequestRayConfig()
            self.ray_config = temp_model.from_map(m['RayConfig'])
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        self.rules = []
        if m.get('Rules') is not None:
            for k in m.get('Rules'):
                temp_model = ModifyDBResourceGroupRequestRules()
                self.rules.append(temp_model.from_map(k))
        if m.get('SpecName') is not None:
            self.spec_name = m.get('SpecName')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TargetResourceGroupName') is not None:
            self.target_resource_group_name = m.get('TargetResourceGroupName')
        return self


class ModifyDBResourceGroupShrinkRequest(TeaModel):
    def __init__(
        self,
        auto_stop_interval: str = None,
        cluster_mode: str = None,
        cluster_size_resource: str = None,
        dbcluster_id: str = None,
        enable_spot: bool = None,
        engine_params_shrink: str = None,
        group_name: str = None,
        group_type: str = None,
        max_cluster_count: int = None,
        max_compute_resource: str = None,
        max_gpu_quantity: int = None,
        min_cluster_count: int = None,
        min_compute_resource: str = None,
        min_gpu_quantity: int = None,
        ray_config_shrink: str = None,
        region_id: str = None,
        rules_shrink: str = None,
        spec_name: str = None,
        status: str = None,
        target_resource_group_name: str = None,
    ):
        self.auto_stop_interval = auto_stop_interval
        # A reserved parameter.
        self.cluster_mode = cluster_mode
        # A reserved parameter.
        self.cluster_size_resource = cluster_size_resource
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the spot instance feature for the resource group. After you enable the spot instance feature, you are charged for resources at a lower unit price but the resources are probably released. You can enable the spot instance feature only for job resource groups. Valid values:
        # 
        # *   **True**\
        # *   **False**\
        self.enable_spot = enable_spot
        self.engine_params_shrink = engine_params_shrink
        # The name of the resource group.
        # 
        # > You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/459446.html) operation to query the name of a resource group in a cluster.
        # 
        # This parameter is required.
        self.group_name = group_name
        # The type of the resource group. Valid values:
        # 
        # *   **Interactive**\
        # *   **Job**\
        # 
        # > For information about resource groups of Data Lakehouse Edition, see [Resource groups](https://help.aliyun.com/document_detail/428610.html).
        # 
        # This parameter is required.
        self.group_type = group_type
        # A reserved parameter.
        self.max_cluster_count = max_cluster_count
        # The maximum amount of reserved computing resources.
        # 
        # *   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16ACU.
        # *   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8ACU.
        self.max_compute_resource = max_compute_resource
        self.max_gpu_quantity = max_gpu_quantity
        # A reserved parameter.
        self.min_cluster_count = min_cluster_count
        # The minimum amount of reserved computing resources.
        # 
        # *   If the GroupType parameter is set to Interactive, set the value to 16ACU.
        # *   If GroupType is set to Job, set the value to 0ACU.
        self.min_compute_resource = min_compute_resource
        self.min_gpu_quantity = min_gpu_quantity
        self.ray_config_shrink = ray_config_shrink
        # The region ID of the cluster.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        self.region_id = region_id
        # The job resubmission rules.
        self.rules_shrink = rules_shrink
        self.spec_name = spec_name
        self.status = status
        self.target_resource_group_name = target_resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_stop_interval is not None:
            result['AutoStopInterval'] = self.auto_stop_interval
        if self.cluster_mode is not None:
            result['ClusterMode'] = self.cluster_mode
        if self.cluster_size_resource is not None:
            result['ClusterSizeResource'] = self.cluster_size_resource
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_spot is not None:
            result['EnableSpot'] = self.enable_spot
        if self.engine_params_shrink is not None:
            result['EngineParams'] = self.engine_params_shrink
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.max_cluster_count is not None:
            result['MaxClusterCount'] = self.max_cluster_count
        if self.max_compute_resource is not None:
            result['MaxComputeResource'] = self.max_compute_resource
        if self.max_gpu_quantity is not None:
            result['MaxGpuQuantity'] = self.max_gpu_quantity
        if self.min_cluster_count is not None:
            result['MinClusterCount'] = self.min_cluster_count
        if self.min_compute_resource is not None:
            result['MinComputeResource'] = self.min_compute_resource
        if self.min_gpu_quantity is not None:
            result['MinGpuQuantity'] = self.min_gpu_quantity
        if self.ray_config_shrink is not None:
            result['RayConfig'] = self.ray_config_shrink
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.rules_shrink is not None:
            result['Rules'] = self.rules_shrink
        if self.spec_name is not None:
            result['SpecName'] = self.spec_name
        if self.status is not None:
            result['Status'] = self.status
        if self.target_resource_group_name is not None:
            result['TargetResourceGroupName'] = self.target_resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AutoStopInterval') is not None:
            self.auto_stop_interval = m.get('AutoStopInterval')
        if m.get('ClusterMode') is not None:
            self.cluster_mode = m.get('ClusterMode')
        if m.get('ClusterSizeResource') is not None:
            self.cluster_size_resource = m.get('ClusterSizeResource')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableSpot') is not None:
            self.enable_spot = m.get('EnableSpot')
        if m.get('EngineParams') is not None:
            self.engine_params_shrink = m.get('EngineParams')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('MaxClusterCount') is not None:
            self.max_cluster_count = m.get('MaxClusterCount')
        if m.get('MaxComputeResource') is not None:
            self.max_compute_resource = m.get('MaxComputeResource')
        if m.get('MaxGpuQuantity') is not None:
            self.max_gpu_quantity = m.get('MaxGpuQuantity')
        if m.get('MinClusterCount') is not None:
            self.min_cluster_count = m.get('MinClusterCount')
        if m.get('MinComputeResource') is not None:
            self.min_compute_resource = m.get('MinComputeResource')
        if m.get('MinGpuQuantity') is not None:
            self.min_gpu_quantity = m.get('MinGpuQuantity')
        if m.get('RayConfig') is not None:
            self.ray_config_shrink = m.get('RayConfig')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('Rules') is not None:
            self.rules_shrink = m.get('Rules')
        if m.get('SpecName') is not None:
            self.spec_name = m.get('SpecName')
        if m.get('Status') is not None:
            self.status = m.get('Status')
        if m.get('TargetResourceGroupName') is not None:
            self.target_resource_group_name = m.get('TargetResourceGroupName')
        return self


class ModifyDBResourceGroupResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyDBResourceGroupResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyDBResourceGroupResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyDBResourceGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyElasticPlanRequest(TeaModel):
    def __init__(
        self,
        cron_expression: str = None,
        dbcluster_id: str = None,
        elastic_plan_name: str = None,
        end_time: str = None,
        start_time: str = None,
        target_size: str = None,
    ):
        # A CORN expression that specifies the scaling cycle and time for the scaling plan.
        self.cron_expression = cron_expression
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the scaling plan.
        # 
        # >  You can call the [DescribeElasticPlans](https://help.aliyun.com/document_detail/601334.html) operation to query the names of scaling plans.
        # 
        # This parameter is required.
        self.elastic_plan_name = elastic_plan_name
        # The end time of the scaling plan.
        # 
        # >  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        self.end_time = end_time
        # The start time of the scaling plan.
        # 
        # >  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.
        self.start_time = start_time
        # The desired specifications of elastic resources after scaling.
        # 
        # > 
        # 
        # *   If the scaling plan uses **EIUs** and **Default Proportional Scaling for EIUs** is enabled, you do not need to specify this parameter. In other cases, you must specify this parameter.
        # 
        # *   You can call the [DescribeElasticPlanSpecifications](https://help.aliyun.com/document_detail/601278.html) operation to query the specifications that are supported for scaling plans.
        self.target_size = target_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cron_expression is not None:
            result['CronExpression'] = self.cron_expression
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.elastic_plan_name is not None:
            result['ElasticPlanName'] = self.elastic_plan_name
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.target_size is not None:
            result['TargetSize'] = self.target_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CronExpression') is not None:
            self.cron_expression = m.get('CronExpression')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ElasticPlanName') is not None:
            self.elastic_plan_name = m.get('ElasticPlanName')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('TargetSize') is not None:
            self.target_size = m.get('TargetSize')
        return self


class ModifyElasticPlanResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyElasticPlanResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyElasticPlanResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyElasticPlanResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyEssdCacheConfigRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        enable_essd_cache: bool = None,
        essd_cache_size: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the disk cache feature.
        # 
        # Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is required.
        self.enable_essd_cache = enable_essd_cache
        # The disk cache size. Unit: GB.
        self.essd_cache_size = essd_cache_size

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_essd_cache is not None:
            result['EnableEssdCache'] = self.enable_essd_cache
        if self.essd_cache_size is not None:
            result['EssdCacheSize'] = self.essd_cache_size
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableEssdCache') is not None:
            self.enable_essd_cache = m.get('EnableEssdCache')
        if m.get('EssdCacheSize') is not None:
            self.essd_cache_size = m.get('EssdCacheSize')
        return self


class ModifyEssdCacheConfigResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyEssdCacheConfigResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyEssdCacheConfigResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyEssdCacheConfigResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyLakeCacheSizeRequest(TeaModel):
    def __init__(
        self,
        capacity: int = None,
        dbcluster_id: str = None,
        enable_lake_cache: bool = None,
    ):
        # The lake cache size that you want to set. Unit: GB.
        self.capacity = capacity
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # Specifies whether to enable the lake cache feature.
        # 
        # Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is required.
        self.enable_lake_cache = enable_lake_cache

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capacity is not None:
            result['Capacity'] = self.capacity
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.enable_lake_cache is not None:
            result['EnableLakeCache'] = self.enable_lake_cache
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Capacity') is not None:
            self.capacity = m.get('Capacity')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('EnableLakeCache') is not None:
            self.enable_lake_cache = m.get('EnableLakeCache')
        return self


class ModifyLakeCacheSizeResponseBodyData(TeaModel):
    def __init__(
        self,
        capacity: int = None,
        data_size: int = None,
        instances: List[str] = None,
    ):
        # The size of the lake cache space. Unit: GB.
        self.capacity = capacity
        # The size of the data that occupies the lake cache space. Unit: GB.
        self.data_size = data_size
        # The clusters that share the lake cache space.
        self.instances = instances

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capacity is not None:
            result['Capacity'] = self.capacity
        if self.data_size is not None:
            result['DataSize'] = self.data_size
        if self.instances is not None:
            result['Instances'] = self.instances
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Capacity') is not None:
            self.capacity = m.get('Capacity')
        if m.get('DataSize') is not None:
            self.data_size = m.get('DataSize')
        if m.get('Instances') is not None:
            self.instances = m.get('Instances')
        return self


class ModifyLakeCacheSizeResponseBody(TeaModel):
    def __init__(
        self,
        code: int = None,
        data: ModifyLakeCacheSizeResponseBodyData = None,
        request_id: str = None,
    ):
        # The status code. The value 200 indicates that the request is successful.
        self.code = code
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = ModifyLakeCacheSizeResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyLakeCacheSizeResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyLakeCacheSizeResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyLakeCacheSizeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyPerformanceViewRequestViewDetailCategoriesKeys(TeaModel):
    def __init__(
        self,
        key_name: str = None,
        selected: bool = None,
    ):
        # The name of the metric.
        self.key_name = key_name
        # Specifies whether to select the metric. Valid values:
        # 
        # *   true
        # *   false
        self.selected = selected

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key_name is not None:
            result['KeyName'] = self.key_name
        if self.selected is not None:
            result['Selected'] = self.selected
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('KeyName') is not None:
            self.key_name = m.get('KeyName')
        if m.get('Selected') is not None:
            self.selected = m.get('Selected')
        return self


class ModifyPerformanceViewRequestViewDetailCategories(TeaModel):
    def __init__(
        self,
        category: str = None,
        keys: List[ModifyPerformanceViewRequestViewDetailCategoriesKeys] = None,
    ):
        # The name of the metric category. Valid values:
        # 
        # *   **Node**\
        # *   **DiskData**\
        # *   **WorkLoad**\
        # *   **ResourceGroup**\
        self.category = category
        # The metrics.
        self.keys = keys

    def validate(self):
        if self.keys:
            for k in self.keys:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.category is not None:
            result['Category'] = self.category
        result['Keys'] = []
        if self.keys is not None:
            for k in self.keys:
                result['Keys'].append(k.to_map() if k else None)
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Category') is not None:
            self.category = m.get('Category')
        self.keys = []
        if m.get('Keys') is not None:
            for k in m.get('Keys'):
                temp_model = ModifyPerformanceViewRequestViewDetailCategoriesKeys()
                self.keys.append(temp_model.from_map(k))
        return self


class ModifyPerformanceViewRequestViewDetail(TeaModel):
    def __init__(
        self,
        categories: List[ModifyPerformanceViewRequestViewDetailCategories] = None,
        chart_linked: bool = None,
        charts_per_line: int = None,
    ):
        # The metric categories.
        self.categories = categories
        # Specifies whether to enable the filter interaction feature. Valid values:
        # 
        # *   true
        # *   false
        self.chart_linked = chart_linked
        # The number of charts to display in each row.
        self.charts_per_line = charts_per_line

    def validate(self):
        if self.categories:
            for k in self.categories:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Categories'] = []
        if self.categories is not None:
            for k in self.categories:
                result['Categories'].append(k.to_map() if k else None)
        if self.chart_linked is not None:
            result['ChartLinked'] = self.chart_linked
        if self.charts_per_line is not None:
            result['ChartsPerLine'] = self.charts_per_line
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        self.categories = []
        if m.get('Categories') is not None:
            for k in m.get('Categories'):
                temp_model = ModifyPerformanceViewRequestViewDetailCategories()
                self.categories.append(temp_model.from_map(k))
        if m.get('ChartLinked') is not None:
            self.chart_linked = m.get('ChartLinked')
        if m.get('ChartsPerLine') is not None:
            self.charts_per_line = m.get('ChartsPerLine')
        return self


class ModifyPerformanceViewRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        view_detail: ModifyPerformanceViewRequestViewDetail = None,
        view_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The new information about the monitoring view.
        # 
        # This parameter is required.
        self.view_detail = view_detail
        # The name of the monitoring view.
        # 
        # This parameter is required.
        self.view_name = view_name

    def validate(self):
        if self.view_detail:
            self.view_detail.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.view_detail is not None:
            result['ViewDetail'] = self.view_detail.to_map()
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ViewDetail') is not None:
            temp_model = ModifyPerformanceViewRequestViewDetail()
            self.view_detail = temp_model.from_map(m['ViewDetail'])
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class ModifyPerformanceViewShrinkRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        view_detail_shrink: str = None,
        view_name: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/612397.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The new information about the monitoring view.
        # 
        # This parameter is required.
        self.view_detail_shrink = view_detail_shrink
        # The name of the monitoring view.
        # 
        # This parameter is required.
        self.view_name = view_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.view_detail_shrink is not None:
            result['ViewDetail'] = self.view_detail_shrink
        if self.view_name is not None:
            result['ViewName'] = self.view_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ViewDetail') is not None:
            self.view_detail_shrink = m.get('ViewDetail')
        if m.get('ViewName') is not None:
            self.view_name = m.get('ViewName')
        return self


class ModifyPerformanceViewResponseBody(TeaModel):
    def __init__(
        self,
        access_denied_detail: str = None,
        modify_status: str = None,
        request_id: str = None,
    ):
        # The details about the access denial. This parameter is returned only if Resource Access Management (RAM) permission verification failed.
        self.access_denied_detail = access_denied_detail
        # The modification result. Valid values:
        # 
        # *   **SUCCESS**\
        # *   **FAILED**\
        self.modify_status = modify_status
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.access_denied_detail is not None:
            result['AccessDeniedDetail'] = self.access_denied_detail
        if self.modify_status is not None:
            result['ModifyStatus'] = self.modify_status
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccessDeniedDetail') is not None:
            self.access_denied_detail = m.get('AccessDeniedDetail')
        if m.get('ModifyStatus') is not None:
            self.modify_status = m.get('ModifyStatus')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyPerformanceViewResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyPerformanceViewResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyPerformanceViewResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyUserEniVswitchOptionsRequest(TeaModel):
    def __init__(
        self,
        db_cluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        region_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        v_switch_options: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.db_cluster_id = db_cluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/454314.html) operation to query the most recent region list.
        self.region_id = region_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The vSwitches that you want to use. The vSwitches must reside in the same virtual private cloud (VPC) and zone as ENIs. You can specify up to three vSwitches. Separate multiple vSwitches with commas (,).
        # 
        # > 
        # 
        # *   The vSwitches that you specify overwrite the existing vSwitches that are connected to ENIs.
        # 
        # *   You can call the [DescribeDBClusterAttribute](https://help.aliyun.com/document_detail/612399.html) operation to query the network information about ENIs in a cluster.
        # 
        # This parameter is required.
        self.v_switch_options = v_switch_options

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.db_cluster_id is not None:
            result['DbClusterId'] = self.db_cluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.v_switch_options is not None:
            result['VSwitchOptions'] = self.v_switch_options
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DbClusterId') is not None:
            self.db_cluster_id = m.get('DbClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('VSwitchOptions') is not None:
            self.v_switch_options = m.get('VSwitchOptions')
        return self


class ModifyUserEniVswitchOptionsResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code or the error code.
        self.code = code
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class ModifyUserEniVswitchOptionsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ModifyUserEniVswitchOptionsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyUserEniVswitchOptionsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class PreloadSparkAppMetricsRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        dbcluster_id: str = None,
    ):
        # The Spark application ID.
        # 
        # This parameter is required.
        self.app_id = app_id
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class PreloadSparkAppMetricsResponseBodyDataScanMetrics(TeaModel):
    def __init__(
        self,
        output_rows_count: int = None,
        total_read_file_size_in_byte: int = None,
    ):
        # The number of rows scanned.
        self.output_rows_count = output_rows_count
        # The size of the scanned data. Unit: bytes.
        self.total_read_file_size_in_byte = total_read_file_size_in_byte

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.output_rows_count is not None:
            result['OutputRowsCount'] = self.output_rows_count
        if self.total_read_file_size_in_byte is not None:
            result['TotalReadFileSizeInByte'] = self.total_read_file_size_in_byte
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('OutputRowsCount') is not None:
            self.output_rows_count = m.get('OutputRowsCount')
        if m.get('TotalReadFileSizeInByte') is not None:
            self.total_read_file_size_in_byte = m.get('TotalReadFileSizeInByte')
        return self


class PreloadSparkAppMetricsResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        attempt_id: str = None,
        event_log_path: str = None,
        finished: bool = None,
        scan_metrics: PreloadSparkAppMetricsResponseBodyDataScanMetrics = None,
    ):
        # The ID of the Spark application.
        self.app_id = app_id
        # The retry ID of the Spark application.
        self.attempt_id = attempt_id
        # The event log path.
        self.event_log_path = event_log_path
        # Indicates whether parsing is complete. Valid values:
        # 
        # *   true
        # *   false
        self.finished = finished
        # The metrics.
        self.scan_metrics = scan_metrics

    def validate(self):
        if self.scan_metrics:
            self.scan_metrics.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.attempt_id is not None:
            result['AttemptId'] = self.attempt_id
        if self.event_log_path is not None:
            result['EventLogPath'] = self.event_log_path
        if self.finished is not None:
            result['Finished'] = self.finished
        if self.scan_metrics is not None:
            result['ScanMetrics'] = self.scan_metrics.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AttemptId') is not None:
            self.attempt_id = m.get('AttemptId')
        if m.get('EventLogPath') is not None:
            self.event_log_path = m.get('EventLogPath')
        if m.get('Finished') is not None:
            self.finished = m.get('Finished')
        if m.get('ScanMetrics') is not None:
            temp_model = PreloadSparkAppMetricsResponseBodyDataScanMetrics()
            self.scan_metrics = temp_model.from_map(m['ScanMetrics'])
        return self


class PreloadSparkAppMetricsResponseBody(TeaModel):
    def __init__(
        self,
        data: PreloadSparkAppMetricsResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = PreloadSparkAppMetricsResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class PreloadSparkAppMetricsResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: PreloadSparkAppMetricsResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = PreloadSparkAppMetricsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ReleaseClusterPublicConnectionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class ReleaseClusterPublicConnectionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ReleaseClusterPublicConnectionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ReleaseClusterPublicConnectionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ReleaseClusterPublicConnectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ResetAccountPasswordRequest(TeaModel):
    def __init__(
        self,
        account_description: str = None,
        account_name: str = None,
        account_password: str = None,
        dbcluster_id: str = None,
        engine: str = None,
    ):
        # The description of the database account.
        # 
        # *   The description cannot start with `http://` or `https://`.
        # *   The description must be 2 to 256 characters in length.
        self.account_description = account_description
        # The name of the database account.
        # 
        # >  You can call the [DescribeAccounts](https://help.aliyun.com/document_detail/612430.html) operation to query the information about database accounts of an AnalyticDB for MySQL cluster, including database account names.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The password of the database account.
        # 
        # *   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
        # *   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
        # *   The password must be 8 to 32 characters in length.
        # 
        # This parameter is required.
        self.account_password = account_password
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The database engine of the cluster. Valid values:
        # 
        # *   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
        # *   **Clickhouse**: the wide table engine.
        self.engine = engine

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_description is not None:
            result['AccountDescription'] = self.account_description
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.account_password is not None:
            result['AccountPassword'] = self.account_password
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountDescription') is not None:
            self.account_description = m.get('AccountDescription')
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('AccountPassword') is not None:
            self.account_password = m.get('AccountPassword')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        return self


class ResetAccountPasswordResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ResetAccountPasswordResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: ResetAccountPasswordResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ResetAccountPasswordResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class RevokeOperatorPermissionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        owner_account: str = None,
        owner_id: int = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        self.owner_account = owner_account
        self.owner_id = owner_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class RevokeOperatorPermissionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class RevokeOperatorPermissionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: RevokeOperatorPermissionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = RevokeOperatorPermissionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SetSparkAppLogRootPathRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        oss_log_path: str = None,
        use_default_oss: bool = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The path of Object Storage Service (OSS) logs.
        self.oss_log_path = oss_log_path
        # Specifies whether to use the default OSS log path.
        self.use_default_oss = use_default_oss

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.oss_log_path is not None:
            result['OssLogPath'] = self.oss_log_path
        if self.use_default_oss is not None:
            result['UseDefaultOss'] = self.use_default_oss
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('OssLogPath') is not None:
            self.oss_log_path = m.get('OssLogPath')
        if m.get('UseDefaultOss') is not None:
            self.use_default_oss = m.get('UseDefaultOss')
        return self


class SetSparkAppLogRootPathResponseBodyData(TeaModel):
    def __init__(
        self,
        default_log_path: str = None,
        is_log_path_exists: bool = None,
        modified_timestamp: str = None,
        modified_uid: str = None,
        recorded_log_path: str = None,
    ):
        # The default log path.
        self.default_log_path = default_log_path
        # Indicates whether a log path exists.
        self.is_log_path_exists = is_log_path_exists
        # The last modification time.
        self.modified_timestamp = modified_timestamp
        # The modifier ID.
        self.modified_uid = modified_uid
        # The recorded log path.
        self.recorded_log_path = recorded_log_path

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.default_log_path is not None:
            result['DefaultLogPath'] = self.default_log_path
        if self.is_log_path_exists is not None:
            result['IsLogPathExists'] = self.is_log_path_exists
        if self.modified_timestamp is not None:
            result['ModifiedTimestamp'] = self.modified_timestamp
        if self.modified_uid is not None:
            result['ModifiedUid'] = self.modified_uid
        if self.recorded_log_path is not None:
            result['RecordedLogPath'] = self.recorded_log_path
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DefaultLogPath') is not None:
            self.default_log_path = m.get('DefaultLogPath')
        if m.get('IsLogPathExists') is not None:
            self.is_log_path_exists = m.get('IsLogPathExists')
        if m.get('ModifiedTimestamp') is not None:
            self.modified_timestamp = m.get('ModifiedTimestamp')
        if m.get('ModifiedUid') is not None:
            self.modified_uid = m.get('ModifiedUid')
        if m.get('RecordedLogPath') is not None:
            self.recorded_log_path = m.get('RecordedLogPath')
        return self


class SetSparkAppLogRootPathResponseBody(TeaModel):
    def __init__(
        self,
        data: SetSparkAppLogRootPathResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SetSparkAppLogRootPathResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SetSparkAppLogRootPathResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: SetSparkAppLogRootPathResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SetSparkAppLogRootPathResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class StartApsJobRequest(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        region_id: str = None,
    ):
        # The job ID.
        # 
        # This parameter is required.
        self.aps_job_id = aps_job_id
        # The region ID
        # 
        # This parameter is required.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class StartApsJobResponseBody(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        code: str = None,
        err_code: str = None,
        err_message: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The HTTP status code or the error code.
        self.code = code
        # The error code returned when the request fails.
        self.err_code = err_code
        # The error message returned if the request failed.
        self.err_message = err_message
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, a success message is returned.****\
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.code is not None:
            result['Code'] = self.code
        if self.err_code is not None:
            result['ErrCode'] = self.err_code
        if self.err_message is not None:
            result['ErrMessage'] = self.err_message
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('ErrCode') is not None:
            self.err_code = m.get('ErrCode')
        if m.get('ErrMessage') is not None:
            self.err_message = m.get('ErrMessage')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class StartApsJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: StartApsJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = StartApsJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class StartSparkReplSessionRequest(TeaModel):
    def __init__(
        self,
        config: str = None,
        dbcluster_id: str = None,
        resource_group_name: str = None,
    ):
        # The configuration parameters that are used to start the Spark session, which are in the JSON format. For more information, see [Spark application configuration parameters](https://help.aliyun.com/document_detail/471203.html).
        # 
        # This parameter is required.
        self.config = config
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the job resource group.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.config is not None:
            result['Config'] = self.config
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Config') is not None:
            self.config = m.get('Config')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class StartSparkReplSessionResponseBodyData(TeaModel):
    def __init__(
        self,
        aliyun_uid: str = None,
        attempt_id: str = None,
        error: str = None,
        session_id: int = None,
        state: str = None,
        web_ui_address: str = None,
    ):
        # The ID of the Alibaba Cloud account that owns the cluster.
        self.aliyun_uid = aliyun_uid
        # The attempt ID of the Spark application.
        self.attempt_id = attempt_id
        # The error message.
        self.error = error
        # The ID of the session that executes the code.
        self.session_id = session_id
        # The status of the session. Valid values:
        # 
        # *   IDLE
        # *   BUSY
        # *   DEAD
        self.state = state
        # The URL of the web UI for the Spark application.
        self.web_ui_address = web_ui_address

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aliyun_uid is not None:
            result['AliyunUid'] = self.aliyun_uid
        if self.attempt_id is not None:
            result['AttemptId'] = self.attempt_id
        if self.error is not None:
            result['Error'] = self.error
        if self.session_id is not None:
            result['SessionId'] = self.session_id
        if self.state is not None:
            result['State'] = self.state
        if self.web_ui_address is not None:
            result['WebUiAddress'] = self.web_ui_address
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AliyunUid') is not None:
            self.aliyun_uid = m.get('AliyunUid')
        if m.get('AttemptId') is not None:
            self.attempt_id = m.get('AttemptId')
        if m.get('Error') is not None:
            self.error = m.get('Error')
        if m.get('SessionId') is not None:
            self.session_id = m.get('SessionId')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('WebUiAddress') is not None:
            self.web_ui_address = m.get('WebUiAddress')
        return self


class StartSparkReplSessionResponseBody(TeaModel):
    def __init__(
        self,
        data: StartSparkReplSessionResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = StartSparkReplSessionResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class StartSparkReplSessionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: StartSparkReplSessionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = StartSparkReplSessionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class StartSparkSQLEngineRequest(TeaModel):
    def __init__(
        self,
        config: str = None,
        dbcluster_id: str = None,
        jars: str = None,
        max_executor: int = None,
        min_executor: int = None,
        resource_group_name: str = None,
        slot_num: int = None,
    ):
        # The configuration that is required to start the Spark SQL engine. Specify this value in the JSON format. For more information, see [Conf configuration parameters](https://help.aliyun.com/document_detail/471203.html).
        self.config = config
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The Object Storage Service (OSS) paths of third-party JAR packages that are required to start the Spark SQL engine. Separate multiple OSS paths with commas (,).
        self.jars = jars
        # The maximum number of executors that are required to execute SQL statements. Valid values: 1 to 2000. If this value exceeds the total number of executes that are supported by the resource group, the Spark SQL engine fails to be started.
        self.max_executor = max_executor
        # The minimum number of executors that are required to execute SQL statements. Valid values: 0 to 2000. A value of 0 indicates that no executors are permanent if no SQL statements are executed. If this value exceeds the total number of executors that are supported by the resource group, the Spark SQL engine fails to be started. The value must be less than the value of MaxExecutor.
        self.min_executor = min_executor
        # The name of the resource group.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name
        # The maximum number of slots that are required to maintain Spark sessions for executing SQL statements. Valid values: 1 to 500.
        self.slot_num = slot_num

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.config is not None:
            result['Config'] = self.config
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.jars is not None:
            result['Jars'] = self.jars
        if self.max_executor is not None:
            result['MaxExecutor'] = self.max_executor
        if self.min_executor is not None:
            result['MinExecutor'] = self.min_executor
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.slot_num is not None:
            result['SlotNum'] = self.slot_num
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Config') is not None:
            self.config = m.get('Config')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Jars') is not None:
            self.jars = m.get('Jars')
        if m.get('MaxExecutor') is not None:
            self.max_executor = m.get('MaxExecutor')
        if m.get('MinExecutor') is not None:
            self.min_executor = m.get('MinExecutor')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('SlotNum') is not None:
            self.slot_num = m.get('SlotNum')
        return self


class StartSparkSQLEngineResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        app_name: str = None,
        state: str = None,
    ):
        # The ID of the Spark job.
        self.app_id = app_id
        # The name of the Spark application.
        self.app_name = app_name
        # The state of the Spark SQL engine. Valid values:
        # 
        # *   SUBMITTED
        # *   STARTING
        # *   RUNNING
        # *   FAILED
        self.state = state

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.app_name is not None:
            result['AppName'] = self.app_name
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AppName') is not None:
            self.app_name = m.get('AppName')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class StartSparkSQLEngineResponseBody(TeaModel):
    def __init__(
        self,
        data: StartSparkSQLEngineResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = StartSparkSQLEngineResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class StartSparkSQLEngineResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: StartSparkSQLEngineResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = StartSparkSQLEngineResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SubmitResultExportJobRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        engine: str = None,
        export_type: str = None,
        region_id: str = None,
        resource_group: str = None,
        sql: str = None,
        schema: str = None,
    ):
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The engine that is used to run the result set export job. Set the value to XIHE.
        self.engine = engine
        # The type of the result set export job.
        self.export_type = export_type
        # The region ID.
        # 
        # >  You can call the [DescribeRegions](https://help.aliyun.com/document_detail/143074.html) operation to query the most recent region list.
        # 
        # This parameter is required.
        self.region_id = region_id
        # The name of the resource group that runs the result set export job.
        self.resource_group = resource_group
        # The SQL statement that is used in the result set export job. You can specify only SELECT statements. If you specify other SQL statements, the request fails.
        # 
        # This parameter is required.
        self.sql = sql
        # The name of the database.
        # 
        # This parameter is required.
        self.schema = schema

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.engine is not None:
            result['Engine'] = self.engine
        if self.export_type is not None:
            result['ExportType'] = self.export_type
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group is not None:
            result['ResourceGroup'] = self.resource_group
        if self.sql is not None:
            result['SQL'] = self.sql
        if self.schema is not None:
            result['Schema'] = self.schema
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Engine') is not None:
            self.engine = m.get('Engine')
        if m.get('ExportType') is not None:
            self.export_type = m.get('ExportType')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroup') is not None:
            self.resource_group = m.get('ResourceGroup')
        if m.get('SQL') is not None:
            self.sql = m.get('SQL')
        if m.get('Schema') is not None:
            self.schema = m.get('Schema')
        return self


class SubmitResultExportJobResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: str = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The HTTP status code.
        self.code = code
        # The ID of the result set export job.
        self.data = data
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, an **OK** message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class SubmitResultExportJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: SubmitResultExportJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SubmitResultExportJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SubmitSparkAppRequest(TeaModel):
    def __init__(
        self,
        agent_source: str = None,
        agent_version: str = None,
        app_name: str = None,
        app_type: str = None,
        dbcluster_id: str = None,
        data: str = None,
        resource_group_name: str = None,
        template_file_id: int = None,
    ):
        # The type of the client. The value can be up to 64 characters in length.
        self.agent_source = agent_source
        # The version of the client. The value can be up to 64 characters in length.
        self.agent_version = agent_version
        # The name of the application. The value can be up to 64 characters in length.
        self.app_name = app_name
        # The type of the application. Valid values:
        # 
        # *   **SQL**\
        # *   **STREAMING**\
        # *   **BATCH** (default)
        self.app_type = app_type
        # The ID of the Enterprise Edition, Basic Edition, or Data Lakehouse Edition cluster.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/454250.html) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The data of the application template.
        # 
        # > For information about the application template configuration, see [Spark application configuration guide](https://help.aliyun.com/document_detail/452402.html).
        # 
        # This parameter is required.
        self.data = data
        # The name of the job resource group.
        # 
        # >  You can call the [DescribeDBResourceGroup](https://help.aliyun.com/document_detail/612410.html) operation to query the name of a resource group within a cluster.
        # 
        # This parameter is required.
        self.resource_group_name = resource_group_name
        # The ID of the application template.
        # 
        # > You can call the [GetSparkTemplateFullTree](https://help.aliyun.com/document_detail/456205.html) operation to query the application template ID.
        self.template_file_id = template_file_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.agent_source is not None:
            result['AgentSource'] = self.agent_source
        if self.agent_version is not None:
            result['AgentVersion'] = self.agent_version
        if self.app_name is not None:
            result['AppName'] = self.app_name
        if self.app_type is not None:
            result['AppType'] = self.app_type
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.data is not None:
            result['Data'] = self.data
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        if self.template_file_id is not None:
            result['TemplateFileId'] = self.template_file_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AgentSource') is not None:
            self.agent_source = m.get('AgentSource')
        if m.get('AgentVersion') is not None:
            self.agent_version = m.get('AgentVersion')
        if m.get('AppName') is not None:
            self.app_name = m.get('AppName')
        if m.get('AppType') is not None:
            self.app_type = m.get('AppType')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Data') is not None:
            self.data = m.get('Data')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        if m.get('TemplateFileId') is not None:
            self.template_file_id = m.get('TemplateFileId')
        return self


class SubmitSparkAppResponseBodyData(TeaModel):
    def __init__(
        self,
        app_id: str = None,
        app_name: str = None,
        message: str = None,
        state: str = None,
    ):
        # The application ID.
        self.app_id = app_id
        # The name of the application.
        self.app_name = app_name
        # The alert message returned for the operation, such as task execution failure or insufficient resources. If no alert occurs, null is returned.
        self.message = message
        # The execution state of the application. Valid values:
        # 
        # *   **SUBMITTED**\
        # *   **STARTING**\
        # *   **RUNNING**\
        # *   **FAILING**\
        # *   **FAILED**\
        # *   **KILLING**\
        # *   **KILLED**\
        # *   **SUCCEEDING**\
        # *   **COMPLETED**\
        # *   **FATAL**\
        # *   **UNKNOWN**\
        self.state = state

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        if self.app_name is not None:
            result['AppName'] = self.app_name
        if self.message is not None:
            result['Message'] = self.message
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        if m.get('AppName') is not None:
            self.app_name = m.get('AppName')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class SubmitSparkAppResponseBody(TeaModel):
    def __init__(
        self,
        data: SubmitSparkAppResponseBodyData = None,
        request_id: str = None,
    ):
        # The returned data.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SubmitSparkAppResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SubmitSparkAppResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: SubmitSparkAppResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SubmitSparkAppResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SubmitSparkLogAnalyzeTaskRequest(TeaModel):
    def __init__(
        self,
        app_id: str = None,
    ):
        # The ID of the Spark application.
        # 
        # This parameter is required.
        self.app_id = app_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.app_id is not None:
            result['AppId'] = self.app_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AppId') is not None:
            self.app_id = m.get('AppId')
        return self


class SubmitSparkLogAnalyzeTaskResponseBody(TeaModel):
    def __init__(
        self,
        data: SparkAnalyzeLogTask = None,
        request_id: str = None,
    ):
        # The information about the Spark log analysis task.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = SparkAnalyzeLogTask()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SubmitSparkLogAnalyzeTaskResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: SubmitSparkLogAnalyzeTaskResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SubmitSparkLogAnalyzeTaskResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SuspendApsJobRequest(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        region_id: str = None,
    ):
        # The job ID.
        # 
        # This parameter is required.
        self.aps_job_id = aps_job_id
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class SuspendApsJobResponseBody(TeaModel):
    def __init__(
        self,
        aps_job_id: str = None,
        err_code: str = None,
        err_message: str = None,
        http_status_code: int = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The job ID.
        self.aps_job_id = aps_job_id
        # The HTTP status code or the error code.
        self.err_code = err_code
        # The error code returned when the request fails.
        self.err_message = err_message
        # The response code. The status code 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.aps_job_id is not None:
            result['ApsJobId'] = self.aps_job_id
        if self.err_code is not None:
            result['ErrCode'] = self.err_code
        if self.err_message is not None:
            result['ErrMessage'] = self.err_message
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('ApsJobId') is not None:
            self.aps_job_id = m.get('ApsJobId')
        if m.get('ErrCode') is not None:
            self.err_code = m.get('ErrCode')
        if m.get('ErrMessage') is not None:
            self.err_message = m.get('ErrMessage')
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class SuspendApsJobResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: SuspendApsJobResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SuspendApsJobResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class UnbindAccountRequest(TeaModel):
    def __init__(
        self,
        account_name: str = None,
        dbcluster_id: str = None,
    ):
        # The name of the database account.
        # 
        # >  You can call the [DescribeAccounts](https://help.aliyun.com/document_detail/612430.html) operation to query the information about database accounts of an AnalyticDB for MySQL cluster, including database account names.
        # 
        # This parameter is required.
        self.account_name = account_name
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account_name is not None:
            result['AccountName'] = self.account_name
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AccountName') is not None:
            self.account_name = m.get('AccountName')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        return self


class UnbindAccountResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class UnbindAccountResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: UnbindAccountResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = UnbindAccountResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class UnbindDBResourceGroupWithUserRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        group_name: str = None,
        group_user: str = None,
    ):
        # The cluster ID.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The name of the resource group.
        self.group_name = group_name
        # The name of the database account.
        self.group_user = group_user

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.group_name is not None:
            result['GroupName'] = self.group_name
        if self.group_user is not None:
            result['GroupUser'] = self.group_user
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('GroupName') is not None:
            self.group_name = m.get('GroupName')
        if m.get('GroupUser') is not None:
            self.group_user = m.get('GroupUser')
        return self


class UnbindDBResourceGroupWithUserResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class UnbindDBResourceGroupWithUserResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: UnbindDBResourceGroupWithUserResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = UnbindDBResourceGroupWithUserResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class UpdateLakeStorageRequestPermissions(TeaModel):
    def __init__(
        self,
        account: str = None,
        read: bool = None,
        type: str = None,
        write: bool = None,
    ):
        # The account ID.
        # 
        # This parameter is required.
        self.account = account
        # The read permissions.
        # 
        # This parameter is required.
        self.read = read
        # The account type.
        # 
        # This parameter is required.
        self.type = type
        # The write permissions.
        # 
        # This parameter is required.
        self.write = write

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account is not None:
            result['Account'] = self.account
        if self.read is not None:
            result['Read'] = self.read
        if self.type is not None:
            result['Type'] = self.type
        if self.write is not None:
            result['Write'] = self.write
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Account') is not None:
            self.account = m.get('Account')
        if m.get('Read') is not None:
            self.read = m.get('Read')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Write') is not None:
            self.write = m.get('Write')
        return self


class UpdateLakeStorageRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        description: str = None,
        lake_storage_id: str = None,
        permissions: List[UpdateLakeStorageRequestPermissions] = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster that is associated with the lake storage.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The unique identifier of the lake storage.
        self.lake_storage_id = lake_storage_id
        # The permissions on the lake storage.
        self.permissions = permissions
        # The region ID.
        self.region_id = region_id

    def validate(self):
        if self.permissions:
            for k in self.permissions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        result['Permissions'] = []
        if self.permissions is not None:
            for k in self.permissions:
                result['Permissions'].append(k.to_map() if k else None)
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        self.permissions = []
        if m.get('Permissions') is not None:
            for k in m.get('Permissions'):
                temp_model = UpdateLakeStorageRequestPermissions()
                self.permissions.append(temp_model.from_map(k))
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class UpdateLakeStorageShrinkRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        description: str = None,
        lake_storage_id: str = None,
        permissions_shrink: str = None,
        region_id: str = None,
    ):
        # The ID of the AnalyticDB for MySQL cluster that is associated with the lake storage.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The unique identifier of the lake storage.
        self.lake_storage_id = lake_storage_id
        # The permissions on the lake storage.
        self.permissions_shrink = permissions_shrink
        # The region ID.
        self.region_id = region_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        if self.permissions_shrink is not None:
            result['Permissions'] = self.permissions_shrink
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        if m.get('Permissions') is not None:
            self.permissions_shrink = m.get('Permissions')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class UpdateLakeStorageResponseBodyDataPermissions(TeaModel):
    def __init__(
        self,
        account: str = None,
        read: bool = None,
        type: str = None,
        write: bool = None,
    ):
        # The account ID.
        self.account = account
        # The read permissions.
        self.read = read
        # The account type.
        self.type = type
        # The write permissions.
        self.write = write

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.account is not None:
            result['Account'] = self.account
        if self.read is not None:
            result['Read'] = self.read
        if self.type is not None:
            result['Type'] = self.type
        if self.write is not None:
            result['Write'] = self.write
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Account') is not None:
            self.account = m.get('Account')
        if m.get('Read') is not None:
            self.read = m.get('Read')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Write') is not None:
            self.write = m.get('Write')
        return self


class UpdateLakeStorageResponseBodyData(TeaModel):
    def __init__(
        self,
        create_time: str = None,
        creator_uid: str = None,
        dbcluster_id: str = None,
        description: str = None,
        file_size: str = None,
        lake_storage_id: str = None,
        operator_uid: str = None,
        owner_uid: str = None,
        partition_count: str = None,
        permissions: List[UpdateLakeStorageResponseBodyDataPermissions] = None,
        region_id: str = None,
        row_count: int = None,
        table_count: int = None,
        update_time: str = None,
    ):
        # The time when the lake storage was created.
        self.create_time = create_time
        # The creator UID.
        self.creator_uid = creator_uid
        # The ID of the AnalyticDB for MySQL cluster that is associated with the lake storage.
        self.dbcluster_id = dbcluster_id
        # The description of the lake storage.
        self.description = description
        # The total storage size.
        self.file_size = file_size
        # The unique identifier of the lake storage.
        self.lake_storage_id = lake_storage_id
        # The operator UID.
        self.operator_uid = operator_uid
        # The owner UID.
        self.owner_uid = owner_uid
        # The number of partitions.
        self.partition_count = partition_count
        # The permissions on the lake storage.
        self.permissions = permissions
        # The region ID.
        self.region_id = region_id
        # The total number of entries returned.
        self.row_count = row_count
        # The number of tables.
        self.table_count = table_count
        # The time when the lake storage was last updated.
        self.update_time = update_time

    def validate(self):
        if self.permissions:
            for k in self.permissions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.create_time is not None:
            result['CreateTime'] = self.create_time
        if self.creator_uid is not None:
            result['CreatorUid'] = self.creator_uid
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.description is not None:
            result['Description'] = self.description
        if self.file_size is not None:
            result['FileSize'] = self.file_size
        if self.lake_storage_id is not None:
            result['LakeStorageId'] = self.lake_storage_id
        if self.operator_uid is not None:
            result['OperatorUid'] = self.operator_uid
        if self.owner_uid is not None:
            result['OwnerUid'] = self.owner_uid
        if self.partition_count is not None:
            result['PartitionCount'] = self.partition_count
        result['Permissions'] = []
        if self.permissions is not None:
            for k in self.permissions:
                result['Permissions'].append(k.to_map() if k else None)
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.row_count is not None:
            result['RowCount'] = self.row_count
        if self.table_count is not None:
            result['TableCount'] = self.table_count
        if self.update_time is not None:
            result['UpdateTime'] = self.update_time
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('CreateTime') is not None:
            self.create_time = m.get('CreateTime')
        if m.get('CreatorUid') is not None:
            self.creator_uid = m.get('CreatorUid')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('FileSize') is not None:
            self.file_size = m.get('FileSize')
        if m.get('LakeStorageId') is not None:
            self.lake_storage_id = m.get('LakeStorageId')
        if m.get('OperatorUid') is not None:
            self.operator_uid = m.get('OperatorUid')
        if m.get('OwnerUid') is not None:
            self.owner_uid = m.get('OwnerUid')
        if m.get('PartitionCount') is not None:
            self.partition_count = m.get('PartitionCount')
        self.permissions = []
        if m.get('Permissions') is not None:
            for k in m.get('Permissions'):
                temp_model = UpdateLakeStorageResponseBodyDataPermissions()
                self.permissions.append(temp_model.from_map(k))
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('RowCount') is not None:
            self.row_count = m.get('RowCount')
        if m.get('TableCount') is not None:
            self.table_count = m.get('TableCount')
        if m.get('UpdateTime') is not None:
            self.update_time = m.get('UpdateTime')
        return self


class UpdateLakeStorageResponseBody(TeaModel):
    def __init__(
        self,
        code: str = None,
        data: UpdateLakeStorageResponseBodyData = None,
        http_status_code: int = None,
        message: str = None,
        request_id: str = None,
        success: bool = None,
    ):
        # The status code. A value of 200 indicates that the request is successful.
        self.code = code
        # The returned data.
        self.data = data
        # The HTTP status code. A value of 200 indicates that the request was successful.
        self.http_status_code = http_status_code
        # The returned message. Valid values:
        # 
        # *   If the request was successful, an OK message is returned.
        # *   If the request failed, an error message is returned.
        self.message = message
        # The request ID.
        self.request_id = request_id
        # Indicates whether the request was successful. Valid values:
        # 
        # *   **true**\
        # *   **false**\
        self.success = success

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.code is not None:
            result['Code'] = self.code
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.http_status_code is not None:
            result['HttpStatusCode'] = self.http_status_code
        if self.message is not None:
            result['Message'] = self.message
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.success is not None:
            result['Success'] = self.success
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Code') is not None:
            self.code = m.get('Code')
        if m.get('Data') is not None:
            temp_model = UpdateLakeStorageResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('HttpStatusCode') is not None:
            self.http_status_code = m.get('HttpStatusCode')
        if m.get('Message') is not None:
            self.message = m.get('Message')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Success') is not None:
            self.success = m.get('Success')
        return self


class UpdateLakeStorageResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: UpdateLakeStorageResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = UpdateLakeStorageResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class UpdateSparkTemplateFileRequest(TeaModel):
    def __init__(
        self,
        content: str = None,
        dbcluster_id: str = None,
        id: int = None,
        resource_group_name: str = None,
    ):
        # The template data to be updated.
        # 
        # >  If you do not specify this parameter, the application template is not updated. For information about how to configure a Spark application template, see [Configure a Spark application](https://help.aliyun.com/document_detail/452402.html).
        self.content = content
        # The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The application template ID.
        # 
        # >  You can call the [GetSparkTemplateFullTree](https://help.aliyun.com/document_detail/456205.html) operation to query the application template ID.
        # 
        # This parameter is required.
        self.id = id
        # The name of the job resource group.
        self.resource_group_name = resource_group_name

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.id is not None:
            result['Id'] = self.id
        if self.resource_group_name is not None:
            result['ResourceGroupName'] = self.resource_group_name
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('ResourceGroupName') is not None:
            self.resource_group_name = m.get('ResourceGroupName')
        return self


class UpdateSparkTemplateFileResponseBodyData(TeaModel):
    def __init__(
        self,
        succeeded: bool = None,
    ):
        # Indicates whether the application template is updated.
        # 
        # *   **True**\
        # *   **False**\
        self.succeeded = succeeded

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.succeeded is not None:
            result['Succeeded'] = self.succeeded
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Succeeded') is not None:
            self.succeeded = m.get('Succeeded')
        return self


class UpdateSparkTemplateFileResponseBody(TeaModel):
    def __init__(
        self,
        data: UpdateSparkTemplateFileResponseBodyData = None,
        request_id: str = None,
    ):
        # The update result.
        self.data = data
        # The request ID.
        self.request_id = request_id

    def validate(self):
        if self.data:
            self.data.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.data is not None:
            result['Data'] = self.data.to_map()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Data') is not None:
            temp_model = UpdateSparkTemplateFileResponseBodyData()
            self.data = temp_model.from_map(m['Data'])
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class UpdateSparkTemplateFileResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: UpdateSparkTemplateFileResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = UpdateSparkTemplateFileResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class UpgradeKernelVersionRequest(TeaModel):
    def __init__(
        self,
        dbcluster_id: str = None,
        dbversion: str = None,
        owner_account: str = None,
        owner_id: int = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        switch_mode: int = None,
    ):
        # The cluster ID.
        # 
        # >  You can call the [DescribeDBClusters](https://help.aliyun.com/document_detail/129857.html) operation to query the information about all AnalyticDB for MySQL Data Warehouse Edition clusters within a region, including cluster IDs.
        # 
        # This parameter is required.
        self.dbcluster_id = dbcluster_id
        # The minor version to which you want to update.
        # 
        # >  You can call the **DescribeKernelVersion** operation to query the supported minor versions.
        self.dbversion = dbversion
        self.owner_account = owner_account
        self.owner_id = owner_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # The time when to perform the update. Valid values:
        # 
        # *   **0** (default): immediately performs the update.
        # *   **1**: performs the update during the maintenance window.
        # 
        # >  You can call the [ModifyDBClusterMaintainTime](https://help.aliyun.com/document_detail/612236.html) operation to modify the maintenance window of an AnalyticDB for MySQL cluster.
        self.switch_mode = switch_mode

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dbcluster_id is not None:
            result['DBClusterId'] = self.dbcluster_id
        if self.dbversion is not None:
            result['DBVersion'] = self.dbversion
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.switch_mode is not None:
            result['SwitchMode'] = self.switch_mode
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('DBClusterId') is not None:
            self.dbcluster_id = m.get('DBClusterId')
        if m.get('DBVersion') is not None:
            self.dbversion = m.get('DBVersion')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('SwitchMode') is not None:
            self.switch_mode = m.get('SwitchMode')
        return self


class UpgradeKernelVersionResponseBody(TeaModel):
    def __init__(
        self,
        request_id: str = None,
    ):
        # The request ID.
        self.request_id = request_id

    def validate(self):
        pass

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class UpgradeKernelVersionResponse(TeaModel):
    def __init__(
        self,
        headers: Dict[str, str] = None,
        status_code: int = None,
        body: UpgradeKernelVersionResponseBody = None,
    ):
        self.headers = headers
        self.status_code = status_code
        self.body = body

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super().to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = UpgradeKernelVersionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


