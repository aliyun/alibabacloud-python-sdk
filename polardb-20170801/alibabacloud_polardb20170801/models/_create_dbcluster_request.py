# -*- coding: utf-8 -*-
# This file is auto-generated, don't edit it. Thanks.
from __future__ import annotations

from typing import List

from alibabacloud_polardb20170801 import models as main_models
from darabonba.model import DaraModel

class CreateDBClusterRequest(DaraModel):
    def __init__(
        self,
        allow_shut_down: str = None,
        architecture: str = None,
        auto_renew: bool = None,
        auto_use_coupon: bool = None,
        backup_retention_policy_on_cluster_deletion: str = None,
        bursting_enabled: str = None,
        client_token: str = None,
        clone_data_point: str = None,
        cloud_provider: str = None,
        cluster_network_type: str = None,
        creation_category: str = None,
        creation_option: str = None,
        dbcluster_description: str = None,
        dbminor_version: str = None,
        dbnode_class: str = None,
        dbnode_num: int = None,
        dbtype: str = None,
        dbversion: str = None,
        default_time_zone: str = None,
        ens_region_id: str = None,
        gdnid: str = None,
        hot_standby_cluster: str = None,
        loose_polar_log_bin: str = None,
        loose_xengine: str = None,
        loose_xengine_use_memory_pct: str = None,
        lower_case_table_names: str = None,
        owner_account: str = None,
        owner_id: int = None,
        parameter_group_id: str = None,
        pay_type: str = None,
        period: str = None,
        promotion_code: str = None,
        provisioned_iops: int = None,
        proxy_class: str = None,
        proxy_type: str = None,
        region_id: str = None,
        resource_group_id: str = None,
        resource_owner_account: str = None,
        resource_owner_id: int = None,
        scale_max: str = None,
        scale_min: str = None,
        scale_ro_num_max: str = None,
        scale_ro_num_min: str = None,
        security_iplist: str = None,
        serverless_type: str = None,
        source_resource_id: str = None,
        source_uid: int = None,
        standby_az: str = None,
        storage_auto_scale: str = None,
        storage_encryption: bool = None,
        storage_encryption_key: str = None,
        storage_pay_type: str = None,
        storage_space: int = None,
        storage_type: str = None,
        storage_upper_bound: int = None,
        strict_consistency: str = None,
        tdestatus: bool = None,
        tag: List[main_models.CreateDBClusterRequestTag] = None,
        target_minor_version: str = None,
        used_time: str = None,
        vpcid: str = None,
        v_switch_id: str = None,
        zone_id: str = None,
    ):
        # Whether to enable idle pause. Values:
        # 
        # - **true**: Enabled
        # 
        # - **false**: Disabled (default)
        # 
        # > Only supported by Serverless clusters.
        self.allow_shut_down = allow_shut_down
        # CPU architecture. Available values include:
        # - X86
        # - ARM
        self.architecture = architecture
        # Whether to enable auto-renewal, with available values as follows:
        # 
        # - **true**: Auto-renew.
        # - **false**: Do not auto-renew.
        # 
        # The default is **false**.
        # 
        # > This parameter takes effect only when **PayType** is set to **Prepaid**.
        self.auto_renew = auto_renew
        self.auto_use_coupon = auto_use_coupon
        # Backup retention policy upon cluster deletion, with valid values as follows:
        # * **ALL**: Permanently retain all backups.
        # * **LATEST**: Permanently retain the latest backup (automatically backed up before deletion).
        # * **NONE**: Do not retain backup sets upon cluster deletion.
        # 
        # By default, the value is set to **NONE**, indicating no backup sets are retained upon cluster deletion.
        # > This parameter applies only when **DBType** is **MySQL**.
        # > Serverless clusters do not support this parameter.
        self.backup_retention_policy_on_cluster_deletion = backup_retention_policy_on_cluster_deletion
        self.bursting_enabled = bursting_enabled
        # Used to ensure idempotency of the request. Generated by the client, ensuring uniqueness across different requests, case-sensitive, and not exceeding 64 ASCII characters.
        self.client_token = client_token
        # The point in time to clone data, with the following options:
        # 
        # - **LATEST**: Data from the latest time point.
        # - **BackupID**: Historical backup set ID, please enter the specific backup set ID.
        # - **Timestamp**: Historical time point, please enter the specific time in the format `YYYY-MM-DDThh:mm:ssZ` (UTC time).
        # 
        # The default value is **LATEST**.
        # 
        # > If **CreationOption** is **CloneFromRDS**, this parameter can only be set to **LATEST**.
        self.clone_data_point = clone_data_point
        self.cloud_provider = cloud_provider
        # Cluster network type, currently only VPC is supported, with a fixed value of **VPC**.
        self.cluster_network_type = cluster_network_type
        # Product series, with valid values as follows:
        # * **Normal**: Cluster Edition (default)
        # * **Basic**: Single-node
        # * **ArchiveNormal**: High Compression Engine (X-Engine)
        # * **NormalMultimaster**: Multi-master Cluster Edition
        # * **SENormal**: Standard Edition
        # 
        # > * **MySQL** **5.6**, **5.7**, **8.0**, **PostgreSQL** **14**, and **Oracle Syntax Compatible 2.0** support **Basic**.
        # > * **MySQL** **8.0** supports **ArchiveNormal** and **NormalMultimaster**.
        # > * **MySQL** **5.6**, **5.7**, **8.0**, and **PostgreSQL** **14** support **SENormal**.
        # 
        # For more information about product series, see [Product Series](https://help.aliyun.com/document_detail/183258.html).
        self.creation_category = creation_category
        # Creation method, with the following values supported:
        # 
        # * **Normal**: Creates a brand new PolarDB cluster. For console operations, refer to the following documents:
        #     * [Create a PolarDB MySQL Edition Database Cluster](https://help.aliyun.com/document_detail/58769.html)
        #     * [Create a PolarDB PostgreSQL Edition Database Cluster](https://help.aliyun.com/document_detail/118063.html)
        #     * [Create a PolarDB PostgreSQL Edition (Oracle Compatible) Database Cluster](https://help.aliyun.com/document_detail/118182.html)
        # 
        # * **CloneFromPolarDB**: Clones data from an existing PolarDB cluster to a new PolarDB cluster. For console operations, refer to the following documents:
        #     * [Clone a PolarDB MySQL Edition Cluster](https://help.aliyun.com/document_detail/87966.html)
        #     * [Clone a PolarDB PostgreSQL Edition Cluster](https://help.aliyun.com/document_detail/118108.html)
        #     * [Clone a PolarDB PostgreSQL Edition (Oracle Compatible) Cluster](https://help.aliyun.com/document_detail/118221.html)
        # 
        # * **RecoverFromRecyclebin**: Recovers data from a released PolarDB cluster to a new PolarDB cluster. For console operations, refer to the following documents:
        #     * [Restore a Released PolarDB MySQL Edition Cluster](https://help.aliyun.com/document_detail/164880.html)
        #     * [Restore a Released PolarDB PostgreSQL Edition Cluster](https://help.aliyun.com/document_detail/432844.html)
        #     * [Restore a Released PolarDB PostgreSQL Edition (Oracle Compatible) Cluster](https://help.aliyun.com/document_detail/424632.html)
        # 
        # * **CloneFromRDS**: Clones data from an existing RDS instance to a new PolarDB cluster. Console operation guide is available at [One-click Clone from RDS MySQL to PolarDB MySQL Edition](https://help.aliyun.com/document_detail/121812.html).
        # 
        # * **MigrationFromRDS**: Migrates data from an existing RDS instance to a new PolarDB cluster. The created PolarDB cluster operates in read-only mode with Binlog enabled by default. Console operation guide is at [One-click Upgrade from RDS MySQL to PolarDB MySQL Edition](https://help.aliyun.com/document_detail/121582.html).
        # 
        # * **CreateGdnStandby**: Creates a standby cluster. Console operation guide can be found at [Add Standby Cluster](https://help.aliyun.com/document_detail/160381.html).
        # 
        # * **UpgradeFromPolarDB**: Upgrades and migrates from PolarDB. Console operation guide is detailed in [Major Version Upgrade](https://help.aliyun.com/document_detail/459712.html).
        # 
        # The default value is **Normal**.
        # 
        # > When **DBType** is **MySQL** and **DBVersion** is **8.0**, this parameter can also take the value **CreateGdnStandby**.
        self.creation_option = creation_option
        # Cluster name, which must meet the following requirements:
        # * Cannot start with `http://` or `https://`.
        # * Length should be between 2 and 256 characters.
        self.dbcluster_description = dbcluster_description
        # Database engine minor version number. Valid values include:
        # 
        # - **8.0.2**
        # - **8.0.1**
        # 
        # > This parameter takes effect only when **DBType** is **MySQL** and **DBVersion** is **8.0**.
        self.dbminor_version = dbminor_version
        # Node specifications. For details, refer to the following documents:
        # 
        # - PolarDB MySQL Edition: [Compute Node Specifications](https://help.aliyun.com/document_detail/102542.html).
        # - PolarDB PostgreSQL Edition (Oracle Compatible): [Compute Node Specifications](https://help.aliyun.com/document_detail/207921.html).
        # - PolarDB PostgreSQL Edition: [Compute Node Specifications](https://help.aliyun.com/document_detail/209380.html).
        # 
        # > - For a Serverless cluster in PolarDB MySQL, enter **polar.mysql.sl.small**.
        # <props="china">> - For a Serverless cluster in both PolarDB PostgreSQL (Oracle Compatible) and PolarDB PostgreSQL, enter **polar.pg.sl.small.c**.
        self.dbnode_class = dbnode_class
        # The number of nodes. This parameter is supported for Standard Edition clusters. Valid values:
        # 
        # *   **1** (default): only one primary node.
        # *   **2**: one read-only node and one primary node.
        # 
        # > 
        # 
        # *   By default, an Enterprise Edition cluster has two nodes and a Standard Edition cluster has one node.
        # 
        # *   This parameter is supported only for PolarDB for MySQL clusters.
        self.dbnode_num = dbnode_num
        # Database engine type, with available values as follows:
        # 
        # - **MySQL**
        # - **PostgreSQL**
        # - **Oracle**
        # 
        # This parameter is required.
        self.dbtype = dbtype
        # Database engine version number.
        # * For MySQL, the version numbers are as follows:
        #     * **5.6**
        #     * **5.7**
        #     * **8.0**
        # * For PostgreSQL, the version numbers are as follows:
        #     * **11**
        #     * **14**
        #     * **15**
        #     <props="china">
        #       
        #       > When creating a Serverless cluster in PolarDB PostgreSQL, only version **14** is supported.
        #     
        #     
        # * For Oracle, the version numbers are as follows:
        #     * **11**
        #     * **14**
        # 
        # This parameter is required.
        self.dbversion = dbversion
        # Cluster timezone (UTC), with selectable values ranging from **-12:00** to **+13:00** at whole-hour intervals, e.g., **00:00**. The default value is **SYSTEM**, which matches the Region\\"s timezone.
        # > This parameter applies only when **DBType** is **MySQL**.
        self.default_time_zone = default_time_zone
        self.ens_region_id = ens_region_id
        # Global Database Network (GDN) ID.
        # 
        # > This parameter is required when **CreationOption** is **CreateGdnStandby**.
        self.gdnid = gdnid
        # Specifies whether to enable the hot standby storage cluster feature. Valid values:
        # 
        # *   **ON** (default): enables the hot standby storage cluster feature.
        # *   **OFF**: disables the hot standby storage cluster feature.
        # *   **STANDBY**: enables the hot standby storage cluster feature for Standard Edition clusters.
        # 
        # >  The default value for Standard Edition clusters is **STANDBY**.
        self.hot_standby_cluster = hot_standby_cluster
        # Enable Binlog feature, valid values are as follows:
        # - **ON**: Cluster enables the Binlog feature. - **OFF**: Cluster disables the Binlog feature. > This parameter takes effect only when the **DBType** parameter is set to **MySQL**.
        self.loose_polar_log_bin = loose_polar_log_bin
        # Enable the X-Engine storage engine feature, with valid values as follows:
        # 
        # - **ON**: The cluster enables the X-Engine engine.
        # - **OFF**: The cluster disables the X-Engine engine.
        # > This parameter is effective only when **CreationOption** is not **CreateGdnStandby**, **DBType** is **MySQL**, and **DBVersion** is **8.0**. The memory specification of nodes that enable the X-Engine engine must be at least 8 GB.
        self.loose_xengine = loose_xengine
        # Set the ratio for enabling the X-Engine storage engine, with a range of integers from 10 to 90.
        # > This parameter takes effect only when **LooseXEngine** is **ON**.
        self.loose_xengine_use_memory_pct = loose_xengine_use_memory_pct
        # Whether table names are case-sensitive, with valid values as follows:
        # * **1**: Case-insensitive
        # * **0**: Case-sensitive
        # 
        # The default value is **1**.
        # > This parameter applies only when **DBType** is **MySQL**.
        self.lower_case_table_names = lower_case_table_names
        self.owner_account = owner_account
        self.owner_id = owner_id
        # Parameter template ID.
        # 
        # > You can view the list of parameter templates in the target region, including the parameter template ID, by calling the [DescribeParameterGroups](https://help.aliyun.com/document_detail/207178.html) interface.
        self.parameter_group_id = parameter_group_id
        # Payment type, with available values as follows:
        # 
        # - **Postpaid**: Pay-as-you-go.
        # - **Prepaid**: Subscription (monthly or yearly).
        # 
        # This parameter is required.
        self.pay_type = pay_type
        # If the payment type is **Prepaid**, this parameter is required. It specifies whether the prepaid cluster is on a monthly or yearly basis.
        # 
        # - **Year**: Yearly subscription.
        # - **Month**: Monthly subscription.
        self.period = period
        self.promotion_code = promotion_code
        # <p id="p_wyg_t4a_glm">The provisioned read and write IOPS for ESSD AutoPL cloud disks. Possible values: 0 to min{50,000, 1000*capacity-Baseline Performance}.</p>
        # <p id="p_6de_jxy_k2g">Baseline Performance = min{1,800+50*capacity, 50000}.</p>
        # <note id="note_7kj_j0o_rgs">This parameter is supported only when StorageType is ESSDAUTOPL.</note>
        self.provisioned_iops = provisioned_iops
        # Standard edition database proxy specifications. Values are as follows:
        # 
        # - **polar.maxscale.g2.medium.c**: 2 cores.
        # - **polar.maxscale.g2.large.c**: 4 cores.
        # - **polar.maxscale.g2.xlarge.c**: 8 cores.
        # - **polar.maxscale.g2.2xlarge.c**: 16 cores.
        # - **polar.maxscale.g2.3xlarge.c**: 24 cores.
        # - **polar.maxscale.g2.4xlarge.c**: 32 cores.
        # - **polar.maxscale.g2.8xlarge.c**: 64 cores.
        self.proxy_class = proxy_class
        # Database proxy type, with values including:
        # - **EXCLUSIVE**: Enterprise Exclusive Edition
        # - **GENERAL**: Enterprise General Purpose Edition
        # > The proxy type must match the type of the cluster\\"s node specifications, i.e.,
        # >- If the node specification is general, the proxy type should be Enterprise General Purpose Edition;
        # >- If the node specification is dedicated, the proxy type should be Enterprise Exclusive Edition.
        self.proxy_type = proxy_type
        # Region ID.
        # 
        # > You can view available regions through the [DescribeRegions](https://help.aliyun.com/document_detail/98041.html) interface.
        # 
        # This parameter is required.
        self.region_id = region_id
        # Resource group ID.
        self.resource_group_id = resource_group_id
        self.resource_owner_account = resource_owner_account
        self.resource_owner_id = resource_owner_id
        # Maximum scaling limit for a single node. The value range is: 1 PCU~32 PCU.
        # 
        # > Only supported by Serverless clusters.
        self.scale_max = scale_max
        # Minimum scaling limit for a single node. The value range is: 1 PCU~31 PCU.
        # 
        # > Only supported by Serverless clusters.
        self.scale_min = scale_min
        # Maximum scaling limit for the number of read-only nodes. The value range is: 0~15.
        # 
        # > Only supported by Serverless clusters.
        self.scale_ro_num_max = scale_ro_num_max
        # Minimum scaling limit for the number of read-only nodes. The value range is: 0~15.
        # 
        # > Only supported by Serverless clusters.
        self.scale_ro_num_min = scale_ro_num_min
        # PolarDB cluster whitelist IP address.
        # > Supports configuring multiple whitelist IP addresses, with English commas separating multiple IP addresses.
        self.security_iplist = security_iplist
        # Serverless type. The current value is fixed to **AgileServerless** (sensitive mode).
        # > This parameter is only supported by Serverless clusters.
        self.serverless_type = serverless_type
        # Source RDS instance ID or source PolarDB cluster ID. This parameter is mandatory only when **CreationOption** is set to **MigrationFromRDS**, **CloneFromRDS**, **CloneFromPolarDB**, or **RecoverFromRecyclebin**.
        # * If **CreationOption** is **MigrationFromRDS** or **CloneFromRDS**, you need to input the source RDS instance ID. The source RDS instance version must be RDS MySQL 5.6, 5.7, or 8.0 High Availability edition.
        # 
        # * If **CreationOption** is **CloneFromPolarDB**, you need to input the source PolarDB cluster ID. The DBType of the cloned cluster will default to match the source cluster. For example, if the source cluster is MySQL 8.0, the cloned cluster must also have **DBType** set to **MySQL** and **DBVersion** to **8.0**.
        # 
        # * If **CreationOption** is **RecoverFromRecyclebin**, you need to input the released source PolarDB cluster ID. The DBType of the cluster being recovered from the recycle bin must match the source cluster. For example, if the source cluster was MySQL 8.0, the recovered cluster must also have **DBType** set to **MySQL** and **DBVersion** to **8.0**.
        self.source_resource_id = source_resource_id
        self.source_uid = source_uid
        # The availability zone where the hot standby cluster is stored. Applicable to the standard edition 3AZ scenario.
        # 
        # > This parameter takes effect only when multi-zone data strong consistency is enabled.
        self.standby_az = standby_az
        # Whether to enable automatic storage expansion for standard edition clusters, with valid values as follows:
        # 
        # - Enable: Enables automatic storage expansion.
        # - Disable: Disables automatic storage expansion.
        self.storage_auto_scale = storage_auto_scale
        # Specifies whether to enable disk encryption. Valid values:
        # 
        # *   **true**
        # *   **false** (default)
        # 
        # >  This parameter takes effect only when **DBType** is set to **MySQL**.
        # 
        # >  This parameter takes effect only when **StorageType** is set to one of the Standard Edition storage types.
        self.storage_encryption = storage_encryption
        # The ID of the custom key that is used for disk encryption in the region in which the instance resides. If this parameter is specified, disk encryption is automatically enabled and cannot be disabled afterwards. If you want to use the default service key for disk encryption, leave this parameter empty.
        # 
        # You can obtain the ID of the key in the KMS console or create a key.
        # 
        # >  This parameter takes effect only when **DBType** is set to **MySQL**.
        # 
        # >  This parameter takes effect only when **StorageType** is set to one of the Standard Edition storage types.
        self.storage_encryption_key = storage_encryption_key
        # The storage billing type, with valid values as follows:
        # 
        # - Postpaid: Pay-as-you-go (hourly).
        # - Prepaid: Pay-per-use based on space (subscription).
        self.storage_pay_type = storage_pay_type
        # The storage that is billed based on the subscription billing method. Unit: GB.
        # 
        # > 
        # 
        # *   Valid values for the subscription storage capacity of a PolarDB for MySQL Standard Edition cluster: 20 to 32000.
        # 
        # *   Valid values for the subscription storage capacity of a Standard Edition cluster that uses the ESSD AUTOPL storage type: 40 to 64000, in increments of 10.
        self.storage_space = storage_space
        # Enterprise edition storage types include:
        # - **PSL5**
        # - **PSL4**
        # 
        # Standard edition storage types include:
        # - **ESSDPL0**
        # - **ESSDPL1**
        # - **ESSDPL2**
        # - **ESSDPL3**
        # - **ESSDAUTOPL**
        self.storage_type = storage_type
        # Set the upper limit for automatic storage expansion of standard edition clusters, in GB.
        # 
        # > The maximum value is 32000.
        self.storage_upper_bound = storage_upper_bound
        # Whether the cluster has enabled strong data consistency across multiple zones. Values are as follows:
        # 
        # - **ON**: Indicates strong data consistency across multiple zones is enabled, applicable to the standard edition 3AZ scenario.
        # 
        # - **OFF**: Indicates strong data consistency across multiple zones is not enabled.
        self.strict_consistency = strict_consistency
        # Enables TDE encryption. Valid values are as follows:
        # 
        # - **true**: Enabled.
        # - **false**: Disabled (default).
        # 
        # > * This parameter takes effect only when **DBType** is **PostgreSQL** or **Oracle**.
        # > * You can call the [ModifyDBClusterTDE](https://help.aliyun.com/document_detail/167982.html) interface to enable TDE encryption for a PolarDB MySQL cluster.
        # > * Once the TDE feature is enabled, it cannot be disabled.
        self.tdestatus = tdestatus
        # List of tags.
        self.tag = tag
        self.target_minor_version = target_minor_version
        # If the payment type is **Prepaid**, this parameter is required.
        # - When **Period** is **Month**, **UsedTime** should be an integer within `[1-9]`.
        # - When **Period** is **Year**, **UsedTime** should be an integer within `[1-3]`.
        self.used_time = used_time
        # VPC ID.
        self.vpcid = vpcid
        # Virtual switch ID.
        # 
        # > If VPCId has been selected, VSwitchId is mandatory.
        self.v_switch_id = v_switch_id
        # Availability Zone ID.
        # 
        # > You can view the available zones through the [DescribeRegions](https://help.aliyun.com/document_detail/98041.html) interface.
        self.zone_id = zone_id

    def validate(self):
        if self.tag:
            for v1 in self.tag:
                 if v1:
                    v1.validate()

    def to_map(self):
        result = dict()
        _map = super().to_map()
        if _map is not None:
            result = _map
        if self.allow_shut_down is not None:
            result['AllowShutDown'] = self.allow_shut_down

        if self.architecture is not None:
            result['Architecture'] = self.architecture

        if self.auto_renew is not None:
            result['AutoRenew'] = self.auto_renew

        if self.auto_use_coupon is not None:
            result['AutoUseCoupon'] = self.auto_use_coupon

        if self.backup_retention_policy_on_cluster_deletion is not None:
            result['BackupRetentionPolicyOnClusterDeletion'] = self.backup_retention_policy_on_cluster_deletion

        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled

        if self.client_token is not None:
            result['ClientToken'] = self.client_token

        if self.clone_data_point is not None:
            result['CloneDataPoint'] = self.clone_data_point

        if self.cloud_provider is not None:
            result['CloudProvider'] = self.cloud_provider

        if self.cluster_network_type is not None:
            result['ClusterNetworkType'] = self.cluster_network_type

        if self.creation_category is not None:
            result['CreationCategory'] = self.creation_category

        if self.creation_option is not None:
            result['CreationOption'] = self.creation_option

        if self.dbcluster_description is not None:
            result['DBClusterDescription'] = self.dbcluster_description

        if self.dbminor_version is not None:
            result['DBMinorVersion'] = self.dbminor_version

        if self.dbnode_class is not None:
            result['DBNodeClass'] = self.dbnode_class

        if self.dbnode_num is not None:
            result['DBNodeNum'] = self.dbnode_num

        if self.dbtype is not None:
            result['DBType'] = self.dbtype

        if self.dbversion is not None:
            result['DBVersion'] = self.dbversion

        if self.default_time_zone is not None:
            result['DefaultTimeZone'] = self.default_time_zone

        if self.ens_region_id is not None:
            result['EnsRegionId'] = self.ens_region_id

        if self.gdnid is not None:
            result['GDNId'] = self.gdnid

        if self.hot_standby_cluster is not None:
            result['HotStandbyCluster'] = self.hot_standby_cluster

        if self.loose_polar_log_bin is not None:
            result['LoosePolarLogBin'] = self.loose_polar_log_bin

        if self.loose_xengine is not None:
            result['LooseXEngine'] = self.loose_xengine

        if self.loose_xengine_use_memory_pct is not None:
            result['LooseXEngineUseMemoryPct'] = self.loose_xengine_use_memory_pct

        if self.lower_case_table_names is not None:
            result['LowerCaseTableNames'] = self.lower_case_table_names

        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account

        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id

        if self.parameter_group_id is not None:
            result['ParameterGroupId'] = self.parameter_group_id

        if self.pay_type is not None:
            result['PayType'] = self.pay_type

        if self.period is not None:
            result['Period'] = self.period

        if self.promotion_code is not None:
            result['PromotionCode'] = self.promotion_code

        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops

        if self.proxy_class is not None:
            result['ProxyClass'] = self.proxy_class

        if self.proxy_type is not None:
            result['ProxyType'] = self.proxy_type

        if self.region_id is not None:
            result['RegionId'] = self.region_id

        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id

        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account

        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id

        if self.scale_max is not None:
            result['ScaleMax'] = self.scale_max

        if self.scale_min is not None:
            result['ScaleMin'] = self.scale_min

        if self.scale_ro_num_max is not None:
            result['ScaleRoNumMax'] = self.scale_ro_num_max

        if self.scale_ro_num_min is not None:
            result['ScaleRoNumMin'] = self.scale_ro_num_min

        if self.security_iplist is not None:
            result['SecurityIPList'] = self.security_iplist

        if self.serverless_type is not None:
            result['ServerlessType'] = self.serverless_type

        if self.source_resource_id is not None:
            result['SourceResourceId'] = self.source_resource_id

        if self.source_uid is not None:
            result['SourceUid'] = self.source_uid

        if self.standby_az is not None:
            result['StandbyAZ'] = self.standby_az

        if self.storage_auto_scale is not None:
            result['StorageAutoScale'] = self.storage_auto_scale

        if self.storage_encryption is not None:
            result['StorageEncryption'] = self.storage_encryption

        if self.storage_encryption_key is not None:
            result['StorageEncryptionKey'] = self.storage_encryption_key

        if self.storage_pay_type is not None:
            result['StoragePayType'] = self.storage_pay_type

        if self.storage_space is not None:
            result['StorageSpace'] = self.storage_space

        if self.storage_type is not None:
            result['StorageType'] = self.storage_type

        if self.storage_upper_bound is not None:
            result['StorageUpperBound'] = self.storage_upper_bound

        if self.strict_consistency is not None:
            result['StrictConsistency'] = self.strict_consistency

        if self.tdestatus is not None:
            result['TDEStatus'] = self.tdestatus

        result['Tag'] = []
        if self.tag is not None:
            for k1 in self.tag:
                result['Tag'].append(k1.to_map() if k1 else None)

        if self.target_minor_version is not None:
            result['TargetMinorVersion'] = self.target_minor_version

        if self.used_time is not None:
            result['UsedTime'] = self.used_time

        if self.vpcid is not None:
            result['VPCId'] = self.vpcid

        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id

        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id

        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('AllowShutDown') is not None:
            self.allow_shut_down = m.get('AllowShutDown')

        if m.get('Architecture') is not None:
            self.architecture = m.get('Architecture')

        if m.get('AutoRenew') is not None:
            self.auto_renew = m.get('AutoRenew')

        if m.get('AutoUseCoupon') is not None:
            self.auto_use_coupon = m.get('AutoUseCoupon')

        if m.get('BackupRetentionPolicyOnClusterDeletion') is not None:
            self.backup_retention_policy_on_cluster_deletion = m.get('BackupRetentionPolicyOnClusterDeletion')

        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')

        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')

        if m.get('CloneDataPoint') is not None:
            self.clone_data_point = m.get('CloneDataPoint')

        if m.get('CloudProvider') is not None:
            self.cloud_provider = m.get('CloudProvider')

        if m.get('ClusterNetworkType') is not None:
            self.cluster_network_type = m.get('ClusterNetworkType')

        if m.get('CreationCategory') is not None:
            self.creation_category = m.get('CreationCategory')

        if m.get('CreationOption') is not None:
            self.creation_option = m.get('CreationOption')

        if m.get('DBClusterDescription') is not None:
            self.dbcluster_description = m.get('DBClusterDescription')

        if m.get('DBMinorVersion') is not None:
            self.dbminor_version = m.get('DBMinorVersion')

        if m.get('DBNodeClass') is not None:
            self.dbnode_class = m.get('DBNodeClass')

        if m.get('DBNodeNum') is not None:
            self.dbnode_num = m.get('DBNodeNum')

        if m.get('DBType') is not None:
            self.dbtype = m.get('DBType')

        if m.get('DBVersion') is not None:
            self.dbversion = m.get('DBVersion')

        if m.get('DefaultTimeZone') is not None:
            self.default_time_zone = m.get('DefaultTimeZone')

        if m.get('EnsRegionId') is not None:
            self.ens_region_id = m.get('EnsRegionId')

        if m.get('GDNId') is not None:
            self.gdnid = m.get('GDNId')

        if m.get('HotStandbyCluster') is not None:
            self.hot_standby_cluster = m.get('HotStandbyCluster')

        if m.get('LoosePolarLogBin') is not None:
            self.loose_polar_log_bin = m.get('LoosePolarLogBin')

        if m.get('LooseXEngine') is not None:
            self.loose_xengine = m.get('LooseXEngine')

        if m.get('LooseXEngineUseMemoryPct') is not None:
            self.loose_xengine_use_memory_pct = m.get('LooseXEngineUseMemoryPct')

        if m.get('LowerCaseTableNames') is not None:
            self.lower_case_table_names = m.get('LowerCaseTableNames')

        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')

        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')

        if m.get('ParameterGroupId') is not None:
            self.parameter_group_id = m.get('ParameterGroupId')

        if m.get('PayType') is not None:
            self.pay_type = m.get('PayType')

        if m.get('Period') is not None:
            self.period = m.get('Period')

        if m.get('PromotionCode') is not None:
            self.promotion_code = m.get('PromotionCode')

        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')

        if m.get('ProxyClass') is not None:
            self.proxy_class = m.get('ProxyClass')

        if m.get('ProxyType') is not None:
            self.proxy_type = m.get('ProxyType')

        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')

        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')

        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')

        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')

        if m.get('ScaleMax') is not None:
            self.scale_max = m.get('ScaleMax')

        if m.get('ScaleMin') is not None:
            self.scale_min = m.get('ScaleMin')

        if m.get('ScaleRoNumMax') is not None:
            self.scale_ro_num_max = m.get('ScaleRoNumMax')

        if m.get('ScaleRoNumMin') is not None:
            self.scale_ro_num_min = m.get('ScaleRoNumMin')

        if m.get('SecurityIPList') is not None:
            self.security_iplist = m.get('SecurityIPList')

        if m.get('ServerlessType') is not None:
            self.serverless_type = m.get('ServerlessType')

        if m.get('SourceResourceId') is not None:
            self.source_resource_id = m.get('SourceResourceId')

        if m.get('SourceUid') is not None:
            self.source_uid = m.get('SourceUid')

        if m.get('StandbyAZ') is not None:
            self.standby_az = m.get('StandbyAZ')

        if m.get('StorageAutoScale') is not None:
            self.storage_auto_scale = m.get('StorageAutoScale')

        if m.get('StorageEncryption') is not None:
            self.storage_encryption = m.get('StorageEncryption')

        if m.get('StorageEncryptionKey') is not None:
            self.storage_encryption_key = m.get('StorageEncryptionKey')

        if m.get('StoragePayType') is not None:
            self.storage_pay_type = m.get('StoragePayType')

        if m.get('StorageSpace') is not None:
            self.storage_space = m.get('StorageSpace')

        if m.get('StorageType') is not None:
            self.storage_type = m.get('StorageType')

        if m.get('StorageUpperBound') is not None:
            self.storage_upper_bound = m.get('StorageUpperBound')

        if m.get('StrictConsistency') is not None:
            self.strict_consistency = m.get('StrictConsistency')

        if m.get('TDEStatus') is not None:
            self.tdestatus = m.get('TDEStatus')

        self.tag = []
        if m.get('Tag') is not None:
            for k1 in m.get('Tag'):
                temp_model = main_models.CreateDBClusterRequestTag()
                self.tag.append(temp_model.from_map(k1))

        if m.get('TargetMinorVersion') is not None:
            self.target_minor_version = m.get('TargetMinorVersion')

        if m.get('UsedTime') is not None:
            self.used_time = m.get('UsedTime')

        if m.get('VPCId') is not None:
            self.vpcid = m.get('VPCId')

        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')

        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')

        return self

class CreateDBClusterRequestTag(DaraModel):
    def __init__(
        self,
        key: str = None,
        value: str = None,
    ):
        # Tag key. If you need to add multiple tags to the target cluster at once, click **Add** to add a tag key.
        # 
        # > Up to 20 pairs of tags can be added each time, where `Tag.N.Key` corresponds to `Tag.N.Value`.
        self.key = key
        # Tag value. If you need to add multiple tags to the target cluster at once, click **Add** to add tag values.
        # 
        # > Up to 20 pairs of tags can be added each time, where `Tag.N.Value` corresponds to `Tag.N.Key`.
        self.value = value

    def validate(self):
        pass

    def to_map(self):
        result = dict()
        _map = super().to_map()
        if _map is not None:
            result = _map
        if self.key is not None:
            result['Key'] = self.key

        if self.value is not None:
            result['Value'] = self.value

        return result

    def from_map(self, m: dict = None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')

        if m.get('Value') is not None:
            self.value = m.get('Value')

        return self

